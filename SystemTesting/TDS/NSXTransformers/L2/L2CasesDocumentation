##############################################################
# Title: Avalanche L2 TDS                                    |
# Dev Feature Owner: Pankaj Thakkar                          |
# PM Feature Owner: Francois Tallet                          |
# QE Feature Owner: jialiangl, salmanm, shawntu, mqing, jana |
# QE Manager: Sujatha, Matt, Srikanth                        |
# QE Reviewers: TBD                                          |
##############################################################

#######################################################################
#                       P0 Test Cases                                 #
#######################################################################

ARPProxyVMinDifferentHost:
 Product: "NSX"
 Category: "L2"
 Component: "LCP-ESX"
 TestName: "ARPProxyVMinDifferentHost"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: "Sanity"
 qcpath:
 Testbed:
 Summary: "To verify that ARP request for a VM in different host is not" .
          " broadcasted, and a request is sent to CCP (ESX)/ no request is" .
          " sent out (KVM)."
 Procedure:
    "- Deploy MP" .
    "- Deploy CCP" .
    "- Install vib for 4 TNs (LCP, MPA, DP), TN1 and TN2 in segment 1," .
    "  TN 3 and TN 4 in segment 2, TN1 and TN3 are ESX, TN2 and TN4 are KVM." .
    "- Bootstrap TNs (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)." .
    "- Create a TZ" .
    "- Add TNs to a TZ." .
    "- Deploy one VM on each TN (VM1 on TN1, VM2 on TN2, VM3 on TN3, " .
    "  and VM4 on TN4)" .
    "- Create LSwitch 5000 in the TZ, with replication method as MTEP" .
    "- Attach VIFs of all 4 VM's to LS 5000" .
    "- Assign static IP addresses to VMs" .
    "- Each VM sends arping traffic to all other VMs" .
    "- Verify arp request is sent to CCP (ESX)/ no request is sent out (KVM)" .
    "- Each VM sends ping traffic to all other VMs" .
    "- Verify CCP connection tables for TN connection" .
    "- Verify CCP VTEP tables for TN" .
    "- Verify whether CCP shows proper ARP table entries and MAC table " .
    "  entries for VM." .
    "- Verify whether replication method is shown as MTEP on TNs" .
    "- Clean up."
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, ARPProxy, ESXOnly, VxSTT"
 AutomationLevel: "Automated"
 Developer: "shawntu"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y

ARPLearningMethodsARPSnooping:
 Product: "NSX"
 Category: "L2"
 Component: "LCP-ESX"
 TestName: "ARPLearningMethodsARPSnooping"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: "Sanity"
 qcpath:
 Testbed:
 Summary: "To verify ARP snooping used by the VTEP in learning the {VM-IP, " .
          " VM-MAC} table."
 Procedure:
    "- Deploy MP" .
    "- Deploy CCP" .
    "- Install vib for 4 TNs (LCP, MPA, DP), TN1 and TN2 in segment 1, TN 3 " .
    "  and TN 4 in segment 2, TN1 and TN3 are ESX, TN2 and TN4 are KVM." .
    "- Bootstrap TNs (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)" .
    "- Create a TZ" .
    "- Add TNs to a TZ" .
    "- Deploy one VM on each TN (VM1 on TN1, VM2 on TN2, VM3 on TN3, and VM4" .
    "  on TN4)" .
    "- Create LSwitch 5000 in the TZ, with replication method as MTEP" .
    "- Attach VIFs of all 4 VM's to LS 5000" .
    "- Assign static IP addresses to VMs" .
    "- Verify whether TN's are able to connect to CCP, using cli commands" .
    "- Verify whether replication method is shown as MTEP on TNs" .
    "- Verify whether tunnels are established between VTEP's" .
    "- Each VM sends ping traffic to all other VMs" .
    "- Verify each VTEP has learned the IP-MAC mapping via ARP snooping." .
    "- Clean up"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, ARPSnooping, ESXOnly, VxSTT"
 AutomationLevel: "Automated"
 Developer: "shawntu"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y

NewController:
 Product: "NSX"
 Category: "L2"
 Component: "L2-ESX"
 TestName: "NewController"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: "Sanity"
 qcpath:
 Testbed:
 Summary: "To verify the scenario where a new controller is added to the " .
          " controller cluster."
 Procedure:
    "- Deploy MP" .
    "- Deploy CCP" .
    "- Install vib for 4 TNs (LCP, MPA, DP), TN1 and TN2 in segment 1, TN 3 " .
    "  and TN 4 in segment 2, TN1 and TN3 are ESX, TN2 and TN4 are KVM." .
    "- Bootstrap TNs (nsxvswitch on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)" .
    "- Create a TZ" .
    "- Add TNs to a TZ" .
    "- Deploy one VM on each TN (VM1 on TN1, VM2 on TN2, VM3 on TN3, and " .
    "  VM4 on TN4)" .
    "- Create LSwitch 5000 in the TZ, with replication method as MTEP" .
    "- Attach VIFs of all 4 VM's to LS 5000" .
    "- Assign static IP addresses to VMs" .
    "- Verify whether TN's are able to connect to CCP, using cli commands" .
    "- Verify whether replication method is shown as MTEP on TNs" .
    "- Verify whether CCP shows proper VM_MAC<->VTEP_IP, VM_IP<->VM_MAC, " .
    "  etc, entries" .
    "- Verify whether tunnels are established between VTEP's" .
    "- Each VM sends ping traffic to all other VMs" .
    "- Add a new CCP to the CCP cluster." .
    "- Verify CCP list in VTEP is updated with new CCP IP address." .
    "- Reload the old CCP node." .
    "- Verify that new CCP node will take over the CCP cluster and VTEP does " .
    "  not enter headless mode." .
    "- Verify that LCP remove the old CCP node info after 3 consecutive hello " .
    "  message lost." .
    "- Verify that the old CCP node join the CCP clusters after reload." .
    "- Clean up"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, ESXOnly, CCP, VxSTT"
 AutomationLevel: "Automated"
 Developer: "shawntu"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y

VNIDatabaseUpdate:
 Product: "NSX"
 Category: "L2"
 Component: "L2-ESX"
 TestName: "VNIDatabaseUpdate"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: "Sanity"
 qcpath:
 Testbed:
 Summary: "To verify whether VTEP updates controller when VNI is added/deleted" .
 Procedure:
    "- Deploy MP" .
    "- Deploy CCP" .
    "- Install vib for 4 TNs (LCP, MPA, DP), TN1 and TN2 in segment 1, TN 3 " .
    "  and TN 4 in segment 2, TN1 and TN3 are ESX, TN2 and TN4 are KVM." .
    "- Bootstrap TNs (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)" .
    "- Create a TZ" .
    "- Add TNs to a TZ" .
    "- Deploy one VM on each TN (VM1 on TN1, VM2 on TN2, VM3 on TN3, and VM4 " .
    "  on TN4)" .
    "- Create LSwitch5000 and LSwitch5001 in the TZ, with replication method " .
    "  as MTEP and source node" .
    "- Attach VIFs of VM1 and VM3 to LS 5000, VM2 and VM4 to LS5001" .
    "- Assign static IP addresses to VMs" .
    "- Verify whether TN's are able to connect to CCP, using cli commands" .
    "- Verify whether replication method is shown as MTEP on TNs" .
    "- Each VM sends ping traffic to all other VMs" .
    "- Verify whether CCP shows proper VNI info, VM_MAC<->VTEP_IP, " .
    "  VM_IP<->VM_MAC, etc, entries" .
    "- Clean up"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, ESXOnly, LCPtoCCP, VxSTT"
 AutomationLevel: "Automated"
 Developer: "shawntu"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y

VTEPDatabaseSync:
 Product: "NSX"
 Category: "L2"
 Component: "L2-ESX"
 TestName: "VTEPDatabaseSync"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: "Sanity"
 qcpath:
 Testbed:
 Summary: "To verify whether a VTEP successfully gets information about other" .
          "relevant VTEPs from the controller."
# Applies more to KVM but ESX should also get data after querying controller
 Procedure:
    "- Deploy MP" .
    "- Deploy CCP" .
    "- Install vib for 4 TNs (LCP, MPA, DP), TN1 is ESX, TN2 is KVM. TN1 and " .
    "  TN2 are in different segments." .
    "- Bootstrap TN (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)" .
    "- Create 2 TZs" .
    "- Add TN1 and TN2 to TZ1 and TN3 and TN4 to TZ2." .
    "- Deploy 2 VMs on each TN (VM1, VM2 on TN1, VM3, vM4 on TN2, VM5 and VM6 " .
    "  onTN3, and etc.)" .
    "- Create LS1 and LS2 in TZ1, LS3 and LS4 in TZ2, with replication " .
    "  method as MTEP" .
    "- Attach VM1, VM2 and VM3 to LS1, VM4 to LS2" .
    "- Assign static IP addresses to VMs" .
    "- Verify whether TN's are able to connect to CCP, using cli commands" .
    "- Verify whether replication method is shown as MTEP on TNs" .
    "- Verify whether CCP shows proper VM_MAC<->VTEP_IP, " .
    "  VM_IP<->VM_MAC, etc, entries" .
    "- If TN1 and TN2 are KVM, TN1 and TN2 both must have info about each " .
    "  other." .
    "- If TN1 and TN2 are ESX, send traffic from VM1 to VM3.  Only " .
    "  after ARP suppression kicks in, TN1 and TN2 will be able to see each " .
    "  other." .
    "- TN1 and TN3 should not see each other, irrespective of the hosts or " .
    "  traffic generated from VM." .
    "- Detach VM3 from LS1 to LS2, verify TN1 and TN2 cannot see each other." .
    "- Attach VM3 to LS1 and verify TN1 and TN2 can see each other." .
    "- Repeat above steps for TN3 and TN4 in TZ2, and for TN1 and TN3 in a " .
    "  new TZ." .
    "- Clean up"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, ESXOnly, LCPtoCCP, VxSTT"
 AutomationLevel: "Automated"
 Developer: "shawntu"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y

TNChangeZone:
 Product: "NSX"
 Category: "L2"
 Component: "unknown"
 TestName: "TNChangeZone"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: ""
 qcpath:
 Testbed:
 Summary: "To verify that a transport node can change to a different " .
          "transport zone and connectivity fails to work."
 Procedure:
    "- Deploy MP" .
    "- Deploy CCP" .
    "- Install vib for 6 TNs (LCP, MPA, DP) in 3 segments, TN1 and TN2 in " .
    "  segment1, TN3 and TN4 in segment 2, TN5 and TN6 in segment3" .
    "- TN1, TN3 and TN5 are ESX, TN2, TN4, and TN6 are KVM." .
    "- Bootstrap TNs (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)" .
    "- Create 3 TZ, and add TN1 and TN3 to TZ1, TN2 and TN4 to TZ2, TN5 " .
    "  and TN6 in TZ3." .
    "- Deploy 1 VM on each TN.  Add the VMs in same TZ to same VNI" .
    "- Set the VXLAN replication mode to Source-Node" .
    "- Generate unicast traffic from VM's such that all VTEPs within" .
    "  the same VNI are aware of other VTEPs" .
    "- Move TN5 to TZ1 to simulate ESX TN move from a mixed ESX/KVM TZ " .
    "  to a pure ESX TZ" .
    "- Verify TN5 can join TZ1" .
    "- Add VMs on TN5 to the VNI in TZ1" .
    "- Verify VM on TN5 can communicate with other VMs in the same VNI" .
    "- Move TN5 back to TZ3" .
    "- Verify TN5 can join TZ3" .
    "- Move TN6 to TZ2 to simulate KVM TN move from a mixed ESX/KVM TZ to a " .
    "  pure KVM TZ" .
    "- Verify TN6 can join TZ2" .
    "- Add VMs on TN6 to the VNI in TZ2" .
    "- Verify VM on TN6 can communicate with other VMs in the same VNI" .
    "- Move TN6 back to TZ3" .
    "- Verify TN6 can join TZ3" .
    "- Move TN1 to TZ3 to simulate ESX TN move from a pure ESX TZ to a mixed " .
    "  ESX/KVM TZ" .
    "- Verify TN1 can join TZ3" .
    "- Add VMs on TN1 to the VNI in TZ3" .
    "- Verify VM on TN1 can communicate with other VMs in the same VNI" .
    "- Move TN1 back to TZ1" .
    "- Verify TN1 can join TZ1" .
    "- Move TN2 to TZ3 to simulate KVM TN move from a pure KVM TZ to a mixed " .
    "  ESX/KVM TZ" .
    "- Verify TN2 can join TZ3" .
    "- Add VMs on TN2 to the VNI in TZ3" .
    "- Verify VM on TN2 can communicate with other VMs in the same VNI" .
    "- Move TN2 back to TZ2" .
    "- Verify TN2 can join TZ2"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, ESXOnly, VxSTT"
 AutomationLevel: "Automated"
 Developer: "jialiangl"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y

L2Isolation:
 Product: "NSX"
 Category: "L2"
 Component: "LCP-ESX"
 TestName: "L2Isolation"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: "Functional"
 qcpath:
 Testbed:
 Summary: "To verify that traffic originated by VM in one logical space is" .
          "never seen in another VM in a different logical space (same host" .
          "or different host)."
 Procedure:
    "- Deploy MP" .
    "- Deploy CCP" .
    "- Install vib for 3 TNs (LCP, MPA, DP). TN1 and TN2 are ESX and TN3 is " .
    "  KVM" .
    "- Bootstrap TNs (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)" .
    "- Create 1 TZ, 2 segments. Add TN1 to segment 1. TN2 & TN3 to segment 2" .
    "- Deploy 2 VM's on each TN. Assign VM1 and VM3 to LS5000, VM2 and VM5 " .
    "  to LS5001, VM4 and VM6 to LS5002." .
    "- Set the VXLAN replication mode to MTEP based" .
    "- Generate unicast traffic from VM's such that all VTEP's are aware of " .
    "  other VTEPs" .
    "- Send traffic only from VM1 to VM3.  Run pktcap or tcpdump utilites on " .
    "  all other VMs and verify that none of them receive any packet" .
    "- Send BUM traffic from VM1.  Again, observe that none of the " .
    "  other VM's receive any packet, except for VM3" .
    "- Stop all traffic. Send unicast traffic from VM2 to VM5. Using " .
    "  pktcap/tcpdump utilities, verify that none of the other VM's receive " .
    "  any packet" .
    "- Send BUM traffic from VM2. Again, observe that none of the other " .
    "  VMs receive any packet, except for VM5" .
    "- Stop all traffic.  Send unicast traffic from VM4 to VM6. Using " .
    "  pktcap/tcpdump utilities, verify that none of the other VM's receive " .
    "  any packet" .
    "- Send BUM traffic from VM4. Again, observe that none of the other " .
    "  VM's receive any packet, except for VM6" .
    "- Continue sending BUM traffic from VM4. Move VM2 to LS5002." .
    "- Verify whether existing tunnel between TN1 and TN3 is momentarily " .
    "  destroyed and established again. And BUM traffic is seen on VM2" .
    "- Move VM2 back to 5001 and verify BUM traffic is not seen on it." .
    "- Clean up"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, Sanity, ESXOnly, VxSTT"
 AutomationLevel: "Automated"
 Developer: "jialiangl"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y

CCPConfig:
 Product: "NSX"
 Category: "L2"
 Component: "Mgmt Application"
 TestName: "CCPConfig"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: "Functional"
 qcpath:
 Testbed:
 Summary: "To verify that MP pushes the CCP sharding data for every VTEP."
 Procedure:
    "- Deploy MP" .
    "- Deploy CCP" .
    "- Install vib for 4 TNs (LCP, MPA, DP). TN1 and TN2 are ESX, and TN3 and " .
    "  TN4 is KVM" .
    "- Bootstrap TNs (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)" .
    "- Create 1 TZ, 2 segments.  Add TN1 and TN3 to segment 1. TN3 and TN4 to " .
    "  segment 2" .
    "- Deploy 2 VM's on each TN. VM1 and VM2 in TN1, VM3 and VM4 in TN2, VM5 " .
    "  and VM6 in TN3, VM7 and VM8 in TN4" .
    "- Assign VM1, VM3, VM5 and VM7 to LS5000, VM2, VM4, VM6 and VM8 to LS5001." .
    "- Set LS5000 replication mode to MTEP-uc, and LS5001 rep mode to " .
    "  source node based." .
    "- Generate unicast traffic from VM's such that all VTEPs are aware " .
    "  of other VTEPs" .
    "- Verify that CCP has correct correct VM_MAC<->VTEP_IP, VM_IP<->VM_MAC" .
    "- Move VM8 from LS5001 to LS5000, verify CCP remove all the info about " .
    "  LS5001 for TZ4 (KVM)" .
    "- Verify BUM/unicast traffic generated from VM8 to other VMs in LS5000" .
    "- Move VM7 from LS5000 to LS5001, verify CCP add the info about LS5001 " .
    "  for TZ4 (KVM)" .
    "- Verify BUM/unicast traffic generated from VM7 to other VMs in LS5001" .
    "- Move VM3 from LS5000 to LS5001, verify CCP remove all the info about " .
    "  LS5000 for TZ2 (ESX)" .
    "- Verify BUM/unicast traffic generated from VM3 to other VMs in LS5001" .
    "- Move VM4 from LS5001 to LS5000, verify CCP add the info about LS5000 " .
    "  for TZ2 (ESX)" .
    "- Verify BUM/unicast traffic generated from VM4 to other VMs in LS5000" .
    "- Cleanup"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, ESXOnly, VxSTT, Sharding"
 AutomationLevel: "Automated"
 Developer: "jialiangl"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y

NegativeControllerIpChange:
 Product: "NSX"
 Category: "L2"
 Component: "unknown"
 TestName: "NegativeControllerIpChange"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: "Negative"
 qcpath:
 Testbed:
 Summary: "To verify whether VTEPs are able to converge, when the configured" .
          "controller on them is switched between multiple ip addresses."
 Procedure:
    "- Deploy MP" .
    "- Deploy CCP" .
    "- Install vib for 4 TNs (LCP, MPA, DP). TN1 and TN2 are ESX, and TN3 and " .
    "  TN4 is KVM" .
    "- Bootstrap TNs (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)" .
    "- Create 1 TZ, 2 segments.  Add TN1 and TN3 to segment 1. TN3 and TN4 to " .
    "  segment 2" .
    "- Deploy 1 VM on each TN. VM1 in TN1, VM2 in TN2, etc." .
    "- Assign all VMs to a random LSwitch number" .
    "- Set LS replication mode to MTEP-uc" .
    "- Generate unicast traffic from VM's such that all VTEPs are aware " .
    "  of other VTEPs" .
    "- Verify that CCP has correct correct VM_MAC<->VTEP_IP, VM_IP<->VM_MAC" .
    "- Initiate traffic between all VMs" .
    "- Change the master CCP IP address to another valid IP address and " .
    "  add it back to CCP list" .
    "- Verify that VTEPs choose another CCP as master CCP and CCP list is " .
    "  updated." .
    "- Change the master CCP IP address to an invalid IP address and try to " .
    "  add it back to CCP list." .
    "- Verify that CCP list is not updated." .
    "- Verify VM traffic is not interrupted." .
    "- Cleanup"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, ESXOnly, VxSTT"
 AutomationLevel: "Automated"
 Developer: "jialiangl"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y

SameVMIPDifferentLS:
 Product: "NSX"
 Category: "L2"
 Component: "unknown"
 TestName: "SameVMIPDifferentLS"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: "Functional"
 qcpath:
 Testbed:
 Summary: "To test the scenario where the VTEPs have VMs having the same IP" .
          "address. (different logical space)"
 Procedure:
    "- Deploy MP." .
    "- Deploy CCP." .
    "- Install vib for 2 TNs (LCP, MPA, DP)." .
    "- Bootstrap all TNs (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    " bridge/bridge interface on KVM)." .
    "- Create 1 TZ, 1 segment, and add 2 TN's to it." .
    "- Verify whether TN's are able to connect to CCP, using cli commands" .
    "- Deploy 2 VMs on each TN (VM1, VM2 on TN1 and VM3, VM4 on TN2)." .
    "- Attach VM1 and VM3 to LSwitch 5000 and VM2 and VM4 to LSwitch " .
    "  5001. Both switches are configured in MTEP-uc mode." .
    "- Assign static IPs to all VMs such that VM1 has the same IP as " .
    "  VM3 and VM2 has the same IP as VM4." .
    "- Verify whether tunnels are established between VTEP's." .
    "- Verify whether replication method on TNs." .
    "- Verify whether CCP shows proper VM_MAC<->VTEP_IP, VM_IP<->VM_MAC, etc, " .
    "  entries." .
    "- Verify that the VM1 and VM3 are able to reach each other, and " .
    "  that VM2 and VM4 are able to reach each other via ping." .
    "- Also verify that VM1/VM3 never see VM2/VM4's traffic and vice versa." .
    "- Cleanup"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, ESXOnly, VxSTT"
 AutomationLevel: "Automated"
 Developer: "jialiangl"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y

ControllerReboot:
 Product: "NSX"
 Category: "L2"
 Component: "LCP-ESX"
 TestName: "ControllerReboot"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: "Functional"
 qcpath:
 Testbed:
 Summary: "To verify the functionality after one or more controllers" .
          "(controller for at least one LS) is rebooted."
 Procedure:
    "- Deploy MP" .
    "- Deploy CCP" .
    "- Install packages/vib (LCP, MPA, DP) for 4 TNs" .
    "- Bootstrap TNs (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)" .
    "- Create 1 TZ, 2 segments.  Add TN3 and TN4 to segment 1. TN5 and " .
    "  TN6 to segment 2" .
    "- Verify (using CLI) that TNs can talk to controllers" .
    "- Deploy 2 VMs on each TN. VM3-4 in TN3 and VM5-6 in TN4 and so on." .
    "- Attach first VM on each host to LSwitch5000 (MTEP-uc mode) and the "
    "  second VM to LSwitch5001 (Source-uc mode)" .
    "- Verify switch replication modes on host."
    "- Generate unicast traffic from VM's such that all VTEPs are aware " .
    "  of other VTEPs" .
    "- Verify that CCP has correct correct VM_MAC<->VTEP_IP, " .
    "  VM_IP<->VM_MAC" .
    "- Initiate traffic between all VMs" .
    "- Reboot master CCP node(CCP command can show logical switch mapping " .
    "  with CCP node)" .
    "- Verify that VTEPs choose another CCP as master CCP and CCP list is " .
    "  updated within at most 15 seconds after master CCP is rebooted (CCP " .
    "  list didn’t sync to LCP when CCP node reboot,this verification can be" .
    "  deleted)." .
    "- After CCP node is back, verify that it is added back to the CCP list " .
    "  and VTEPs have the updated list (same as above,this step can be " .
    "  deleted)." .
    "- Verify VM traffic is not interrupted." .
    "- Reboot entire CCP cluster" .
    "- After CCP nodes are back up, verify that the LCPs download " .
    "  correct information from CCP." .
    "- Verify VM traffic is not interrupted." .
    "- Cleanup"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, ESXOnly, VxSTT, Reboot"
 AutomationLevel: "Automated"
 Developer: "salmanm"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y
 TestbedSpec: Functional_Topology_2
 WORKLOADS:
    Sequence:
        - ['CreateVMsVnics']
        - ['CreateTransportZone']
        - ['AddTransportNodesToTransportZone']
        - ['CreateLogicalSwitch']
        - ['CreateLogicalPort']
        - ['ChangeVnicBackingLogicalSwitch']
        - ['PoweronVM3', 'PoweronVM5', 'PoweronVM7', 'PoweronVM9']
        - ['PoweronVM4', 'PoweronVM6', 'PoweronVM8', 'PoweronVM10']
        - ['VerifyControlConnectivityOnHost']
        - ['VerifyReplicationModeOfLSwitch1OnHost',
           'VerifyReplicationModeOfLSwitch2OnHost']
        - ['ConfigureVnicIP']
        - ['ArpPingLS1', 'ArpPingLS2']
        - ['VerifyLS1ArpEntryOnControllers', 'VerifyLS2ArpEntryOnControllers']
        # Not sure how we can start traffic, do some operation and then verify
        # that traffic wasn't interrupted by the intermediary operation.
        - ['RunVerifyArpPingLS1', 'RunVerifyArpPingLS2',
           ['RebootMasterControllerOfLSwitch1',
            ['RebootMasterControllerOfSwitch2',
        # Not sure how we can verify that there has been a change in certain
        # database after an operation has executed.
             'VerifyMasterControllerChangeOfaVNI']]]
        - ['RunVerifyArpPingLS1', 'RunVerifyArpPingLS2',
           ['RebootCCP', ['VerifyMTEPOnHost', 'VerifyMacTableLSwitch1OnHost',
                          'VerifyMacTableLSwitch2OnHost']]]
        - ['VerifyLS1ArpEntryOnControllers', 'VerifyLS2ArpEntryOnControllers']
    ExitSequence:
        - ['PowerOffAllVMs']
        - ['DeleteVM3Vnic1InExitSeq', 'DeleteVM5Vnic1InExitSeq',
           'DeleteVM7Vnic1InExitSeq', 'DeleteVM9Vnic1InExitSeq']
        - ['DeleteVM4Vnic1InExitSeq', 'DeleteVM6Vnic1InExitSeq',
           'DeleteVM8Vnic1InExitSeq', 'DeleteVM10Vnic1InExitSeq']
        - ['CleanupNSX']

    PoweronVM3: *POWERON_VM3
    PoweronVM4: *POWERON_VM4
    PoweronVM5: *POWERON_VM5
    PoweronVM6: *POWERON_VM6
    PoweronVM7: *POWERON_VM7
    PoweronVM8: *POWERON_VM8
    PoweronVM9: *POWERON_VM9
    PoweronVM10: *POWERON_VM10
    PoweroffAllVMs: *POWEROFF_ALL_VM

    CreateVMsVnics:
        Type: VM
        TestVM: vm.[3-10]
        vnic:
            [1]:
                driver: vmxnet3
                connected: 1
                startconnected: 1
                allowguestcontrol: 1
                external_uuid: 'auto'

    CreateTransportZone:
        Type: NSX
        TestNSX: nsxmanager.[1]
        transportzone:
            '[1]':
                name: autogenerate
                transportZoneType: 'overlay'

    AddTransportNodesToTransportZone:
        Type: NSX
        TestNSX: nsxmanager.[1]
        transportnode:
            '[3-6]':
                name: autogenerate
                hostId: esx.[x:vdnetindex:transportnode]
                hostSwitches:
                    # Opaque Switch ID.
                    - hostSwitchId:
                        esx.[x:vdnetindex:transportnode].nsxvswitch.[1]
                      uplink:
                        - deviceId:
                            esx.[x:vdnetindex:transportnode].vmnic.[1]
                    transportZoneEndPoints:
                        - transportZoneId: nsxmanager.[1].transportzone.[1]
                        # List of VTEPs.
                        vteps:
                            - ip: esx.[x:vdnetindex:transportnode].vtep.[1]
                              name: esx.[x:vdnetindex:transportnode].vtep.[1]

    CreateLogicalSwitch:
        Type: NSX
        TestNSX: nsxmanager.[1]
        logicalswitch:
            '[1]':
                name: LSwitch1
                transportZone: nsxmanager.[1].transportzone.[1]
                adminState: up
                replicationmode: mtep
            '[2]':
                name: LSwitch2
                transportZone: nsxmanager.[1].transportzone.[1]
                adminState: up
                replicationmode: source

    CreateLogicalPort:
        Type: NSX
        TestNSX: nsxmanager.[1]
        logicalport:
            '[3-10]':
                logicalSwitchId: nsxmanager.[1].logicalswitch.[x:mod:2]
                vif: vm.[x].vnic.[1]
                adminState: up

    ChangeVnicBackingLogicalSwitch:
        Type: NetAdapter
        TestAdapter: vm.[3-10].vnic.[1]
        network: nsxmanager.[1].logicalswitch.[x:mod:2]

    VerifyControlConnectivityOnHost
        Type: "Switch"
        TestSwitch: "nsxmanager.[1].logicalswitch.[-1]"
        controllerstatusonhosts: 'up'
        hosts: 'esx.[3-6]'

    ConfigureVnicIP:
        Type: NetAdapter
        TestAdapter: vm.[3-10].vnic.[1]
        IPv4: auto

    VerifyReplicationModeOfLSwitch1OnHost:
        Type: "Switch"
        testswitch: "nsxmanager.[1].logicalswitch.[1]"
        hosts: "esx.[3-6]"
        verifyreplicationmodeonhost:
            - 'replicationmode[?]match': 'mtep'

    VerifyReplicationModeOfLSwitch2OnHost:
        Type: "Switch"
        testswitch: "nsxmanager.[1].logicalswitch.[2]"
        hosts: "esx.[3-6]"
        verifyreplicationmodeonhost:
            - 'replicationmode[?]match': 'source'

    ArpPingLS1:
        Type: 'Traffic'
        toolName: 'ArpPing'
        TestAdapter   : "vm.[3].vnic.[1],vm.[5].vnic.[1],vm.[7].vnic.[1]"
        SupportAdapter: 'vm.[9].vnic.[1]'

    ArpPingLS2:
        Type: 'Traffic'
        toolName: 'ArpPing'
        TestAdapter: 'vm.[4].vnic.[1],vm.[6].vnic.[1],vm.[8].vnic.[1]'
        SupportAdapter: 'vm.[10].vnic.[1]'

    VerifyLS1ArpEntryOnControllers:
        Type: 'Switch'
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1]'
        controllers: 'nsxmanager.[1].nsxcontroller.[-1]'
        'VerifyArpEntryOnController[?]contain_once':
            - ip: "vm.[3].vnic.[1]"
              mac: "vm.[3].vnic.[1]"
            - ip: "vm.[5].vnic.[1]"
              mac: "vm.[5].vnic.[1]"
            - ip: "vm.[7].vnic.[1]"
              mac: "vm.[7].vnic.[1]"
            - ip: "vm.[9].vnic.[1]"
              mac: "vm.[9].vnic.[1]"

    VerifyLS2ArpEntryOnControllers:
        Type: 'Switch'
        TestSwitch: 'nsxmanager.[1].logicalswitch.[2]'
        controllers: 'nsxmanager.[1].nsxcontroller.[-1]'
        'VerifyArpEntryOnController[?]contain_once':
            - ip: "vm.[4].vnic.[1]"
              mac: "vm.[4].vnic.[1]"
            - ip: "vm.[6].vnic.[1]"
              mac: "vm.[6].vnic.[1]"
            - ip: "vm.[8].vnic.[1]"
              mac: "vm.[8].vnic.[1]"
            - ip: "vm.[10].vnic.[1]"
              mac: "vm.[10].vnic.[1]"

    RunVerifyArpPingLS1:
        Type          : "Traffic"
        ToolName      : "netperf"
        L3Protocol    : "ipv4"
        L4Protocol    : "tcp"
        TestAdapter: 'vm.[3].vnic.[1],vm.[5].vnic.[1],vm.[7].vnic.[1]'
        SupportAdapter: 'vm.[9].vnic.[1]'
        NoofOutbound  : "1"
        NoofInbound   : "1"
        TestDuration  : "90"

    RunVerifyArpPingLS2:
        Type          : "Traffic"
        ToolName      : "netperf"
        L3Protocol    : "ipv4"
        L4Protocol    : "tcp"
        TestAdapter: 'vm.[4].vnic.[1],vm.[6].vnic.[1],vm.[8].vnic.[1]'
        SupportAdapter: 'vm.[10].vnic.[1]'
        NoofOutbound  : "1"
        NoofInbound   : "1"
        TestDuration  : "90"

    RebootMasterControllerOfLSwitch1:
        Type: "Switch"
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1]'
        controllers: 'nsxmanager.[1].nsxcontroller.[-1]'
        controllerstate: 'poweroff,poweron'
        sleepbetweenworkloads: '20'

    RebootMasterControllerOfLSwitch2:
        Type: "Switch"
        TestSwitch: 'nsxmanager.[1].logicalswitch.[2]'
        controllers: 'nsxmanager.[1].nsxcontroller.[-1]'
        controllerstate: 'poweroff,poweron'
        sleepbetweenworkloads: '20'

    RebootCCP:
        Type: "Nsxcontroller"
        TestController: 'nsxmanager.[1].nsxcontroller.[-1]'
        controllerstate: 'poweroff,poweron'
        sleepbetweenworkloads: '60'

    VerifyMTEPOnHost:
        Type: "Switch"
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1]'
        checkmteponhost: 'esx.[3-6]'

    VerifyMacTableLSwitch1OnHost:
        Type: "Switch"
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1]'
        hosts: 'esx.[6]'
        'VerifyMacTableOnHost[?]contain_once':
            - inner_mac: "vm.[3].vnic.[1]"
              outer_ip: "esx.[3].vtep.[1]"
            - inner_mac: "vm.[5].vnic.[1]"
              outer_ip: "esx.[4].vtep.[1]"
            - inner_mac: "vm.[7].vnic.[1]"
              outer_ip: "esx.[5].vtep.[1]"

    VerifyMacTableLSwitch2OnHost:
        Type: "Switch"
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1-2]'
        hosts: 'esx.[6]'
        'VerifyMacTableOnHost[?]contain_once':
            - inner_mac: "vm.[4].vnic.[1]"
              outer_ip: "esx.[3].vtep.[1]"
            - inner_mac: "vm.[6].vnic.[1]"
              outer_ip: "esx.[4].vtep.[1]"
            - inner_mac: "vm.[8].vnic.[1]"
              outer_ip: "esx.[5].vtep.[1]"

    DeleteVM3Vnic1InExitSeq: *DELETE_VM3_VNIC1_IN_EXIT_SEQ
    DeleteVM4Vnic1InExitSeq: *DELETE_VM4_VNIC1_IN_EXIT_SEQ
    DeleteVM5Vnic1InExitSeq: *DELETE_VM5_VNIC1_IN_EXIT_SEQ
    DeleteVM6Vnic1InExitSeq: *DELETE_VM6_VNIC1_IN_EXIT_SEQ
    DeleteVM7Vnic1InExitSeq: *DELETE_VM7_VNIC1_IN_EXIT_SEQ
    DeleteVM8Vnic1InExitSeq: *DELETE_VM8_VNIC1_IN_EXIT_SEQ
    DeleteVM9Vnic1InExitSeq: *DELETE_VM9_VNIC1_IN_EXIT_SEQ
    DeleteVM10Vnic1InExitSeq: *DELETE_VM10_VNIC1_IN_EXIT_SEQ
    CleanupNSX: *CLEANUP_NSX

VTEPReboot:
 Product: "NSX"
 Category: "L2"
 Component: "LCP-ESX"
 TestName: "VTEPReboot"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: ""
 qcpath:
 Testbed:
 Summary: "To verify the functionality after the VTEP is rebooted."
 Procedure:
    "- Deploy MP" .
    "- Deploy CCP" .
    "- Install packages/vib (LCP, MPA, DP) for 4 TNs." .
    "- Bootstrap TNs (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)" .
    "- Create 1 TZ, 2 segments.  Add TN3 and TN4 to segment 1. TN5 and " .
    "  TN6 to segment 2" .
    "- Verify (using CLI) that TNs can talk to controllers" .
    "- Deploy 2 VMs on each TN. VM3-4 in TN3, VM5-VM6 in TN4 and so on" .
    "- Attach first VM on each TN to LSwitch1 (in MTEP-uc mode) and second" .
    "  VM on each TN to LSwitch2 (in source-uc mode)" .
    "- Verify switch replication modes on host."
    "- Generate unicast traffic between VMs such that all VTEPs are " .
    "  aware of other VTEPs" .
    "- Verify that CCP has correct correct VM_MAC<->VTEP_IP, " .
    "  VM_IP<->VM_MAC" .
    "- Verify that VM1 and VM8 can ping other VMs in their logical domains" .
    "- Reboot TN1 and TN4" .
    "- Verify that after TN1 and TN4 are back and VM1/VM8 are back, traffic"
    "  between VM1/VM8 and other VMs in the same logical network goes"
    "  through" .
    "  other VMs can continue." .
    "- Cleanup"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, ESXOnly, VxSTT, Reboot"
 AutomationLevel: "Automated"
 Developer: "salmanm"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y
 TestbedSpec: Functional_Topology_2
 WORKLOADS:
    Sequence:
        - ['CreateVMsVnics']
        - ['CreateTransportZone']
        - ['AddTransportNodesToTransportZone']
        - ['CreateLogicalSwitch']
        - ['CreateLogicalPort']
        - ['ChangeVnicBackingLogicalSwitch']
        - ['PoweronVM3', 'PoweronVM5', 'PoweronVM7', 'PoweronVM9']
        - ['PoweronVM4', 'PoweronVM6', 'PoweronVM8', 'PoweronVM10']
        - ['VerifyControlConnectivityOnHost']
        - ['VerifyReplicationModeOfLSwitch1OnHost',
           'VerifyReplicationModeOfLSwitch2OnHost']
        - ['ConfigureVnicIP']
        - ['ArpPingLS1', 'ArpPingLS2']
        - ['VerifyLS1ArpEntryOnControllers', 'VerifyLS2ArpEntryOnControllers']
        - ['VerifyMTEPOnHost', 'VerifyMacTableLSwitch1OnHost',
           'VerifyMacTableLSwitch2OnHost']
        - ['RebootTN3', 'RebootTN6']
        - ['PoweronVM3', 'PoweronVM9']
        - ['PoweronVM4', 'PoweronVM10']
        # XXX(Salman): Configuring IPs on the VMs again might not be mandatory.
        - ['ConfigureVM3Vnic1IP', 'ConfigureVM4Vnic1IP', 'ConfigureVM9Vnic1IP',
           'ConfigureVM10Vnic1IP']
        - ['VerifyPingVM3toVM579', 'VerifyPingVM10toVM468']
        - ['VerifyLS1ArpEntryOnControllers', 'VerifyLS2ArpEntryOnControllers']
        - ['VerifyMTEPOnHost', 'VerifyMacTableLSwitch1OnHost',
           'VerifyMacTableLSwitch2OnHost']
    ExitSequence:
        - ['PowerOffAllVMs']
        - ['DeleteVM3Vnic1InExitSeq', 'DeleteVM5Vnic1InExitSeq',
           'DeleteVM7Vnic1InExitSeq', 'DeleteVM9Vnic1InExitSeq']
        - ['DeleteVM4Vnic1InExitSeq', 'DeleteVM6Vnic1InExitSeq',
           'DeleteVM8Vnic1InExitSeq', 'DeleteVM10Vnic1InExitSeq']
        - ['CleanupNSX']

    PoweronVM3: *POWERON_VM3
    PoweronVM4: *POWERON_VM4
    PoweronVM5: *POWERON_VM5
    PoweronVM6: *POWERON_VM6
    PoweronVM7: *POWERON_VM7
    PoweronVM8: *POWERON_VM8
    PoweronVM9: *POWERON_VM9
    PoweronVM10: *POWERON_VM10
    ConfigureVM3Vnic1IP: *CONFIGURE_VM3_VNIC1_IP
    ConfigureVM4Vnic1IP: *CONFIGURE_VM4_VNIC1_IP
    ConfigureVM9Vnic1IP: *CONFIGURE_VM9_VNIC1_IP
    ConfigureVM10Vnic1IP: *CONFIGURE_VM10_VNIC1_IP
    PoweroffAllVMs: *POWEROFF_ALL_VM
    CleanupNSX: *CLEANUP_NSX

    CreateVMsVnics:
        Type: VM
        TestVM: vm.[3-10]
        vnic:
            [1]:
                driver: vmxnet3
                connected: 1
                startconnected: 1
                allowguestcontrol: 1
                external_uuid: 'auto'

    CreateTransportZone:
        Type: NSX
        TestNSX: nsxmanager.[1]
        transportzone:
            '[1]':
                name: autogenerate
                transportZoneType: 'overlay'

    AddTransportNodesToTransportZone:
        Type: NSX
        TestNSX: nsxmanager.[1]
        transportnode:
            '[3-6]':
                name: autogenerate
                hostId: esx.[x:vdnetindex:transportnode]
                hostSwitches:
                    # Opaque Switch ID.
                    - hostSwitchId:
                        esx.[x:vdnetindex:transportnode].nsxvswitch.[1]
                      uplink:
                        - deviceId:
                            esx.[x:vdnetindex:transportnode].vmnic.[1]
                    transportZoneEndPoints:
                        - transportZoneId: nsxmanager.[1].transportzone.[1]
                        # List of VTEPs.
                        vteps:
                            - ip: esx.[x:vdnetindex:transportnode].vtep.[1]
                              name: esx.[x:vdnetindex:transportnode].vtep.[1]

    CreateLogicalSwitch:
        Type: NSX
        TestNSX: nsxmanager.[1]
        logicalswitch:
            '[1]':
                name: LSwitch1
                transportZone: nsxmanager.[1].transportzone.[1]
                adminState: up
                replicationmode: mtep
            '[2]':
                name: LSwitch2
                transportZone: nsxmanager.[1].transportzone.[1]
                adminState: up
                replicationmode: source

    CreateLogicalPort:
        Type: NSX
        TestNSX: nsxmanager.[1]
        logicalport:
            '[3-10]':
                logicalSwitchId: nsxmanager.[1].logicalswitch.[x:mod:2]
                vif: vm.[x].vnic.[1]
                adminState: up

    ChangeVnicBackingLogicalSwitch:
        Type: NetAdapter
        TestAdapter: vm.[3-10].vnic.[1]
        network: nsxmanager.[1].logicalswitch.[x:mod:2]

    VerifyControlConnectivityOnHost
        Type: "Switch"
        TestSwitch: "nsxmanager.[1].logicalswitch.[-1]"
        controllerstatusonhosts: 'up'
        hosts: 'esx.[3-6]'

    ConfigureVnicIP:
        Type: NetAdapter
        TestAdapter: vm.[3-10].vnic.[1]
        IPv4: auto

    VerifyReplicationModeOfLSwitch1OnHost:
        Type: "Switch"
        testswitch: "nsxmanager.[1].logicalswitch.[1]"
        hosts: "esx.[3-6]"
        verifyreplicationmodeonhost:
            - 'replicationmode[?]match': 'mtep'

    VerifyReplicationModeOfLSwitch2OnHost:
        Type: "Switch"
        testswitch: "nsxmanager.[1].logicalswitch.[2]"
        hosts: "esx.[3-6]"
        verifyreplicationmodeonhost:
            - 'replicationmode[?]match': 'source'

    ArpPingLS1:
        Type: 'Traffic'
        toolName: 'ArpPing'
        TestAdapter   : "vm.[3].vnic.[1],vm.[5].vnic.[1],vm.[7].vnic.[1]"
        SupportAdapter: 'vm.[9].vnic.[1]'

    ArpPingLS2:
        Type: 'Traffic'
        toolName: 'ArpPing'
        TestAdapter: 'vm.[4].vnic.[1],vm.[6].vnic.[1],vm.[8].vnic.[1]'
        SupportAdapter: 'vm.[10].vnic.[1]'

    VerifyLS1ArpEntryOnControllers:
        Type: 'Switch'
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1]'
        controllers: 'nsxmanager.[1].nsxcontroller.[-1]'
        'VerifyArpEntryOnController[?]contain_once':
            - ip: "vm.[3].vnic.[1]"
              mac: "vm.[3].vnic.[1]"
            - ip: "vm.[5].vnic.[1]"
              mac: "vm.[5].vnic.[1]"
            - ip: "vm.[7].vnic.[1]"
              mac: "vm.[7].vnic.[1]"
            - ip: "vm.[9].vnic.[1]"
              mac: "vm.[9].vnic.[1]"

    VerifyLS2ArpEntryOnControllers:
        Type: 'Switch'
        TestSwitch: 'nsxmanager.[1].logicalswitch.[2]'
        controllers: 'nsxmanager.[1].nsxcontroller.[-1]'
        'VerifyArpEntryOnController[?]contain_once':
            - ip: "vm.[4].vnic.[1]"
              mac: "vm.[4].vnic.[1]"
            - ip: "vm.[6].vnic.[1]"
              mac: "vm.[6].vnic.[1]"
            - ip: "vm.[8].vnic.[1]"
              mac: "vm.[8].vnic.[1]"
            - ip: "vm.[10].vnic.[1]"
              mac: "vm.[10].vnic.[1]"

   VerifyMTEPOnHost:
        Type: "Switch"
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1]'
        checkmteponhost: 'esx.[3-6]'

    VerifyMacTableLSwitch1OnHost:
        Type: "Switch"
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1]'
        hosts: 'esx.[3-6]'
        'VerifyMacTableOnHost[?]contain_once':
            - inner_mac: "vm.[3].vnic.[1]"
              outer_ip: "esx.[3].vtep.[1]"
            - inner_mac: "vm.[5].vnic.[1]"
              outer_ip: "esx.[4].vtep.[1]"
            - inner_mac: "vm.[7].vnic.[1]"
              outer_ip: "esx.[5].vtep.[1]"

    VerifyMacTableLSwitch2OnHost:
        Type: "Switch"
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1-2]'
        hosts: 'esx.[3-6]'
        'VerifyMacTableOnHost[?]contain_once':
            - inner_mac: "vm.[4].vnic.[1]"
              outer_ip: "esx.[3].vtep.[1]"
            - inner_mac: "vm.[6].vnic.[1]"
              outer_ip: "esx.[4].vtep.[1]"
            - inner_mac: "vm.[8].vnic.[1]"
              outer_ip: "esx.[5].vtep.[1]"

    RebootTN3:
        Type: "Host"
        TestHost: "esx.[3]"
        reboot: "yes"
        sleepbetweenworkloads: 30

    RebootTN6:
        Type: "Host"
        TestHost: "esx.[6]"
        reboot: "yes"
        sleepbetweenworkloads: 30

    VerifyPingVM3toVM579:
        Type          : "Traffic"
        ToolName      : "netperf"
        L3Protocol    : "ipv4"
        L4Protocol    : "tcp"
        TestAdapter: 'vm.[3].vnic.[1],vm.[5].vnic.[1],vm.[].vnic.[1]'
        SupportAdapter: 'vm.[9].vnic.[1]'
        NoofOutbound  : "1"
        NoofInbound   : "1"
        TestDuration  : "5"

    VerifyPingVM10toVM468:
        Type          : "Traffic"
        ToolName      : "netperf"
        L3Protocol    : "ipv4"
        L4Protocol    : "tcp"
        TestAdapter: 'vm.[4].vnic.[1],vm.[6].vnic.[1],vm.[8].vnic.[1]'
        SupportAdapter: 'vm.[10].vnic.[1]'
        NoofOutbound  : "1"
        NoofInbound   : "1"
        TestDuration  : "5"

    DeleteVM3Vnic1InExitSeq: *DELETE_VM3_VNIC1_IN_EXIT_SEQ
    DeleteVM4Vnic1InExitSeq: *DELETE_VM4_VNIC1_IN_EXIT_SEQ
    DeleteVM5Vnic1InExitSeq: *DELETE_VM5_VNIC1_IN_EXIT_SEQ
    DeleteVM6Vnic1InExitSeq: *DELETE_VM6_VNIC1_IN_EXIT_SEQ
    DeleteVM7Vnic1InExitSeq: *DELETE_VM7_VNIC1_IN_EXIT_SEQ
    DeleteVM8Vnic1InExitSeq: *DELETE_VM8_VNIC1_IN_EXIT_SEQ
    DeleteVM9Vnic1InExitSeq: *DELETE_VM9_VNIC1_IN_EXIT_SEQ
    DeleteVM10Vnic1InExitSeq: *DELETE_VM10_VNIC1_IN_EXIT_SEQ


MTEPFuncTraffic:
 Product: "NSX"
 Category: "L2"
 Component: "Mgmt Application"
 TestName: "MTEPFuncTraffic"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: ""
 qcpath:
 Testbed:
 Summary: "To verify whether a VTEP chooses only one MTEP per segment and" .
          "sends traffic to only that MTEP."
 Procedure:
    "- Deploy MP" .
    "- Deploy CCP" .
    "- Install packages/vibs (LCP, MPA, DP) for 9 TNs" .
    "- Bootstrap TNs (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)" .
    "- Create 1 TZ, 3 segments.  Add TN3, TN4 and TN5 to segment 1," .
    "  TN7, TN8 and TN9 to segment 2, and TN10, TN11 and TN12 to segment3 " .
    "- Verify (using CLI) that TNs can talk to controllers" .
    "- Deploy 1 VM on each TN. VM3 in TN1, VM5 in TN2, etc" .
    "- Attach all VMs to LSwitch1 configured in MTEP-uc mode" .
    "- Verify switch replication mode on host."
    "- Generate unicast traffic between VMs such that all VTEPs are " .
    "  aware of other VTEPs" .
    "- Verify that CCP has correct correct VM_MAC<->VTEP_IP, " .
    "  VM_IP<->VM_MAC" .
    "- Verify MTEP table in each VTEP" .
    "- Disconnect CCP and wait for learned entries to timeout on hosts."
    "- Ping VM3 from VM19 to the LSwitch1 to generate BUM traffic" .
    "- Verify that VM1 sends traffic to only one TN in each segment." .
    "- Poweroff the MTEPs chosen in last step. Verify that TN3 selects"
    "  another TN as MTEP in that segment and send traffic to that TN"
    "  only." .
    "- Disconnect CCP cluster." .
    "- Let VM1 send BUM traffic to the VNI." .
    "- Verify that TN12 sends traffic to only one TN in each segment." .
    "- Cleanup"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, MTEP, ESXOnly, VxSTT"
 AutomationLevel: "Automated"
 Developer: "salmanm"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y
 TestbedSpec: Functional_Topology_4
 WORKLOADS:
    Sequence:
        - ['CreateVM3Vnic1', 'CreateVM5Vnic1', 'CreateVM7Vnic1',
           'CreateVM9Vnic1', 'CreateVM11Vnic1', 'CreateVM13Vnic1',
           'CreateVM15Vnic1', 'CreateVM17Vnic1', 'CreateVM19Vnic1']
        - ['CreateTransportZone']
        - ['AddTransportNodesToTransportZone']
        - ['CreateLogicalPort']
        - ['ChangeVM3Vnic1BackingLogicalSwitch',
           'ChangeVM5Vnic1BackingLogicalSwitch',
           'ChangeVM7Vnic1BackingLogicalSwitch',
           'ChangeVM9Vnic1BackingLogicalSwitch',
           'ChangeVM11Vnic1BackingLogicalSwitch',
           'ChangeVM13Vnic1BackingLogicalSwitch',
           'ChangeVM15Vnic1BackingLogicalSwitch',
           'ChangeVM17Vnic1BackingLogicalSwitch',
           'ChangeVM19Vnic1BackingLogicalSwitch']
        - ['PoweronVM3', 'PoweronVM5', 'PoweronVM7', 'PoweronVM9',
           'PoweronVM11', 'PoweronVM13', 'PoweronVM15',
           'PoweronVM17','PoweronVM19']
        - ['VerifyControlConnectivityOnHost']
        - ['VerifyReplicationModeOfLSwitch1OnHost']
        - ['ConfigureVM3Vnic1IP', 'ConfigureVM5Vnic1IP', 'ConfigureVM7Vnic1IP',
           'ConfigureVM9Vnic1IP', 'ConfigureVM11Vnic1IP', 'ConfigureVM13Vnic1IP',
           'ConfigureVM15Vnic1IP', 'ConfigureVM17Vnic1IP', 'ConfigureVM19Vnic1IP']
        - ['ArpPingLS1']
        - ['VerifyLS1ArpEntryOnControllers', 'VerifyMTEPOnHost',
           'VerifyMacTableLSwitch1OnHost']
        - ['DisconnectCCPAndWaitForEntriesTimeout']
        - ['ReadLSwitch1ReplicationInfoBeforeTrafficOnHost3']
        - ['VerifyPingVM3toVM19AndVerifyReplication']
        - ['PoweroffSelectedMTEPsAndWaitForEntriesTimeout']
        - ['ReadLSwitch1ReplicationInfoAfterPrimaryMTEPDownOnHost3']
        - ['VerifyPingVM3toVM19AndVerifyReplicationAfterPrimaryMTEPDown']
        - ['VerifyMTEPOnHostWithNewMTEPs', 'VerifyMacTableLSwitch1OnHost']
    ExitSequence:
        - ['PoweronSelectedMTEPs']
        - ['ConnectCCPInExitSeq']
        - ['PowerOffAllVMs']
        - ['DeleteVM3Vnic1InExitSeq', 'DeleteVM5Vnic1InExitSeq',
           'DeleteVM7Vnic1InExitSeq', 'DeleteVM9Vnic1InExitSeq',
           'DeleteVM11Vnic1InExitSeq', 'DeleteVM13Vnic1InExitSeq',
           'DeleteVM15Vnic1InExitSeq', 'DeleteVM17Vnic1InExitSeq',
           'DeleteVM19Vnic1InExitSeq']
        - ['CleanupNSX']

    CreateVM3Vnic1: *CREATE_VM3_VNIC1
    CreateVM5Vnic1: *CREATE_VM5_VNIC1
    CreateVM7Vnic1: *CREATE_VM7_VNIC1
    CreateVM9Vnic1: *CREATE_VM9_VNIC1
    CreateVM11Vnic1: *CREATE_VM11_VNIC1
    CreateVM13Vnic1: *CREATE_VM13_VNIC1
    CreateVM15Vnic1: *CREATE_VM15_VNIC1
    CreateVM17Vnic1: *CREATE_VM17_VNIC1
    CreateVM19Vnic1: *CREATE_VM19_VNIC1
    CreateLogicalPort3VM3LSwitch1: *CREATE_LOGICAL_PORT3_VM3_LSWITCH1
    CreateLogicalPort5VM5LSwitch1: *CREATE_LOGICAL_PORT5_VM5_LSWITCH1
    CreateLogicalPort7VM7LSwitch1: *CREATE_LOGICAL_PORT7_VM7_LSWITCH1
    CreateLogicalPort9VM9LSwitch1: *CREATE_LOGICAL_PORT9_VM9_LSWITCH1
    CreateLogicalPort11VM11LSwitch1: *CREATE_LOGICAL_PORT11_VM11_LSWITCH1
    CreateLogicalPort13VM13LSwitch1: *CREATE_LOGICAL_PORT13_VM13_LSWITCH1
    CreateLogicalPort15VM15LSwitch1: *CREATE_LOGICAL_PORT15_VM15_LSWITCH1
    CreateLogicalPort17VM17LSwitch1: *CREATE_LOGICAL_PORT17_VM17_LSWITCH1
    CreateLogicalPort19VM19LSwitch1: *CREATE_LOGICAL_PORT19_VM19_LSWITCH1
    PoweronVM3: *POWERON_VM3
    PoweronVM5: *POWERON_VM5
    PoweronVM7: *POWERON_VM7
    PoweronVM9: *POWERON_VM9
    PoweronVM11: *POWERON_VM11
    PoweronVM13: *POWERON_VM13
    PoweronVM15: *POWERON_VM15
    PoweronVM17: *POWERON_VM17
    PoweronVM19: *POWERON_VM19
    ChangeVM3Vnic1BackingLogicalSwitch1: *CHANGE_VM3_VNIC1_BACKING_LOGICAL_SWTICH1
    ChangeVM5Vnic1BackingLogicalSwitch1: *CHANGE_VM5_VNIC1_BACKING_LOGICAL_SWTICH1
    ChangeVM7Vnic1BackingLogicalSwitch1: *CHANGE_VM7_VNIC1_BACKING_LOGICAL_SWTICH1
    ChangeVM9Vnic1BackingLogicalSwitch1: *CHANGE_VM9_VNIC1_BACKING_LOGICAL_SWTICH1
    ChangeVM11Vnic1BackingLogicalSwitch1: *CHANGE_VM11_VNIC1_BACKING_LOGICAL_SWTICH1
    ChangeVM13Vnic1BackingLogicalSwitch1: *CHANGE_VM13_VNIC1_BACKING_LOGICAL_SWTICH1
    ChangeVM115Vnic1BackingLogicalSwitch1: *CHANGE_VM15_VNIC1_BACKING_LOGICAL_SWTICH1
    ChangeVM17Vnic1BackingLogicalSwitch1: *CHANGE_VM17_VNIC1_BACKING_LOGICAL_SWTICH1
    ChangeVM19Vnic1BackingLogicalSwitch1: *CHANGE_VM19_VNIC1_BACKING_LOGICAL_SWTICH1
    ConfigureVM3Vnic1IP: *CONFIGURE_VM3_VNIC1_IP
    ConfigureVM5Vnic1IP: *CONFIGURE_VM5_VNIC1_IP
    ConfigureVM7Vnic1IP: *CONFIGURE_VM7_VNIC1_IP
    ConfigureVM9Vnic1IP: *CONFIGURE_VM9_VNIC1_IP
    ConfigureVM11Vnic1IP: *CONFIGURE_VM11_VNIC1_IP
    ConfigureVM13Vnic1IP: *CONFIGURE_VM13_VNIC1_IP
    ConfigureVM15Vnic1IP: *CONFIGURE_VM15_VNIC1_IP
    ConfigureVM17Vnic1IP: *CONFIGURE_VM17_VNIC1_IP
    ConfigureVM19Vnic1IP: *CONFIGURE_VM19_VNIC1_IP
    DisconnectCCPAndWaitForEntriesTimeout: *DISCONNECT_CCP_WAIT_ENTRIES_TIMEOUT
    ConnectCCPInExitSeq: *CONNECT_CCP_IN_EXIT_SEQ
    PoweroffAllVMs: *POWEROFF_ALL_VM
    CleanupNSX: *CLEANUP_NSX

    CreateVMsVnics:
        Type: VM
        > TestVM: 'vm.[3],vm.[5],vm.[7],vm.[9],vm.[11],vm.[13],vm.[15],vm.[17]'
                  'vm.[19]'
        vnic:
            [1]:
                driver: vmxnet3
                connected: 1
                startconnected: 1
                allowguestcontrol: 1
                external_uuid: 'auto'

    CreateTransportZone:
        Type: NSX
        TestNSX: nsxmanager.[1]
        transportzone:
            '[1]':
                name: autogenerate
                transportZoneType: 'overlay'

    AddTransportNodesToTransportZone:
        Type: NSX
        TestNSX: nsxmanager.[1]
        transportnode:
            '[3-11]':
                name: autogenerate
                hostId: esx.[x:vdnetindex:transportnode]
                hostSwitches:
                    # Opaque Switch ID.
                    - hostSwitchId:
                        esx.[x:vdnetindex:transportnode].nsxvswitch.[1]
                      uplink:
                        - deviceId:
                            esx.[x:vdnetindex:transportnode].vmnic.[1]
                    transportZoneEndPoints:
                        - transportZoneId: nsxmanager.[1].transportzone.[1]
                        # List of VTEPs.
                        vteps:
                            - ip: esx.[x:vdnetindex:transportnode].vtep.[1]
                              name: esx.[x:vdnetindex:transportnode].vtep.[1]

    CreateLogicalSwitch:
        Type: NSX
        TestNSX: nsxmanager.[1]
        logicalswitch:
            '[1]':
                name: LSwitch1
                transportZone: nsxmanager.[1].transportzone.[1]
                adminState: up
                replicationmode: mtep

    VerifyControlConnectivityOnHost
        Type: "Switch"
        TestSwitch: "nsxmanager.[1].logicalswitch.[-1]"
        controllerstatusonhosts: 'up'
        hosts: 'esx.[3-11]'

    VerifyReplicationModeOfLSwitch1OnHost:
        Type: "Switch"
        testswitch: "nsxmanager.[1].logicalswitch.[1]"
        hosts: "esx.[3-11]"
        verifyreplicationmodeonhost:
            - 'replicationmode[?]match': 'mtep'

    ArpPingLS1:
        Type: 'Traffic'
        toolName: 'ArpPing'
        > TestAdapter   : "vm.[3].vnic.[1],vm.[5].vnic.[1],vm.[7].vnic.[1]"
                          "vm.[9].vnic.[1],vm.[11].vnic.[1],vm.[13].vnic.[1],"
                          "vm.[15].vnic.[1],vm.[17].vnic.[1],vm.[19]"
        SupportAdapter: 'vm.[19].vnic.[1]'

    VerifyLS1ArpEntryOnControllers:
        Type: 'Switch'
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1]'
        controllers: 'nsxmanager.[1].nsxcontroller.[-1]'
        'VerifyArpEntryOnController[?]contain_once':
            - ip: "vm.[3].vnic.[1]"
              mac: "vm.[3].vnic.[1]"
            - ip: "vm.[5].vnic.[1]"
              mac: "vm.[5].vnic.[1]"
            - ip: "vm.[7].vnic.[1]"
              mac: "vm.[7].vnic.[1]"
            - ip: "vm.[9].vnic.[1]"
              mac: "vm.[9].vnic.[1]"
            - ip: "vm.[11].vnic.[1]"
              mac: "vm.[11].vnic.[1]"
            - ip: "vm.[13].vnic.[1]"
              mac: "vm.[13].vnic.[1]"
            - ip: "vm.[15].vnic.[1]"
              mac: "vm.[15].vnic.[1]"
            - ip: "vm.[17].vnic.[1]"
              mac: "vm.[17].vnic.[1]"
            - ip: "vm.[19].vnic.[1]"
              mac: "vm.[19].vnic.[1]"

    VerifyMTEPOnHost:
        Type: "Switch"
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1]'
        checkmteponhost: 'esx.[3-11]'

    VerifyMacTableLSwitch1OnHost:
        Type: "Switch"
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1]'
        hosts: 'esx.[11]'
        'VerifyMacTableOnHost[?]contain_once':
            - inner_mac: "vm.[3].vnic.[1]"
              outer_ip: "esx.[3].vtep.[1]"
            - inner_mac: "vm.[5].vnic.[1]"
              outer_ip: "esx.[4].vtep.[1]"
            - inner_mac: "vm.[7].vnic.[1]"
              outer_ip: "esx.[5].vtep.[1]"
            - inner_mac: "vm.[9].vnic.[1]"
              outer_ip: "esx.[6].vtep.[1]"
            - inner_mac: "vm.[11].vnic.[1]"
              outer_ip: "esx.[7].vtep.[1]"
            - inner_mac: "vm.[13].vnic.[1]"
              outer_ip: "esx.[8].vtep.[1]"
            - inner_mac: "vm.[15].vnic.[1]"
              outer_ip: "esx.[9].vtep.[1]"
            - inner_mac: "vm.[17].vnic.[1]"
              outer_ip: "esx.[10].vtep.[1]"

    ReadLSwitch1ReplicationInfoBeforeTrafficOnHost3:
        Type: 'Switch'
        TestSwtich: "nsxmanager.[1].logicalswitch.[1]"
        host: 'esx.[3]'
        PersistData: Yes
        read:
        # TODO(Salman): Determine how the mtep hosts are managed here.
            'mtephosts[?]defined': ''
            'nonmtephosts[?]defined': ''

    ReadLSwitch1ReplicationInfoAfterPrimaryMTEPDownOnHost3:
        Type: 'Switch'
        TestSwtich: "nsxmanager.[1].logicalswitch.[1]"
        PersistData: Yes
        read:
        # TODO(Salman): Determine how the mtep hosts are managed here.
            'newmtephosts[?]defined': ''
            'newnonmtephosts[?]defined': ''

    VerifyPingVM3toVM19AndVerifyReplication:
        Type          : "Traffic"
        ToolName      : "netperf"
        L3Protocol    : "ipv4"
        L4Protocol    : "tcp"
        TestAdapter   : 'vm.[3].vnic.[1]'
        SupportAdapter: 'vm.[19].vnic.[1]'
        NoofOutbound  : "1"
        NoofInbound   : "1"
        TestDuration  : "10"
        verification  : "MTEPReplicatedARPLSwitch1"

    MTEPReplicatedARPLSwitch1:
        PktCapVerificaton:
        target: 'esx.[4-11]'
        > pktcapfilter: 'count 10,vxlan nsxmanager.[1].logicalswitch.[1],'
                        'flowdirection rx,capturestage post'
        verificationtype: 'pktcapuserworld'
        vxlanid: "nsxmanager.[1].logicalswitch.[1]"
        pktcount: '1'
        l3protocolheader: 'TBD'
        pkttype:  'unicast'
        tos:  '0x0'
        innerpkttype: 'broadcast'
        # TODO(Salman): Following keys need to be added.
        > replicationbithosts: 'nsxmanager.[1].logicalswitch.[1]->read->'
                               'mtephosts'
        > nonreplicationbithosts: 'nsxmanager.[1].logicalswitch.[1]->read->'
                                  'nonmtephosts'

    VerifyPingVM3toVM19AndVerifyReplicationAfterPrimaryMTEPDown:
        Type          : "Traffic"
        ToolName      : "netperf"
        L3Protocol    : "ipv4"
        L4Protocol    : "tcp"
        TestAdapter   : 'vm.[3].vnic.[1]'
        SupportAdapter: 'vm.[19].vnic.[1]'
        NoofOutbound  : "1"
        NoofInbound   : "1"
        TestDuration  : "10"
        verification  : "MTEPReplicatedARPLSwitch1AfterPrimaryMTEPDown"

    MTEPReplicatedARPLSwitch1AfterPrimaryMTEPDown:
        PktCapVerificaton:
        > target: 'nsxmanager.[1].logicalswitch.[1]->read->newmtephosts,'
                  'nsxmanager.[1].logicalswitch.[1]->read->newnonmtephosts'
        > pktcapfilter: 'count 10,vxlan nsxmanager.[1].logicalswitch.[1],'
                        'flowdirection rx,capturestage post'
        verificationtype: 'pktcapuserworld'
        vxlanid: "nsxmanager.[1].logicalswitch.[1]"
        pktcount: '1'
        l3protocolheader: 'TBD'
        pkttype:  'unicast'
        tos:  '0x0'
        innerpkttype: 'broadcast'
        # TODO(Salman): Following keys need to be added.
        > replicationbithosts: 'nsxmanager.[1].logicalswitch.[1]->read->'
                               'newmtephosts'
        > nonreplicationbithosts: 'nsxmanager.[1].logicalswitch.[1]->read->'
                                  'newnonmtephosts'

    PoweroffSelectedMTEPsAndWaitForEntriesTimeout:
        Type: "Host"
        TestHost: "nsxmanager.[1].logicalswitch.[1]->read->mtephosts"
        # TODO(Salman): Following key needs to be added.
        poweroff: "yes"
        sleepbetweenworkloads: 20

    VerifyMTEPOnHostWithNewMTEPs:
        Type: "Switch"
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1]'
        checkmteponhost: 'esx.[3-11]'
        # TODO(Salman): Following key needs to be added.
        'VerifyMTEPonHost[?]does_not_contain':
            hosts: "nsxmanager.[1].logicalswitch.[1]->read->mtephosts"

    PoweronSelectedMTEPs:
        Type: "Host"
        TestHost: "nsxmanager.[1].logicalswitch.[1]->read->mtephosts"
        # TODO(Salman): Following key needs to be added.
        poweron: "yes"

    DeleteVM3Vnic1InExitSeq: *DELETE_VM3_VNIC1_IN_EXIT_SEQ
    DeleteVM5Vnic1InExitSeq: *DELETE_VM5_VNIC1_IN_EXIT_SEQ
    DeleteVM7Vnic1InExitSeq: *DELETE_VM7_VNIC1_IN_EXIT_SEQ
    DeleteVM9Vnic1InExitSeq: *DELETE_VM9_VNIC1_IN_EXIT_SEQ
    DeleteVM11Vnic1InExitSeq: *DELETE_VM11_VNIC1_IN_EXIT_SEQ
    DeleteVM13Vnic1InExitSeq: *DELETE_VM13_VNIC1_IN_EXIT_SEQ
    DeleteVM15Vnic1InExitSeq: *DELETE_VM15_VNIC1_IN_EXIT_SEQ
    DeleteVM17Vnic1InExitSeq: *DELETE_VM17_VNIC1_IN_EXIT_SEQ
    DeleteVM19Vnic1InExitSeq: *DELETE_VM19_VNIC1_IN_EXIT_SEQ


SourceNodeReplication:
 Product: "NSX"
 Category: "L2"
 Component: "LCP-ESX"
 TestName: "SourceNodeReplication"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: "Functional"
 qcpath:
 Testbed:
 Summary: "To verify that a VM can reach another VM in a different physical" .
          "L2 segment, when source replication is being used."
 Procedure:
    "- Deploy MP." .
    "- Deploy CCP." .
    "- Install packages/vib (LCP, MPA, DP) for 4 TNs." .
    "- Bootstrap all TNs (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)." .
    "- Create 1 TZ, 2 segments, and add TN3 and TN4 to segment1, TN5 " .
    "  and TN6 to segment2." .
    "- Verify (using CLI) that TNs can talk to controllers" .
    "- Deploy 1 VM on each TN (VM3 on TN3, VM5 on TN4, VM7 on TN5 and " .
    "  VM9 on TN6)." .
    "- Attach all VMs to LSwitch1 which is configured in source-uc mode." .
    "- Verify switch replication mode on host."
    "- Generate unicast traffic between VMs such that all VTEPs are " .
    "  aware of other VTEPs" .
    "- Verify that CCP has correct correct VM_MAC<->VTEP_IP, " .
    "  VM_IP<->VM_MAC" .
    "- Disconnect CCP from the topology and wait for entries to timeout." .
    "- Verify VM3 can ping VM7 and that all TNs see the broadcasted traffic" .
    "- Verify VM9 can ping VM5 and that all TNs see the broadcasted traffic" .
    "- Cleanup"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, ESXOnly, Replication, VxSTT"
 AutomationLevel: "Automated"
 Developer: "salmanm"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y
 TestbedSpec: Functional_Topology_2
 WORKLOADS:
    Sequence:
        - ['CreateVM3Vnic1', 'CreateVM5Vnic1', 'CreateVM7Vnic1',
           'CreateVM9Vnic1']
        - ['CreateTransportZone']
        - ['AddTransportNodesToTransportZone']
        - ['CreateLogicalSwitch']
        - ['CreateLogicalPort']
        - ['CreateLogicalPort3VM3LSwitch1', 'CreateLogicalPort5VM5LSwitch1',
           'CreateLogicalPort7VM7LSwitch1', 'CreateLogicalPort9VM9LSwitch1']
        - ['ChangeVM3Vnic1BackingLogicalSwitch1',
           'ChangeVM5Vnic1BackingLogicalSwitch1',
           'ChangeVM7Vnic1BackingLogicalSwitch1',
           'ChangeVM9Vnic1BackingLogicalSwitch1']
        - ['PoweronVM3', 'PoweronVM5', 'PoweronVM7', 'PoweronVM9']
        - ['VerifyControlConnectivityOnHost']
        - ['VerifyReplicationModeOfLSwitch1OnHost']
        - ['ConfigureVM3Vnic1IP', 'ConfigureVM5Vnic1IP', 'ConfigureVM7Vnic1IP',
           'ConfigureVM9Vnic1IP']
        - ['ArpPingLS1']
        - ['VerifyLS1ArpEntryOnControllers']
        - ['VerifyMacTableLSwitch1OnHost']
        - ['DisconnectCCPAndWaitForEntriesTimeout']
        - ['VerifyPingVM3toVM7AndVerifyTrafficReplication',
           'VerifyPingVM9toVM5AndVerifyTrafficReplication']
        - ['VerifyMacTableLSwitch1OnHost3', 'VerifyMacTableLSwitch1OnHost6']
    ExitSequence:
        - ['PowerOffAllVMs']
        - ['ConnectCCPInExitSeq']
        - ['DeleteVM3Vnic1InExitSeq', 'DeleteVM5Vnic1InExitSeq',
           'DeleteVM7Vnic1InExitSeq', 'DeleteVM9Vnic1InExitSeq']
        - ['CleanupNSX']

    CreateVM3Vnic1: *CREATE_VM3_VNIC1
    CreateVM5Vnic1: *CREATE_VM5_VNIC1
    CreateVM7Vnic1: *CREATE_VM7_VNIC1
    CreateVM9Vnic1: *CREATE_VM9_VNIC1
    CreateLogicalPort3VM3LSwitch1: *CREATE_LOGICAL_PORT3_VM3_LSWITCH1
    CreateLogicalPort5VM5LSwitch1: *CREATE_LOGICAL_PORT5_VM5_LSWITCH1
    CreateLogicalPort7VM7LSwitch1: *CREATE_LOGICAL_PORT7_VM7_LSWITCH1
    CreateLogicalPort9VM9LSwitch1: *CREATE_LOGICAL_PORT9_VM9_LSWITCH1
    PoweronVM3: *POWERON_VM3
    PoweronVM5: *POWERON_VM5
    PoweronVM7: *POWERON_VM7
    PoweronVM9: *POWERON_VM9
    ChangeVM3Vnic1BackingLogicalSwitch1: *CHANGE_VM3_VNIC1_BACKING_LOGICAL_SWTICH1
    ChangeVM5Vnic1BackingLogicalSwitch1: *CHANGE_VM5_VNIC1_BACKING_LOGICAL_SWTICH1
    ChangeVM7Vnic1BackingLogicalSwitch1: *CHANGE_VM7_VNIC1_BACKING_LOGICAL_SWTICH1
    ChangeVM9Vnic1BackingLogicalSwitch1: *CHANGE_VM9_VNIC1_BACKING_LOGICAL_SWTICH1
    ConfigureVM3Vnic1IP: *CONFIGURE_VM3_VNIC1_IP
    ConfigureVM5Vnic1IP: *CONFIGURE_VM5_VNIC1_IP
    ConfigureVM7Vnic1IP: *CONFIGURE_VM7_VNIC1_IP
    ConfigureVM9Vnic1IP: *CONFIGURE_VM9_VNIC1_IP
    ConnectCCPInExitSeq: *CONNECT_CCP_IN_EXIT_SEQ
    DisconnectCCPAndWaitForEntriesTimeout: *DISCONNECT_CCP_WAIT_ENTRIES_TIMEOUT
    PoweroffAllVMs: *POWEROFF_ALL_VM
    CleanupNSX: *CLEANUP_NSX

    CreateTransportZone:
        Type: NSX
        TestNSX: nsxmanager.[1]
        transportzone:
            '[1]':
                name: autogenerate
                transportZoneType: 'overlay'

    AddTransportNodesToTransportZone:
        Type: NSX
        TestNSX: nsxmanager.[1]
        transportnode:
            '[3-6]':
                name: autogenerate
                hostId: esx.[x:vdnetindex:transportnode]
                hostSwitches:
                    # Opaque Switch ID.
                    - hostSwitchId:
                        esx.[x:vdnetindex:transportnode].nsxvswitch.[1]
                      uplink:
                        - deviceId:
                            esx.[x:vdnetindex:transportnode].vmnic.[1]
                    transportZoneEndPoints:
                        - transportZoneId: nsxmanager.[1].transportzone.[1]
                        # List of VTEPs.
                        vteps:
                            - ip: esx.[x:vdnetindex:transportnode].vtep.[1]
                              name: esx.[x:vdnetindex:transportnode].vtep.[1]

    CreateLogicalSwitch:
        Type: NSX
        TestNSX: nsxmanager.[1]
        logicalswitch:
            '[1]':
                name: LSwitch1
                transportZone: nsxmanager.[1].transportzone.[1]
                adminState: up
                replicationmode: 'source'

    VerifyControlConnectivityOnHost
        Type: "Switch"
        TestSwitch: "nsxmanager.[1].logicalswitch.[-1]"
        controllerstatusonhosts: 'up'
        hosts: 'esx.[3-6]'

    VerifyReplicationModeOfLSwitch1OnHost:
        Type: "Switch"
        testswitch: "nsxmanager.[1].logicalswitch.[1]"
        hosts: "esx.[3-6]"
        verifyreplicationmodeonhost:
            - 'replicationmode[?]match': 'source'

    ArpPingLS1:
        Type: 'Traffic'
        toolName: 'ArpPing'
        TestAdapter   : "vm.[3].vnic.[1],vm.[5].vnic.[1],vm.[7].vnic.[1]"
        SupportAdapter: 'vm.[9].vnic.[1]'

    VerifyPingVM3toVM7AndVerifyTrafficReplication:
        Type          : "Traffic"
        ToolName      : "netperf"
        L3Protocol    : "ipv4"
        L4Protocol    : "tcp"
        TestAdapter   : "vm.[7]"
        SupportAdapter: "vm.[3]"
        NoofOutbound  : "1"
        NoofInbound   : "1"
        TestDuration  : "10"
        verification  : "VerifyReplicationToOtherHostsFromHost3"
        sleepbetweenworkloads: 20

    VerifyReplicationToOtherHostsFromHost3:
        PktCapVerificaton:
        target: 'esx.[3],esx.[4],esx[6]'
        pktcapfilter: 'count 5,vxlan nsxmanager.[1].logicalswitch.[1],'
                      'flowdirection rx,capturestage post'
        verificationtype: 'pktcapuserworld'
        vxlanid: "nsxmanager.[1].logicalswitch.[1]"
        pktcount: '1'
        l3protocolheader: 'TBD'
        pkttype:  'unicast'
        tos:  '0x0'
        innerpkttype: 'broadcast'

    VerifyPingVM9toVM5AndVerifyTrafficReplication:
        Type          : "Traffic"
        ToolName      : "netperf"
        L3Protocol    : "ipv4"
        L4Protocol    : "tcp"
        TestAdapter   : "vm.[5]"
        SupportAdapter: "vm.[9]"
        NoofOutbound  : "1"
        NoofInbound   : "1"
        TestDuration  : "10"
        verification  : "VerifyReplicationToOtherHostsFromHost6"
        sleepbetweenworkloads: 20

    VerifyReplicationToOtherHostsFromHost6:
        PktCapVerificaton:
        target: 'esx.[3],esx.[4],esx[5]'
        pktcapfilter: 'count 5,vxlan nsxmanager.[1].logicalswitch.[1],'
                      'flowdirection rx,capturestage post'
        verificationtype: 'pktcapuserworld'
        vxlanid: "nsxmanager.[1].logicalswitch.[1]"
        pktcount: '1'
        l3protocolheader: 'TBD'
        pkttype:  'unicast'
        tos:  '0x0'
        innerpkttype: 'broadcast'

    VerifyLS1ArpEntryOnControllers:
        Type: 'Switch'
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1]'
        controllers: 'nsxmanager.[1].nsxcontroller.[-1]'
        'VerifyArpEntryOnController[?]contain_once':
            - ip: "vm.[3].vnic.[1]"
              mac: "vm.[3].vnic.[1]"
            - ip: "vm.[5].vnic.[1]"
              mac: "vm.[5].vnic.[1]"
            - ip: "vm.[7].vnic.[1]"
              mac: "vm.[7].vnic.[1]"
            - ip: "vm.[9].vnic.[1]"
              mac: "vm.[9].vnic.[1]"

    VerifyMacTableLSwitch1OnHost:
        Type: "Switch"
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1]'
        hosts: 'esx.[6]'
        'VerifyMacTableOnHost[?]contain_once':
            - inner_mac: "vm.[3].vnic.[1]"
              outer_ip: "esx.[3].vtep.[1]"
            - inner_mac: "vm.[5].vnic.[1]"
              outer_ip: "esx.[4].vtep.[1]"
            - inner_mac: "vm.[7].vnic.[1]"
              outer_ip: "esx.[5].vtep.[1]"

    VerifyMacTableLSwitch1OnHost3:
        Type: "Switch"
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1]'
        hosts: 'esx.[3]'
        'VerifyMacTableOnHost[?]contain_once':
            - inner_mac: "vm.[7].vnic.[1]"
              outer_ip: "esx.[5].vtep.[1]"

    VerifyMacTableLSwitch1OnHost6:
        Type: "Switch"
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1]'
        hosts: 'esx.[6]'
        'VerifyMacTableOnHost[?]contain_once':
            - inner_mac: "vm.[5].vnic.[1]"
              outer_ip: "esx.[4].vtep.[1]"

    DeleteVM3Vnic1InExitSeq: *DELETE_VM3_VNIC1_IN_EXIT_SEQ
    DeleteVM4Vnic1InExitSeq: *DELETE_VM4_VNIC1_IN_EXIT_SEQ
    DeleteVM5Vnic1InExitSeq: *DELETE_VM5_VNIC1_IN_EXIT_SEQ
    DeleteVM6Vnic1InExitSeq: *DELETE_VM6_VNIC1_IN_EXIT_SEQ
    DeleteVM7Vnic1InExitSeq: *DELETE_VM7_VNIC1_IN_EXIT_SEQ
    DeleteVM8Vnic1InExitSeq: *DELETE_VM8_VNIC1_IN_EXIT_SEQ
    DeleteVM9Vnic1InExitSeq: *DELETE_VM9_VNIC1_IN_EXIT_SEQ
    DeleteVM10Vnic1InExitSeq: *DELETE_VM10_VNIC1_IN_EXIT_SEQ

InteropQoS:
 Product: "NSX"
 Category: "L2"
 Component: "LCP-ESX"
 TestName: "InteropQoS"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: "Interop"
 qcpath:
 Testbed:
 Summary: "To verify whether the VTEP copies the QoS values (DSCP) from the" .
          "inner header to the outer VXLAN header."
 Procedure:
    "- Deploy MP" .
    "- Deploy CCP" .
    "- Install packege/vib (LCP, MPA, DP) for 4 TNs, TN3 and TN4 are in "
    "  segment 1, TN 5 and TN 6 are in segment 2," .
    "- Bootstrap TNs (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)" .
    "- Create a TZ" .
    "- Add TNs to a TZ" .
    "- Deploy 2 VMs on each TN (VM3-4 on TN3, VM5-6 on TN4, VM7-8 on TN5, " .
    "  and VM9-10 on TN6)" .
    "- Create LSwitch1 in the TZ, with replication method as MTEP-uc" .
    "- Create LSwitch2 in the TZ, with replication method as source-uc" .
    "- Attach first VM on each TN to LSwitch1 and the second VM on each TN " .
    "  to LSwitch2" .
    "- Verify whether TN's are able to connect to CCP, using cli " .
    "  commands" .
    "- Verify whether tunnels are established between VTEP's" .
    "- Verify whether replication method on TNs" .
    "- Generate Ping traffic in the logical domains" .
    "- Verify whether CCP shows proper VM_MAC<->VTEP_IP, " .
    "  VM_IP<->VM_MAC, etc, entries" .
    "- Each VM sends ping traffic to all other VMs" .
    "- Verify ARP enties on the CCP" .
    "- Verify ARP entris on the hosts" .
    "- Initiate traffic stream between VM3 and VM7, assign DSCP value " .
    "  to the packets." .
    "- Verify in TN5 that the packet received has outer DSCP value same as " .
    "  inner DSCP value" .
    "- Initiate traffic stream between VM4 and VM10, assign DSCP value to the " .
    "  packets." .
    "- Verify in TN6 that the packet received has outer DSCP value same as " .
    "  inner DSCP value" .
    "- Clean up"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, ESXOnly, QoS, Interop, VxSTT"
 AutomationLevel: "Automated"
 Developer: "salmanm"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y
 TestbedSpec: Functional_Topology_2
 WORKLOADS:
    Sequence:
        - ['CreateVMsVnics']
        - ['CreateTransportZone']
        - ['AddTransportNodesToTransportZone']
        - ['CreateLogicalSwitch']
        - ['CreateLogicalPort']
        - ['ChangeVnicBackingLogicalSwitch']
        - ['PoweronVM3', 'PoweronVM5', 'PoweronVM7', 'PoweronVM9']
        - ['PoweronVM4', 'PoweronVM6', 'PoweronVM8', 'PoweronVM10']
        - ['VerifyControlConnectivityOnHost', 'VerifyTunnelsOnnHost',
           'VerifyReplicationModeOfLSwitch1OnHost',
           'VerifyReplicationModeOfLSwitch2OnHost']
        - ['ConfigureVnicIP']
        - ['ArpPingLS1', 'ArpPingLS2']
        - ['VerifyLS1ArpEntryOnControllers', 'VerifyLS2ArpEntryOnControllers']
        - ['VerifyMTEPOnHost', 'VerifyMacTableLSwitch1OnHost',
           'VerifyMacTableLSwitch2OnHost']
        - ['VeriyfToSTrafficFromVM3toVM7', 'VeriyfToSTrafficFromVM4toVM10']
    ExitSequence:
        - ['PowerOffAllVMs']
        - ['DeleteVM3Vnic1InExitSeq', 'DeleteVM5Vnic1InExitSeq',
           'DeleteVM7Vnic1InExitSeq', 'DeleteVM9Vnic1InExitSeq']
        - ['DeleteVM4Vnic1InExitSeq', 'DeleteVM6Vnic1InExitSeq',
           'DeleteVM8Vnic1InExitSeq', 'DeleteVM10Vnic1InExitSeq']
        - ['CleanupNSX']

    PoweronVM3: *POWERON_VM3
    PoweronVM4: *POWERON_VM4
    PoweronVM5: *POWERON_VM5
    PoweronVM6: *POWERON_VM6
    PoweronVM7: *POWERON_VM7
    PoweronVM8: *POWERON_VM8
    PoweronVM9: *POWERON_VM9
    PoweronVM10: *POWERON_VM10
    PoweroffAllVMs: *POWEROFF_ALL_VM
    CleanupNSX: *CLEANUP_NSX

    CreateVMsVnics:
        Type: VM
        TestVM: vm.[3-10]
        vnic:
            [1]:
                driver: vmxnet3
                connected: 1
                startconnected: 1
                allowguestcontrol: 1
                external_uuid: 'auto'

    CreateTransportZone:
        Type: NSX
        TestNSX: nsxmanager.[1]
        transportzone:
            '[1]':
                name: autogenerate
                transportZoneType: 'overlay'

    AddTransportNodesToTransportZone:
        Type: NSX
        TestNSX: nsxmanager.[1]
        transportnode:
            '[3-6]':
                name: autogenerate
                hostId: esx.[x:vdnetindex:transportnode]
                hostSwitches:
                    # Opaque Switch ID.
                    - hostSwitchId:
                        esx.[x:vdnetindex:transportnode].nsxvswitch.[1]
                      uplink:
                        - deviceId:
                            esx.[x:vdnetindex:transportnode].vmnic.[1]
                    transportZoneEndPoints:
                        - transportZoneId: nsxmanager.[1].transportzone.[1]
                        # List of VTEPs.
                        vteps:
                            - ip: esx.[x:vdnetindex:transportnode].vtep.[1]
                              name: esx.[x:vdnetindex:transportnode].vtep.[1]

    CreateLogicalSwitch:
        Type: NSX
        TestNSX: nsxmanager.[1]
        logicalswitch:
            '[1]':
                name: LSwitch1
                transportZone: nsxmanager.[1].transportzone.[1]
                adminState: up
                replicationmode: mtep
            '[2]':
                name: LSwitch2
                transportZone: nsxmanager.[1].transportzone.[1]
                adminState: up
                replicationmode: source

    CreateLogicalPort:
        Type: NSX
        TestNSX: nsxmanager.[1]
        logicalport:
            '[3-10]':
                logicalSwitchId: nsxmanager.[1].logicalswitch.[x:mod:2]
                vif: vm.[x].vnic.[1]
                adminState: up

    ChangeVnicBackingLogicalSwitch:
        Type: NetAdapter
        TestAdapter: vm.[3-10].vnic.[1]
        network: nsxmanager.[1].logicalswitch.[x:mod:2]

    VerifyControlConnectivityOnHost
        Type: "Switch"
        TestSwitch: "nsxmanager.[1].logicalswitch.[-1]"
        controllerstatusonhosts: 'up'
        hosts: 'esx.[3-6]'

    VerifyTunnelsOnHost:
        Type: "Switch"
        TestSwitch: 'nsxmanager.[1].logicalswitch.[-1]'
        checktunnelsonhost: 'esx.[3-6]'

    ConfigureVnicIP:
        Type: NetAdapter
        TestAdapter: vm.[3-10].vnic.[1]
        IPv4: auto

    VerifyReplicationModeOfLSwitch1OnHost:
        Type: "Switch"
        testswitch: "nsxmanager.[1].logicalswitch.[1]"
        hosts: "esx.[3-6]"
        verifyreplicationmodeonhost:
            - 'replicationmode[?]match': 'mtep'

    VerifyReplicationModeOfLSwitch2OnHost:
        Type: "Switch"
        testswitch: "nsxmanager.[1].logicalswitch.[2]"
        hosts: "esx.[3-6]"
        verifyreplicationmodeonhost:
            - 'replicationmode[?]match': 'source'

    ArpPingLS1:
        Type: 'Traffic'
        toolName: 'ArpPing'
        TestAdapter   : "vm.[3].vnic.[1],vm.[5].vnic.[1],vm.[7].vnic.[1]"
        SupportAdapter: 'vm.[9].vnic.[1]'

    ArpPingLS2:
        Type: 'Traffic'
        toolName: 'ArpPing'
        TestAdapter: 'vm.[4].vnic.[1],vm.[6].vnic.[1],vm.[8].vnic.[1]'
        SupportAdapter: 'vm.[10].vnic.[1]'

    VerifyLS1ArpEntryOnControllers:
        Type: 'Switch'
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1]'
        controllers: 'nsxmanager.[1].nsxcontroller.[-1]'
        'VerifyArpEntryOnController[?]contain_once':
            - ip: "vm.[3].vnic.[1]"
              mac: "vm.[3].vnic.[1]"
            - ip: "vm.[5].vnic.[1]"
              mac: "vm.[5].vnic.[1]"
            - ip: "vm.[7].vnic.[1]"
              mac: "vm.[7].vnic.[1]"
            - ip: "vm.[9].vnic.[1]"
              mac: "vm.[9].vnic.[1]"

    VerifyLS2ArpEntryOnControllers:
        Type: 'Switch'
        TestSwitch: 'nsxmanager.[1].logicalswitch.[2]'
        controllers: 'nsxmanager.[1].nsxcontroller.[-1]'
        'VerifyArpEntryOnController[?]contain_once':
            - ip: "vm.[4].vnic.[1]"
              mac: "vm.[4].vnic.[1]"
            - ip: "vm.[6].vnic.[1]"
              mac: "vm.[6].vnic.[1]"
            - ip: "vm.[8].vnic.[1]"
              mac: "vm.[8].vnic.[1]"
            - ip: "vm.[10].vnic.[1]"
              mac: "vm.[10].vnic.[1]"

   VerifyMTEPOnHost:
        Type: "Switch"
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1]'
        checkmteponhost: 'esx.[3-6]'

    VerifyMacTableLSwitch1OnHost:
        Type: "Switch"
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1]'
        hosts: 'esx.[3-6]'
        'VerifyMacTableOnHost[?]contain_once':
            - inner_mac: "vm.[3].vnic.[1]"
              outer_ip: "esx.[3].vtep.[1]"
            - inner_mac: "vm.[5].vnic.[1]"
              outer_ip: "esx.[4].vtep.[1]"
            - inner_mac: "vm.[7].vnic.[1]"
              outer_ip: "esx.[5].vtep.[1]"

    VerifyMacTableLSwitch2OnHost:
        Type: "Switch"
        TestSwitch: 'nsxmanager.[1].logicalswitch.[1-2]'
        hosts: 'esx.[3-6]'
        'VerifyMacTableOnHost[?]contain_once':
            - inner_mac: "vm.[4].vnic.[1]"
              outer_ip: "esx.[3].vtep.[1]"
            - inner_mac: "vm.[6].vnic.[1]"
              outer_ip: "esx.[4].vtep.[1]"
            - inner_mac: "vm.[8].vnic.[1]"
              outer_ip: "esx.[5].vtep.[1]"

    VeriyfToSTrafficFromVM3toVM7:
        Type          : "Traffic"
        ToolName      : "netperf"
        L3Protocol    : "ipv4"
        L4Protocol    : "tcp"
        TestAdapter   : 'vm.[7].vnic.[1]'
        SupportAdapter: 'vm.[3].vnic.[1]'
        NoofOutbound  : "1"
        NoofInbound   : "1"
        TestDuration  : "10"
        # TODO(Salman): Implement the TOS key.
        tos: '0x02'
        verification  : "VerifyToSReplicatedOnHost5"

    VerifyToSReplicatedOnHost5:
        PktCapVerificaton:
        target: 'esx.[5]'
        pktcapfilter: 'count 15,vxlan nsxmanager.[1].logicalswitch.[1],'
                      'flowdirection rx,capturestage post'
        verificationtype: 'pktcapuserworld'
        vxlanid: "nsxmanager.[1].logicalswitch.[1]"
        pktcount: '10+'
        l3protocolheader: 'TBD'
        pkttype:  'unicast'
        tos:  '0x02'
        innerpkttype: 'unicast'
        innertos: '0x02'

    VeriyfToSTrafficFromVM4toVM10:
        Type          : "Traffic"
        ToolName      : "netperf"
        L3Protocol    : "ipv4"
        L4Protocol    : "tcp"
        TestAdapter   : 'vm.[10].vnic.[1]'
        SupportAdapter: 'vm.[4].vnic.[1]'
        NoofOutbound  : "1"
        NoofInbound   : "1"
        TestDuration  : "10"
        # TODO(Salman): Implement the TOS key.
        tos: '0x03'
        verification  : "VerifyToSReplicatedOnHost6"

    VerifyToSReplicatedOnHost5:
        PktCapVerificaton:
        target: 'esx.[6]'
        pktcapfilter: 'count 15,vxlan nsxmanager.[1].logicalswitch.[1],'
                      'flowdirection rx,capturestage post'
        verificationtype: 'pktcapuserworld'
        vxlanid: "nsxmanager.[1].logicalswitch.[2]"
        pktcount: '10+'
        l3protocolheader: 'TBD'
        pkttype:  'unicast'
        tos:  '0x03'
        innerpkttype: 'unicast'
        innertos: '0x03'

    DeleteVM3Vnic1InExitSeq: *DELETE_VM3_VNIC1_IN_EXIT_SEQ
    DeleteVM4Vnic1InExitSeq: *DELETE_VM4_VNIC1_IN_EXIT_SEQ
    DeleteVM5Vnic1InExitSeq: *DELETE_VM5_VNIC1_IN_EXIT_SEQ
    DeleteVM6Vnic1InExitSeq: *DELETE_VM6_VNIC1_IN_EXIT_SEQ
    DeleteVM7Vnic1InExitSeq: *DELETE_VM7_VNIC1_IN_EXIT_SEQ
    DeleteVM8Vnic1InExitSeq: *DELETE_VM8_VNIC1_IN_EXIT_SEQ
    DeleteVM9Vnic1InExitSeq: *DELETE_VM9_VNIC1_IN_EXIT_SEQ
    DeleteVM10Vnic1InExitSeq: *DELETE_VM10_VNIC1_IN_EXIT_SEQ

TsoOffloadOptions:
 Product: "NSX"
 Category: "L2"
 Component: "LCP-ESX"
 TestName: "TsoOffloadOptions"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: "Functional"
 qcpath:
 Testbed:
 Summary: "To verify that the network tso offload options are used when" .
          "enabled on the nic card for VxSTT frames as they appear to be TCP" .
          "packets"
 Procedure:
    "- Deploy MP" .
    "- Deploy CCP" .
    "- Install vib for 4 TNs (LCP, MPA, DP), TN1 and TN2 in segment 1, " .
    "  TN 3 and TN 4 in segment 2, TN1 and TN3 are ESX, TN2 and TN4 are KVM." .
    "- Bootstrap TNs (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)" .
    "- Create a TZ" .
    "- Add TNs to a TZ" .
    "- Deploy one VM on each TN (VM1 on TN1, VM2 on TN2, VM3 on TN3, " .
    "  and VM4 on TN4)" .
    "- Create LSwitch 5000 in the TZ, with replication method as MTEP" .
    "- Attach VIFs of all VM to LS 5000" .
    "- Assign static IP addresses to VMs" .
    "- Verify whether TN's are able to connect to CCP, using cli commands" .
    "- Verify whether replication method is shown as MTEP on TNs" .
    "- Verify whether CCP shows proper VM_MAC<->VTEP_IP, " .
    "  VM_IP<->VM_MAC, etc, entries" .
    "- Verify whether tunnels are established between VTEP's" .
    "- Each VM sends ping traffic to all other VMs" .
    "- Verify each VTEP has learned the IP-MAC mapping via ARP snooping." .
    "- Enable TSO options for all TNs." .
    "- Initiate netperf traffic stream between VM1 and VM3" .
    "- Capture traffic statistics." .
    "- Disable TSO options for all TNs." .
    "- Initiate netperf traffic stream between VM1 and VM3" .
    "- Capture traffic statistics." .
    "- Verify traffic throughput when TSO option is disabled is less than " .
    "  that when TSO option is enabled." .
    "- Enable TSO options for all TNs." .
    "- Initiate netperf traffic stream between VM2 and VM3" .
    "- Capture traffic statistics." .
    "- Disable TSO options for all TNs." .
    "- Initiate netperf traffic stream between VM2 and VM3" .
    "- Capture traffic statistics." .
    "- Verify traffic throughput when TSO option is disabled is less than " .
    "  that when TSO option is enabled." .
    "- Clean up"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, ESXOnly, TSO, VxSTT"
 AutomationLevel: "Automated"
 Developer: "mqing"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y


InteropActiveStandbyTeamingFailOver:
 Product: "NSX"
 Category: "L2"
 Component: "LCP-ESX"
 TestName: "InteropActiveStandbyTeamingFailOver"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: "Interop"
 qcpath:
 Testbed:
 Summary: "To verify the VTEPs functionality when one of the uplinks goes" .
          "down (in active standby/explicit failover)."
 Procedure:
    "- Deploy MP" .
    "- Deploy CCP" .
    "- Install vib for 4 TNs (LCP, MPA, DP), TN1 and TN2 in segment 1, " .
    "  TN 3 and TN 4 in segment 2, TN1 and TN2 are ESX, TN3 and TN4 are KVM." .
    "- TN1 and TN4 should have three uplinks." .
    "- Bootstrap TNs (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)" .
    "- Create a TZ and add all TNs to the TZ" .
    "- Deploy one VM on each TN (VM1 on TN1, VM2 on TN2, and etc)" .
    "- Create LSwitch 5000 in the TZ, with replication method as MTEP" .
    "- Attach VIFs of all VM to LS 5000" .
    "- Assign static IP addresses to VMs" .
    "- Verify whether TN's are able to connect to CCP, using cli commands" .
    "- Verify whether replication method is shown as MTEP on TNs" .
    "- Verify whether CCP shows proper VM_MAC<->VTEP_IP, VM_IP<->VM_MAC, etc, " .
    "  entries" .
    "- Verify whether tunnels are established between VTEP's" .
    "- Each VM sends ping traffic to all other VMs" .
    "- Verify each VTEP has learned the IP-MAC mapping via ARP snooping." .
    "- Configure TN1 uplinks in active-passive teaming mode." .
    "- VM1 generate unicast traffic and BUM traffic to other VMs, verify " .
    "  traffic can reach destination." .
    "- Bring down the active slave and verify that an VM to VM traffic still " .
    "  egresses/ingresses using one of the backup slaves." .
    "- Bring back the uplinks, verify the traffic does not go back to the " .
    "  original uplink and is not interrupted." .
    "- Bring down CCP cluster." .
    "- Bring down the active slave and verify that an VM to VM traffic still " .
    "  egresses/ingresses using one of the backup slaves." .
    "- Bring back the uplinks, verify the traffic does not go back to the " .
    "  original uplink and is not interrupted." .
    "- Configure TN4 uplinks in active-passive teaming mode." .
    "- VM4 generate unicast traffic and BUM traffic to other VMs, verify " .
    "  traffic can reach destination." .
    "- Bring down the active slave and verify that an VM to VM traffic still " .
    "  egresses/ingresses using one of the backup slaves." .
    "- Bring back the uplinks, verify the traffic does not go back to the " .
    "  original uplink and is not interrupted." .
    "- Bring down CCP cluster." .
    "- Bring down the active slave and verify that an VM to VM traffic still " .
    "  egresses/ingresses using one of the backup slaves." .
    "- Bring back the uplinks, verify the traffic does not go back to the " .
    "  original uplink and is not interrupted." .
    "- Cleanup"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, ESXOnly, Teaming, VxSTT"
 AutomationLevel: "Automated"
 Developer: "mqing"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y

VMPropertyUpdate:
 Product: "NSX"
 Category: "L2"
 Component: "LCP-ESX"
 TestName: "VMPropertyUpdate"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: "Sanity"
 qcpath:
 Testbed:
 Summary: "To verify whether controller updates all VTEPs about change in a" .
          "VM's property (IP/MAC changes)"
 Procedure:
    "- Deploy MP." .
    "- Deploy CCP." .
    "- Install vib for 4 TNs (LCP, MPA, DP), TN1 and TN2 are ESX, TN3 " .
    "  and TN4 are KVM." .
    "- Bootstrap the TNs (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)." .
    "- Create 1 TZ, 2 segment, and add TN1 and TN3 to segment1, TN2 and " .
    "  TN4 to segment2." .
    "- Verify whether TN's are able to connect to CCP, using cli commands" .
    "- Deploy 1 VM on each TN (VM1 on TN1, VM2 on TN2, and etc)." .
    "- Attach all VMs to LSwitch 5000 configured in MTEP-uc mode." .
    "- Assign static IP addresses to VMs" .
    "- Verify whether TN's are able to connect to CCP, using cli commands" .
    "- Verify whether replication method is shown as MTEP on TNs" .
    "- Verify whether CCP shows proper VM_MAC<->VTEP_IP, VM_IP<->VM_MAC, " .
    "  etc, entries" .
    "- Verify whether tunnels are established between VTEPs" .
    "- Each VM sends ping traffic to all other VMs" .
    "- Verify each VTEP has learned the IP-MAC mapping via ARP snooping." .
    "- Modify IP address of VM1 and send traffic to VM3 (VM on ESX)" .
    "- VM2 sends traffic to VM1’s new IP address, verify that TN2 can " .
    "  retrieve the IP-MAC mapping from controller (ESX)" .
    "- VM4 sends traffic to VM1’s new IP address, verify that TN4 already " .
    "  have the IP-MAC mapping from controller (KVM)" .
    "- Modify MAC address of VM2 and send traffic to VM4 (VM on ESX)" .
    "- VM1 sends traffic to VM2, verify that TN1 can retrieve the IP-MAC " .
    "  mapping from controller (ESX)" .
    "- VM3 sends traffic to VM2, verify that TN4 already have the IP-MAC " .
    "  mapping from controller (KVM)" .
    "- Modify IP address of VM3 and send traffic to VM1 (VM on KVM)" .
    "- VM2 sends traffic to VM3’s new IP address, verify that TN2 can " .
    "  retrieve the IP-MAC mapping from controller (ESX)" .
    "- VM4 sends traffic to VM3’s new IP address, verify that TN4 already " .
    "  have the IP-MAC mapping from controller (KVM)" .
    "- Modify MAC address of VM4 and send traffic to VM2 (VM on KVM)" .
    "- VM1 sends traffic to VM4, verify that TN1 can retrieve the IP-MAC " .
    "  mapping from controller (ESX)" .
    "- VM3 sends traffic to VM4, verify that TN3 already have the IP-MAC " .
    "  mapping from controller (KVM)" .
    "- Cleanup"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, ESXOnly, LCPtoCCP, VxSTT"
 AutomationLevel: "Automated"
 Developer: "mqing"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y

MultiplePacketSizes:
 Product: "NSX"
 Category: "L2"
 Component: "LCP-ESX"
 TestName: "MultiplePacketSizes"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: "MultiplePacketSizes"
 qcpath:
 Testbed:
 Summary: "To verify that the network doesn't drop packets if they are of" .
          "odd sizes (e.g. not a mulitple of 8, frame less than 64 bytes in" .
          "size and jumbo frames == 9k Bytes etc.)"
 Procedure:
    "- Deploy MP" .
    "- Deploy CCP" .
    "- Install vib for 4 TNs (LCP, MPA, DP), TN1 and TN2 in segment 1, " .
    "  TN 3 and TN 4 in segment 2, TN1 and TN3 are ESX, TN2 and TN4 are KVM." .
    "- Configure physical router interface to support jumbo frame." .
    "- Bootstrap TNs (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)" .
    "- Create a TZ and add all TNs to the TZ" .
    "- Deploy two VM on each TN (VM1 and VM2 on TN1, VM3 and VM4 on TN2, and " .
    "  etc)" .
    "- Create LSwitch 5000 in the TZ, with replication method as MTEP, and " .
    "  LSwitch5001 with replication method as source node based" .
    "- Attach VIFs of VM1, VM3, VM5 and VM7 to LS 5000, remaining VMs " .
    "  to LS5001" .
    "- Assign static IP addresses to VMs" .
    "- Verify whether TN's are able to connect to CCP, using cli commands" .
    "- Verify whether replication method is shown as MTEP on TNs" .
    "- Verify whether CCP shows proper VM_MAC<->VTEP_IP, VM_IP<->VM_MAC, etc, " .
    "  entries" .
    "- Verify whether tunnels are established between VTEP's" .
    "- Each VM sends ping traffic to all other VMs" .
    "- Verify each VTEP has learned the IP-MAC mapping via ARP snooping." .
    "- VM1 sends ICMP request ping packets of varying sizes to all the " .
    "  VMs in LS 5000" .
    "- Verify traffic can be delivered." .
    "- VM8 sends ICMP request ping packets of varying sizes to all the VMs in " .
    "  LS 5001" .
    "- Verify traffic can be delivered." .
    "- Cleanup"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, ESXOnly, VxSTT"
 AutomationLevel: "Automated"
 Developer: "mqing"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y

VTEPTrafficIPv6:
 Product: "NSX"
 Category: "L2"
 Component: "LCP-ESX"
 TestName: "VTEPTrafficIPv6"
 Version: "2"
 tcmsid:
 Priority: "P0"
 pmt:
 Testcaselevel: "Product"
 Testcasetype: "Functional"
 qcpath:
 Testbed:
 Summary: "To verify whether a VTEP considers the IPv6 traffic as BUM."
 Procedure:
    "- Deploy MP" .
    "- Deploy CCP" .
    "- Install vib for 4 TNs (LCP, MPA, DP), TN1 and TN2 in segment 1, " .
    "  TN 3 and TN 4 in segment 2, TN1 and TN2 are ESX, TN3 and TN4 are KVM." .
    "- Bootstrap TNs (opaqueDVS on ESX, vmknic for VTEP on ESX, " .
    "  bridge/bridge interface on KVM)" .
    "- Create a TZ and add all TNs to the TZ" .
    "- Deploy two VM on each TN (VM1 and VM2 on TN1, VM3 and VM4 on " .
    "  TN2, and etc)" .
    "- Create LSwitch 5000 in the TZ, with replication method as MTEP, " .
    "  and LSwitch5001 with replication method as source node based" .
    "- Attach VIFs of VM1, VM3, VM5 and VM7 to LS 5000, remaining VMs " .
    "  to LS5001" .
    "- Assign static IPv6 addresses to VMs" .
    "- Verify whether TN's are able to connect to CCP, using cli commands" .
    "- Verify whether replication method is shown as MTEP on TNs" .
    "- Verify whether CCP shows proper VM_MAC<->VTEP_IP, VM_IP<->VM_MAC, " .
    "  etc, entries" .
    "- Verify whether tunnels are established between VTEP's" .
    "- Each VM sends ping traffic to all other VMs" .
    "- Verify each VTEP has learned the IP-MAC mapping via ARP snooping." .
    "- VM1 sends ICMP request pingv6 unicast packets (both NDP and ping) to " .
    "  each VMs in LS 5000" .
    "- Verify traffic is transformed to BUM traffic and seen by all VTEPs." .
    "- VM8 sends ICMP request pingv6 unicast packets (both NDP and " .
    "  ping) to each VMs in LS 5001" .
    "- Verify traffic is transformed to BUM traffic and seen by all VTEPs." .
    "- Cleanup"
 ExpectedResult: "PASS"
 Duration:
 Tags: "NSX, L2, ESXOnly, Replication, VxSTT"
 AutomationLevel: "Automated"
 Developer: "mqing"
 FullAutomatable: Y
 Status: "Draft"
 PartnerFacing: Y
