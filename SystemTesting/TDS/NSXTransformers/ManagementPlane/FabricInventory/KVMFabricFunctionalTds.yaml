!include ../AAA/CommonWorkloads.yaml
!include ../Clustering/MPCommonWorkloads.yaml
!include CommonWorkloads.yaml
!include TestbedSpec.yaml

KVMRegisterNodeInvalidPassword:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies nsxcli returns correct error code if password is incorrect while registering hostnode in KVM"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "KVMRegisterNodeInvalidPassword"
    Priority: "P2"
    Developer: "kchakraborty"
    Procedure: '1. Register a Fabric Host to inventory with incorrect password'
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_KVM_ONE_VM
    WORKLOADS:
        Sequence:
            - ['RegisterKvm1WithInvalidPassword']

        RegisterKvm1WithInvalidPassword: *REGISTER_NODE_WITH_INVALID_PASSWORD--KVM

KVMRegisterNodeInvalidThumbprint:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies nsxcli returns correct error code if Manager Thumbprint is
    incorrect while registering hostnode in KVM"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "KVMRegisterNodeInvalidThumbprint"
    Priority: "P2"
    Developer: "kchakraborty"
    Procedure: '1. Deregister a Fabric Host to inventory with Invalid Thumbprint'
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_KVM_ONE_VM
    WORKLOADS:
        Sequence:
            - ['RegisterKvm1WithInvalidThumbprint']

        RegisterKvm1WithInvalidThumbprint: *REGISTER_NODE_WITH_INVALID_THUMBPRINT--KVM

KVMRegisterNodeInvalidUser:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies nsxcli returns correct error code if user is incorrect
    while registering hostnode in KVM"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "KVMRegisterNodeInvalidUser"
    Priority: "P2"
    Developer: "kchakraborty"
    Procedure: '1. Deregister a Fabric Host to inventory with Invalid User'
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_KVM_ONE_VM
    WORKLOADS:
        Sequence:
            - ['RegisterKvm1WithInvalidUser']

        RegisterKvm1WithInvalidUser: *REGISTER_NODE_WITH_INVALID_USER--KVM

KVMRegisterNodeUnreachableManager:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies nsxcli returns correct error code if Manager is unreachable while registering hostnode in KVM"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "KVMRegisterNodeUnreachableManager"
    Priority: "P2"
    Developer: "kchakraborty"
    Procedure: '1. Deregister a Fabric Host to inventory with Unreachable Manager'
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_KVM_ONE_VM
    WORKLOADS:
        Sequence:
            - ['RegisterKvm1WithUnreachableManager']

        RegisterKvm1WithUnreachableManager: *REGISTER_NODE_WITH_UNREACHABLE_MANAGER--KVM

KVMDeregisterNodeInvalidPassword:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies nsxcli returns correct error code if password is incorrect"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "KVMDeregisterNodeInvalidPassword"
    Priority: "P2"
    Developer: "kchakraborty"
    Procedure: '1. Deregister a Fabric Host to inventory with incorrect password'
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_KVM_ONE_VM
    WORKLOADS:
        Sequence:
            - ['SetManagerOnKVM1']
            - ['DeregisterKvm1WithInvalidPassword']
        ExitSequence:
            - ['RemoveNSXManagerOnKVM1']

        SetManagerOnKVM1: *SET_MANAGER--KVM
        DeregisterKvm1WithInvalidPassword: *DEREGISTER_NODE_WITH_INVALID_PASSWORD--KVM
        RemoveNSXManagerOnKVM1: *REMOVE_NSX_MANAGER--KVM

KVMDeregisterNodeInvalidThumbprint:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies nsxcli returns correct error code if Manager Thumbprint is incorrect while deregistering hostnode in KVM"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "KVMDeregisterNodeInvalidThumbprint"
    Priority: "P2"
    Developer: "kchakraborty"
    Procedure: '1. Deregister a Fabric Host to inventory with invalid thumbprint '
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_KVM_ONE_VM
    WORKLOADS:
        Sequence:
            - ['SetManagerOnKVM1']
            - ['DeregisterKVM1WithInvalidThumbprint']
        ExitSequence:
            - ['RemoveNSXManagerOnKVM1']

        SetManagerOnKVM1: *SET_MANAGER--KVM
        DeregisterKVM1WithInvalidThumbprint: *DEREGISTER_NODE_WITH_INVALID_THUMBPRINT--KVM
        RemoveNSXManagerOnKVM1: *REMOVE_NSX_MANAGER--KVM

KVMDeregisterNodeInvalidUser:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies nsxcli returns correct error code if user is incorrect
    while deregistering hostnode in KVM"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "KVMDeregisterNodeInvalidUser"
    Priority: "P2"
    Developer: "kchakraborty"
    Procedure: '1. Deregister a Fabric Host to inventory with invalid user'
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_KVM_ONE_VM
    WORKLOADS:
        Sequence:
            - ['SetManagerOnKVM1']
            - ['DeregisterKVM1WithInvalidUser']
        ExitSequence:
            - ['RemoveNSXManagerOnKVM1']

        SetManagerOnKVM1: *SET_MANAGER--KVM
        DeregisterKVM1WithInvalidUser: *DEREGISTER_NODE_WITH_INVALID_USER--KVM
        RemoveNSXManagerOnKVM1: *REMOVE_NSX_MANAGER--KVM

KVMDeregisterNodeUnreachableManager:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies nsxcli returns correct error code if Manager is unreachable
    while deregistering hostnode in KVM"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "KVMDeregisterNodeUnreachableManager"
    Priority: "P2"
    Developer: "kchakraborty"
    Procedure: '1. Deregister a Fabric Host to inventory with Unreachable Manager'
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_KVM_ONE_VM
    WORKLOADS:
        Sequence:
            - ['SetManagerOnKVM1']
            - ['DeregisterKVM1WithUnreachableManager']
        ExitSequence:
            - ['RemoveNSXManagerOnKVM1']

        SetManagerOnKVM1: *SET_MANAGER--KVM
        DeregisterKVM1WithUnreachableManager: *DEREGISTER_NODE_WITH_UNREACHABLE_MANAGER--KVM
        RemoveNSXManagerOnKVM1: *REMOVE_NSX_MANAGER--KVM

KVMRegisterDeregisterHostNodeTacacasUser:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies nsxcli can regsiter and deregsiter node using Tacacas User in KVM"
    Tags: nsx,avalanche,cat
    Version: "2"
    TestName: "KVMRegisterDeregisterHostNodeTacacasUser"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Priority: "P2"
    Developer: "kchakraborty"
    Procedure: '1. Register an KVM host using Tacacs Server Credential
                2. Deregister an KVM host using Tacacs Server Credential'
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_KVM_ONE_VM
    WORKLOADS:
        <<: *AAA_WORKLOADS
        <<: *INVENTORY_WORKLOADS
        Sequence:
            - ["SetAAAId"]
            - ["UpdateProviderList"]
            - ["StopAuthServer"]
            - ["BackupDefaultConfig"]
            - ["AddUser"]
            - ["StartAuthServer"]
            - ["RegisterNodeWithTacacsUserKVM"]
        ExitSequence:
            - ["DeregisterNodeWithTacacsUserKVM"]
            - ["StopAuthServer"]
            - ["RestoreDefaultConfig"]
            - ["StartAuthServer"]

        RegisterNodeWithTacacsUserKVM: *REGISTER_NODE_WITH_TACACS_USER--KVM
        DeregisterNodeWithTacacsUserKVM: *DEREGISTER_NODE_WITH_TACACS_USER--KVM

KVMMPNodeGracefullyShutdown:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Semi-Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,Inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "KVMMPNodeGracefullyShutdown"
    Summary: 'Verify KVM is shifted to new MP master and able to send inventory
              updates'
    Procedure: '1. Register all 3 NSXManager
                2. Discover host node on all 3 KVM
                3. Get VM1 ID
                4. Power-off NSXManager 1
                5. Deploy 4th VM on KVM1
                6. Add Vif on VM4
                7. Get VM4 ID from NSXManager 2 and 3
                8. Get VM4 Vif from NSXManager 2 and 3'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
            - - RegisterHostNode1ToManager1
              - RegisterHostNode2ToManager2
              - RegisterHostNode3ToManager3
            - - DiscoverHostNodes
            - - GetVm1Id
            - - PowerOffManager1
            - - AddVm4OnKVM1
            - - AddVif1VM4
            - - GetVm4IdFromManager2
              - GetVm4IdFromManager3
            - - GetVif1OfVM4FromManager2
              - GetVif1OfVM4FromManager3
        ExitSequence:
            - - PowerOnManager1
              - DeleteVM4
            - - RemoveNSXManager3OnNode3
              - RemoveNSXManager2OnNode2
              - RemoveNSXManager1OnNode1

        RegisterHostNode1ToManager1: *SET_MANAGER--KVM
        RegisterHostNode2ToManager2: *SET_MANAGER2_ON_NODE2--KVM
        RegisterHostNode3ToManager3: *SET_MANAGER3_ON_NODE3--KVM
        DiscoverHostNodes: *DISCOVER_HOST_NODES--KVM
        GetVm1Id: *GET_VM1_ID
        PowerOffManager1: *POWER_OFF_MANAGER1
        AddVm4OnKVM1: *ADD_VM4_ON_HOST1--KVM
        AddVif1VM4:
          <<: *ADD_VIF1_TO_VM1
          TestVM: 'vm.[4]'
        GetVm4IdFromManager2:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[2]"
        GetVm4IdFromManager3:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[3]"
        GetVif1OfVM4FromManager2:
          <<: *GET_VIF1_OF_VM1_ON_KVM
          TestNSX: "nsxmanager.[2]"
          fabricvif:
              '[4]':
               discover: 'true'
               adapter_mac: 'vm.[4].vif.[1]'
        GetVif1OfVM4FromManager3:
          <<: *GET_VIF1_OF_VM1_ON_KVM
          TestNSX: "nsxmanager.[3]"
          fabricvif:
              '[4]':
               discover: 'true'
               adapter_mac: 'vm.[4].vif.[1]'
        PowerOnManager1: *POWER_ON_MANAGER1
        DeleteVM4:
          <<: *DELETE_VM
          deletevm: vm.[4]
          sleepbetweenworkloads: 120
        RemoveNSXManager1OnNode1: *REMOVE_NSX_MANAGER--KVM
        RemoveNSXManager2OnNode2: *REMOVE_NSX_MANAGER2_ON_NODE2--KVM
        RemoveNSXManager3OnNode3: *REMOVE_NSX_MANAGER3_ON_NODE3--KVM

KVMRestartMPAIn3NodeCluster:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Semi-Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,Inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "KVMRestartMPAIn3NodeCluster"
    Summary: 'This test case verifies inventory updates are working fine in 3 node MP cluster
    scenario after MPA service restart'
    Procedure: '1. Register all 3 NSXManager
                2. Discover host node on all 3 KVM
                3. Get VM1 ID
                4. Stop MPA on KVM1
                5. Deploy 4th VM on KVM1
                6. Add Vif on VM4
                7. Start MPA on KVM1
                8. Get VM4 ID and Vif from all 3 NSXManager
                9. Revert the changes as part of Exit sequence'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
            - ["RegisterHostNode1ToManager1"]
            - ["RegisterHostNode2ToManager2"]
            - ["RegisterHostNode3ToManager3"]
            - ['DiscoverHostNodes']
            - ['GetVm1Id']
            - ['StopMPAOnKVM1']
            - ['AddVm4OnKVM1']
            - ['AddVif1VM4']
            - ['StartMPAOnKVM1']
            - ['GetVm4IdFromManager1']
            - ['GetVm4IdFromManager2']
            - ['GetVm4IdFromManager3']
            - ['GetVif1OfVM4FromManager1']
            - ['GetVif1OfVM4FromManager2']
            - ['GetVif1OfVM4FromManager3']
        ExitSequence:
            - ["DeleteVM4"]
            - ["RemoveNSXManager3OnNode3"]
            - ["RemoveNSXManager2OnNode2"]
            - ["RemoveNSXManager1OnNode1"]

        RegisterHostNode1ToManager1: *SET_MANAGER--KVM
        RegisterHostNode2ToManager2: *SET_MANAGER2_ON_NODE2--KVM
        RegisterHostNode3ToManager3: *SET_MANAGER3_ON_NODE3--KVM
        DiscoverHostNodes: *DISCOVER_HOST_NODES--KVM
        GetVm1Id: *GET_VM1_ID
        StopMPAOnKVM1: *STOP_MPA--KVM
        AddVm4OnKVM1: *ADD_VM4_ON_HOST1--KVM
        AddVif1VM4:
          <<: *ADD_VIF1_TO_VM1
          TestVM: 'vm.[4]'
        StartMPAOnKVM1: *START_MPA--KVM
        GetVm4IdFromManager1: *GET_VM4ID_FROM_MANAGER1
        GetVm4IdFromManager2:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[2]"
        GetVm4IdFromManager3:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[3]"
        GetVif1OfVM4FromManager1:
          <<: *GET_VIF1_OF_VM1_ON_KVM
          TestNSX: "nsxmanager.[1]"
          fabricvif:
              '[4]':
                  discover: 'true'
                  adapter_mac: 'vm.[4].vif.[1]'
        GetVif1OfVM4FromManager2:
          <<: *GET_VIF1_OF_VM1_ON_KVM
          TestNSX: "nsxmanager.[2]"
          fabricvif:
              '[4]':
                  discover: 'true'
                  adapter_mac: 'vm.[4].vif.[1]'
        GetVif1OfVM4FromManager3:
          <<: *GET_VIF1_OF_VM1_ON_KVM
          TestNSX: "nsxmanager.[3]"
          fabricvif:
              '[4]':
                  discover: 'true'
                  adapter_mac: 'vm.[4].vif.[1]'
        DeleteVM4:
          <<: *DELETE_VM
          deletevm: vm.[4]
        RemoveNSXManager1OnNode1: *REMOVE_NSX_MANAGER--KVM
        RemoveNSXManager2OnNode2: *REMOVE_NSX_MANAGER2_ON_NODE2--KVM
        RemoveNSXManager3OnNode3: *REMOVE_NSX_MANAGER3_ON_NODE3--KVM

KVMAddMultipleHostsToMPNode:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Semi-Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,Inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "KVMAddMultipleHostsToMPNode"
    Summary: 'This test case verifies inventory updates are working fine in
              3 KVM host registered with single node MP scenario'
    Procedure: '1. Register 3 KVM host with NSXManager1
                2. Discover all 3 host node
                3. Get VM1, VM2 and VM3 ID
                4. Deploy VM4, VM5 and VM6 on KVM1, KVM2 and KVM3 respectively
                5. Add Vif on VM4, VM5 and VM6
                6. Get VM4, VM5 and VM6 ID and Vif from NSXManager'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
            - ["RegisterHostNode1OnManager1"]
            - ["RegisterHostNode2OnManager1"]
            - ["RegisterHostNode3OnManager1"]
            - ['DiscoverHostNodes']
            - ['GetVm1Id']
            - ['GetVm2Id']
            - ['GetVm3Id']
            - ['AddVm4OnKVM1']
            - ['AddVm5OnKVM2']
            - ['AddVm6OnKVM3']
            - ["AddVif1VM4"]
            - ["AddVif1VM5"]
            - ["AddVif1VM6"]
            - ['GetVm4IdFromManager1']
            - ['GetVm5IdFromManager1']
            - ['GetVm6IdFromManager1']
            - ['GetVif1OfVM4FromManager1']
            - ['GetVif1OfVM5FromManager1']
            - ['GetVif1OfVM6FromManager1']
        ExitSequence:
            - ["DeleteVM4",
               "DeleteVM5",
               "DeleteVM6"]
            - ["DeregisterHostNode1FromManager1",
               "DeregisterHostNode2FromManager1",
               "DeregisterHostNode3FromManager1"]

        RegisterHostNode1OnManager1: *SET_MANAGER--KVM
        RegisterHostNode2OnManager1:
            Type: Host
            TestHost: 'kvm.[2]'
            set_nsx_manager:
                manager_ip: 'nsxmanager.[1]'
                execution_type: 'cli'
                manager_thumbprint: 'nsxmanager.[1]'
        RegisterHostNode3OnManager1:
            Type: Host
            TestHost: 'kvm.[3]'
            set_nsx_manager:
                manager_ip: 'nsxmanager.[1]'
                execution_type: 'cli'
                manager_thumbprint: 'nsxmanager.[1]'
        DiscoverHostNodes: *DISCOVER_HOST_NODES--KVM
        GetVm1Id: *GET_VM1_ID
        GetVm2Id:
          <<: *GET_VM1_ID
          fabricvm:
              '[2]':
                  discover: 'true'
                  name: 'vm.[2]'
        GetVm3Id:
          <<: *GET_VM1_ID
          fabricvm:
              '[3]':
                  discover: 'true'
                  name: 'vm.[3]'
        AddVm4OnKVM1:
          <<: *ADD_VM1_ON_HOST1--KVM
          vm:
            '[4]':
                template: 'template_kvm_debian'
                vmstate: 'poweron'
                host: 'kvm.[1]'
                installtype: fullclone
        AddVm5OnKVM2:
          <<: *ADD_VM1_ON_HOST1--KVM
          vm:
            '[5]':
                template: 'template_kvm_debian'
                vmstate: 'poweron'
                host: 'kvm.[2]'
                installtype: fullclone
        AddVm6OnKVM3:
          <<: *ADD_VM1_ON_HOST1--KVM
          vm:
            '[6]':
                template: 'template_kvm_debian'
                vmstate: 'poweron'
                host: 'kvm.[3]'
                installtype: fullclone
        AddVif1VM4:
          <<: *ADD_VIF1_TO_VM1
          TestVM: 'vm.[4]'
          vif:
              '[4]':
                  backing: 'kvm.[1].bridge.[1]'
        AddVif1VM5:
          <<: *ADD_VIF1_TO_VM1
          TestVM: 'vm.[5]'
          vif:
              '[5]':
                  backing: 'kvm.[2].bridge.[1]'
        AddVif1VM6:
          <<: *ADD_VIF1_TO_VM1
          TestVM: 'vm.[6]'
          vif:
              '[6]':
                  backing: 'kvm.[3].bridge.[1]'
        GetVm4IdFromManager1:
          <<: *GET_VM1_ID
          fabricvm:
              '[4]':
                  discover: 'true'
                  name: 'vm.[4]'
        GetVm5IdFromManager1:
          <<: *GET_VM1_ID
          fabricvm:
              '[5]':
                  discover: 'true'
                  name: 'vm.[5]'
        GetVm6IdFromManager1:
          <<: *GET_VM1_ID
          fabricvm:
              '[6]':
                  discover: 'true'
                  name: 'vm.[6]'
        GetVif1OfVM4FromManager1:
          <<: *GET_VIF1_OF_VM1_ON_KVM
          TestNSX: "nsxmanager.[1]"
          fabricvif:
              '[4]':
                  discover: 'true'
                  adapter_mac: 'vm.[4].vif.[4]'
        GetVif1OfVM5FromManager1:
          <<: *GET_VIF1_OF_VM1_ON_KVM
          fabricvif:
              '[5]':
                  discover: 'true'
                  adapter_mac: 'vm.[5].vif.[5]'
        GetVif1OfVM6FromManager1:
          <<: *GET_VIF1_OF_VM1_ON_KVM
          fabricvif:
              '[6]':
                  discover: 'true'
                  adapter_mac: 'vm.[6].vif.[6]'
        DeleteVM4:
          <<: *DELETE_VM
          deletevm: vm.[4]
        DeleteVM5:
          <<: *DELETE_VM
          deletevm: vm.[5]
        DeleteVM6:
          <<: *DELETE_VM
          deletevm: vm.[6]
        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--KVM
        DeregisterHostNode2FromManager1:
          <<: *REMOVE_NSX_MANAGER--KVM
          TestHost: 'kvm.[2]'
        DeregisterHostNode3FromManager1:
          <<: *REMOVE_NSX_MANAGER--KVM
          TestHost: 'kvm.[3]'

KVMMpnodeWithoutAnyHostInventoryUpdatePostReboot:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Semi-Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,Inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "KVMMpnodeWithoutAnyHostInventoryUpdatePostReboot"
    Summary: 'This test case verifies an mp node which does not have own inventory is able to fetch inventory of others post MP Node reboot'
    Procedure: '1. Register 2 KVM host with NSXManager
                2. Discover all 2 host node
                3. Get VM1 ID
                4. Reboot Nasxmanager 3
                5. Deploy VM4 on KVM1
                6. Get VM4 ID from all NSXManager'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        <<: *MPClusteringVerificationWorkloads
        Sequence:
            - ["RegisterHostNode1ToManager1"]
            - ["RegisterHostNode2ToManager2"]
            - ['DiscoverHostNode1']
            - ['DiscoverHostNode2']
            - ['GetVm1Id']
            - ['Reboot_Node3_CLI']
            - ['AddVm4OnKVM1']
            - ['GetVm4IdFromManager1']
            - ['GetVm4IdFromManager2']
            - ['GetVm4IdFromManager3']
        ExitSequence:
            - ["DeleteVM4"]
            - ["RemoveNSXManager2OnNode2"]
            - ["RemoveNSXManager1OnNode1"]

        RegisterHostNode1ToManager1: *SET_MANAGER--KVM
        RegisterHostNode2ToManager2: *SET_MANAGER2_ON_NODE2--KVM
        DiscoverHostNode1: *DISCOVER_HOST_NODE1--KVM
        DiscoverHostNode2: *DISCOVER_HOST_NODE2--KVM
        GetVm1Id: *GET_VM1_ID
        AddVm4OnKVM1: *ADD_VM4_ON_HOST1--KVM
        GetVm4IdFromManager1: *GET_VM4ID_FROM_MANAGER1
        GetVm4IdFromManager2:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[2]"
        GetVm4IdFromManager3:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[3]"
        DeleteVM4:
          <<: *DELETE_VM
          deletevm: vm.[4]
        RemoveNSXManager1OnNode1: *REMOVE_NSX_MANAGER--KVM
        RemoveNSXManager2OnNode2: *REMOVE_NSX_MANAGER2_ON_NODE2--KVM

KVMProtonServicesOfAllNodesDown:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Semi-Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,Inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "KVMProtonServicesOfAllNodesDown"
    Summary: 'This test case verifies that inventory updates are working fine when some inventory changes
    happen while proton services was stopped'
    Procedure: '1. Register all 3 NSXManager
                2. Discover host node on all 3 KVM
                3. Get VM1 ID
                4. Stop Proton Services on all nodes
                5. Deploy 4th VM on KVM1
                6. Add Vif on VM4
                7. Start Proton Services on all nodes
                8. Get VM4 ID and Vif from all 3 NSXManager
                9. Revert the changes as part of Exit sequence'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        <<: *MPClusteringVerificationWorkloads
        Sequence:
            - ["RegisterHostNode1ToManager1"]
            - ["RegisterHostNode2ToManager2"]
            - ["RegisterHostNode3ToManager3"]
            - ['DiscoverHostNodes']
            - ['GetVm1Id']
            - ['SetProtonServiceIdFor_Node1']
            - ['SetProtonServiceIdFor_Node2']
            - ['SetProtonServiceIdFor_Node3']
            - ['StopProtonServiceOn_Node1']
            - ['StopProtonServiceOn_Node2']
            - ['StopProtonServiceOn_Node3']
            - ['AddVm4OnKVM1']
            - ['AddVif1VM4']
            - ['StartProtonServiceOn_Node1']
            - ['StartProtonServiceOn_Node2']
            - ['StartProtonServiceOn_Node3']
            - ["VerifyStartProtonServiceStatusForNode3AfterRestart"]
            - ["VerifyClusterStatusFrom_Node1"]
            - ["VerifyClusterStatusFrom_Node2"]
            - ["VerifyClusterStatusFrom_Node3"]
            - ['GetVm4IdFromManager1']
            - ['GetVm4IdFromManager2']
            - ['GetVm4IdFromManager3']
            - ['GetVif1OfVM4FromManager1']
            - ['GetVif1OfVM4FromManager2']
            - ['GetVif1OfVM4FromManager3']
        ExitSequence:
            - ["DeleteVM4"]
            - ["RemoveNSXManager3OnNode3"]
            - ["RemoveNSXManager2OnNode2"]
            - ["RemoveNSXManager1OnNode1"]

        RegisterHostNode1ToManager1: *SET_MANAGER--KVM
        RegisterHostNode2ToManager2: *SET_MANAGER2_ON_NODE2--KVM
        RegisterHostNode3ToManager3: *SET_MANAGER3_ON_NODE3--KVM
        DiscoverHostNodes: *DISCOVER_HOST_NODES--KVM
        RemoveNSXManager1OnNode1: *REMOVE_NSX_MANAGER--KVM
        RemoveNSXManager2OnNode2: *REMOVE_NSX_MANAGER2_ON_NODE2--KVM
        RemoveNSXManager3OnNode3: *REMOVE_NSX_MANAGER3_ON_NODE3--KVM
        GetVm4IdFromManager1: *GET_VM4ID_FROM_MANAGER1
        GetVif1OfVM4FromManager1:
          <<: *GET_VIF1_OF_VM1_ON_KVM
          TestNSX: "nsxmanager.[1]"
          fabricvif:
              '[4]':
                  discover: 'true'
                  adapter_mac: 'vm.[4].vif.[1]'
        GetVm1Id: *GET_VM1_ID
        AddVm4OnKVM1: *ADD_VM4_ON_HOST1--KVM
        AddVif1VM4:
          <<: *ADD_VIF1_TO_VM1
          TestVM: 'vm.[4]'
        GetVm4IdFromManager2:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[2]"
        GetVm4IdFromManager3:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[3]"
        GetVif1OfVM4FromManager2:
          <<: *GET_VIF1_OF_VM1_ON_KVM
          TestNSX: "nsxmanager.[2]"
          fabricvif:
              '[4]':
                  discover: 'true'
                  adapter_mac: 'vm.[4].vif.[1]'
        GetVif1OfVM4FromManager3:
          <<: *GET_VIF1_OF_VM1_ON_KVM
          TestNSX: "nsxmanager.[3]"
          fabricvif:
              '[4]':
                  discover: 'true'
                  adapter_mac: 'vm.[4].vif.[1]'
        DeleteVM4:
          <<: *DELETE_VM
          deletevm: vm.[4]
        VerifyStartProtonServiceStatusForNode3AfterRestart:
          <<: *VERFIY_START_PROTON_SERVICE_STATUS_FOR_NODE_3
          sleepbetweenworkloads: 180

KVMOSVersionOfHost:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies os version of kvm is updated in NsxManager"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "KVMOSVersionOfHost"
    Priority: "P2"
    Developer: "kchakraborty"
    Status: "Execution Ready"
    AutomationLevel: "Semi-Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Procedure: '1. Register a Host Node
                2. Verify if Fabric Host is registered successfully
                3. Verify vms and vif information are uploaded correctly to nsx manager
                4. Add a new Vm on the host
                5. Verify new vm information is updated into nsx manager'
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_KVM_ONE_VM
    WORKLOADS:
        Sequence:
            - ['SetManagerOnKVM1']
            - ['DiscoverHostNode1']
            - ['GetVm1Id']
            - ['ReadOSVersionOnHostNode1']
        ExitSequence:
            - ['RemoveNSXManagerOnKVM1']

        SetManagerOnKVM1: *SET_MANAGER--KVM
        RemoveNSXManagerOnKVM1: *REMOVE_NSX_MANAGER--KVM
        ReadOSVersionOnHostNode1: *READ_OSVERSION_ON_HOST_NODE1--KVM
        DiscoverHostNode1: *DISCOVER_HOST_NODE1--KVM
        GetVm1Id: *GET_VM1_ID

KVMReregisterNodeToDifferentNodePostDeregister:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Semi-Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,Inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "KVMReregisterNodeToDifferentNodePostDeregister"
    Summary: 'Verify KVM host can be registered to diffrent manager post registration from another manager'
    Procedure: '1. Register KVM1 with NSXManager 1
                2. Discover host node1
                3. Get VM1 ID on node 1
                4. Deregister host node 1
                5. Register KVM1 with NSXManager2
                6. Discover host node1
                7. Get VM1 ID on node 1'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
            - ["RegisterHostNode1ToManager1"]
            - ['DiscoverHostNode1']
            - ['GetVm1Id']
            - ["RemoveNSXManager1OnNode1"]
            - ["SetManager2OnNode1"]
            - ['DiscoverHostNode1']
            - ['GetVm1Id']
        ExitSequence:
            - ["RemoveNSXManager1OnNode1"]

        RegisterHostNode1ToManager1: *SET_MANAGER--KVM
        DiscoverHostNode1: *DISCOVER_HOST_NODE1--KVM
        GetVm1Id: *GET_VM1_ID
        RemoveNSXManager1OnNode1: *REMOVE_NSX_MANAGER--KVM
        SetManager2OnNode1:
            Type: Host
            TestHost: 'kvm.[1]'
            set_nsx_manager:
                manager_ip: 'nsxmanager.[2]'
                execution_type: 'cli'
                manager_thumbprint: 'nsxmanager.[2]'

KVMNetworkDisconnectBetweenMpAndHostNode:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies inventory is updated after network disconnect with data generated during disconnect"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "KVMNetworkDisconnectBetweenMpAndHostNode"
    Priority: "P1"
    Developer: "kchakraborty"
    Procedure: '1. Register a KVM1 to Nsxmanager1
                2. Verify vms and vif information are uploaded correctly to nsx manager
                3. Network is disconnected between Host and Nsxmanager
                4. Add a new Vm on the host
                4. Network is restored between Host and Nsxmanager
                5. Verify new vm information is updated into nsx manager'
    ExpectedResult: "PASS"
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
            - ['SetManagerOnKVM1']
            - ['DiscoverHostNode']
            - ['GetVm1Id']
            - ['AddVIF1ToVM1']
            - ['GetVIF1OfVM1']
            - ['GetClients']
            - ['BlockHostNode1TrafficOnNode1']
            - ['AddVm4OnKVM1']
            - ['AddVif1VM4']
            - ['UnblockHostNode1TrafficOnNode1']
            - ['PingClient1']
            - ['GetVm4IdFromManager1']
            - ['GetVif1OfVM4FromManager1']
        ExitSequence:
            - ['DeleteVm4']
            - ['DeleteVIF1ofVM1']
            - ["RemoveNSXManager1OnNode1"]

        SetManagerOnKVM1: *SET_MANAGER--KVM
        DeleteVIF1ofVM1: *DELETE_VIF1_OF_VM1
        GetVIF1OfVM1: *GET_VIF1_OF_VM1_ON_KVM
        AddVIF1ToVM1: *ADD_VIF1_TO_VM1
        DiscoverHostNode: *DISCOVER_HOST_NODE1--KVM
        RemoveNSXManager1OnNode1: *REMOVE_NSX_MANAGER--KVM
        BlockHostNode1TrafficOnNode1: *BLOCK_HOSTNODE1_TRAFFIC_ON_NODE1--KVM
        UnblockHostNode1TrafficOnNode1: *UNBLOCK_HOSTNODE1_TRAFFIC_ON_NODE1--KVM
        GetClients: *GET_CLIENTS
        PingClient1: *PING_CLIENT_1
        GetVm1Id: *GET_VM1_ID
        GetVm4IdFromManager1:
            <<: *GET_VM1_ID
            fabricvm:
                '[4]':
                    discover: 'true'
                    name: 'vm.[4]'
        GetVif1OfVM4FromManager1:
            <<: *GET_VIF1_OF_VM1_ON_KVM
            TestNSX: "nsxmanager.[1]"
            fabricvif:
                '[4]':
                    discover: 'true'
                    adapter_mac: 'vm.[4].vif.[1]'
        AddVm4OnKVM1:
          <<: *ADD_VM1_ON_HOST1--KVM
          vm:
            '[4]':
                  template: 'template_kvm_debian'
                  vmstate: 'poweron'
                  host: 'kvm.[1]'
                  installtype: fullclone
        AddVif1VM4:
            <<: *ADD_VIF1_TO_VM1
            TestVM: 'vm.[4]'
        DeleteVm4:
            <<: *DELETE_VM
            deletevm: vm.[4]

KVMClusterRebootInOrder:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Semi-Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,Inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "KVMClusterRebootInOrder"
    Summary: 'This test case verifies that inventory updates are working fine
              after MP cluster nodes sequential reboot'
    Procedure: '1. Register 3 KVM host with NSXManager
                2. Discover all 3 host node
                3. Get VM1, VM2 and VM3 ID
                4. Verify cluster status from all 3 MP nodes
                5. Reboot MP cluster node-1
                6. Wait till node 1 comes UP and check cluster status from all nodes
                7. Reboot MP cluster node-2
                8. Wait till node 2 comes UP and check cluster status from all nodes
                9. Reboot MP cluster node-3 and simultaneously deploy VM4 on KVM1 and add Vif
                10. Wait till node 3 comes UP and check cluster status from all nodes
                11. Get VM4 ID and Vif info from all 3 NSXManager'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE

    WORKLOADS:
      <<: *MPClusteringVerificationWorkloads
      Sequence:
        - ["RegisterHostNode1OnManager1"]
        - ["RegisterHostNode2OnManager2"]
        - ["RegisterHostNode3OnManager3"]
        - ['DiscoverHostNodes']
        - ['GetVm1IdFromManager1']
        - ['GetVm2IdFromManager2']
        - ['GetVm3IdFromManager3']
        - ["VerifyClusterStatusFrom_Node1"]
        - ["VerifyClusterStatusFrom_Node2"]
        - ["VerifyClusterStatusFrom_Node3"]
        - ["Restart_Node1"]
        - ["SetProtonServiceIdFor_Node1"]
        - ["VerifyStartProtonServiceStatusForNode1AfterRestart"]
        - ["VerifyClusterStatusFrom_Node1"]
        - ["VerifyClusterStatusFrom_Node2"]
        - ["VerifyClusterStatusFrom_Node3"]
        - ["Restart_Node2"]
        - ["SetProtonServiceIdFor_Node2"]
        - ["VerifyStartProtonServiceStatusForNode2AfterRestart"]
        - ["VerifyClusterStatusFrom_Node1"]
        - ["VerifyClusterStatusFrom_Node2"]
        - ["VerifyClusterStatusFrom_Node3"]
        - ["Restart_Node3", 'AddVm4OnKVM1']
        - ["AddVif1VM4"]
        - ["SetProtonServiceIdFor_Node3"]
        - ["VerifyStartProtonServiceStatusForNode3AfterRestart"]
        - ["VerifyClusterStatusFrom_Node1"]
        - ["VerifyClusterStatusFrom_Node2"]
        - ["VerifyClusterStatusFrom_Node3"]
        - ['GetVm4IdFromManager1', 'GetVm4IdFromManager2', 'GetVm4IdFromManager3']
        - ['GetVif1OfVM4FromManager1', 'GetVif1OfVM4FromManager2', 'GetVif1OfVM4FromManager3']
      ExitSequence:
        - ["DeleteVM4"]
        - ["DeregisterHostNode1FromManager1"]
        - ["DeregisterHostNode2FromManager2"]
        - ["DeregisterHostNode3FromManager3"]

      VerifyStartProtonServiceStatusForNode1AfterRestart:
        <<: *VERFIY_START_PROTON_SERVICE_STATUS_FOR_NODE_1
        sleepbetweenworkloads: 180

      VerifyStartProtonServiceStatusForNode2AfterRestart:
        <<: *VERFIY_START_PROTON_SERVICE_STATUS_FOR_NODE_2
        sleepbetweenworkloads: 180

      VerifyStartProtonServiceStatusForNode3AfterRestart:
        <<: *VERFIY_START_PROTON_SERVICE_STATUS_FOR_NODE_3
        sleepbetweenworkloads: 180

      RegisterHostNode1OnManager1: *SET_MANAGER--KVM
      RegisterHostNode2OnManager2: *SET_MANAGER2_ON_NODE2--KVM
      RegisterHostNode3OnManager3: *SET_MANAGER3_ON_NODE3--KVM
      DiscoverHostNodes: *DISCOVER_HOST_NODES--KVM
      GetVm1IdFromManager1: *GET_VM1_ID
      GetVm2IdFromManager2:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[2]"
        fabricvm:
            '[2]':
                discover: 'true'
                name: 'vm.[2]'
      GetVm3IdFromManager3:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[3]"
        fabricvm:
            '[3]':
                discover: 'true'
                name: 'vm.[3]'
      AddVm4OnKVM1:
        <<: *ADD_VM1_ON_HOST1--KVM
        vm:
          '[4]':
                template: 'template_kvm_debian'
                vmstate: 'poweron'
                host: 'kvm.[1]'
                installtype: fullclone
      AddVif1VM4:
        <<: *ADD_VIF1_TO_VM1
        TestVM: 'vm.[4]'
      GetVm4IdFromManager1:
        <<: *GET_VM1_ID
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVm4IdFromManager2:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[2]"
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVm4IdFromManager3:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[3]"
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVif1OfVM4FromManager1:
        <<: *GET_VIF1_OF_VM1_ON_KVM
        TestNSX: "nsxmanager.[1]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vif.[1]'
      GetVif1OfVM4FromManager2:
        <<: *GET_VIF1_OF_VM1_ON_KVM
        TestNSX: "nsxmanager.[2]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vif.[1]'
      GetVif1OfVM4FromManager3:
        <<: *GET_VIF1_OF_VM1_ON_KVM
        TestNSX: "nsxmanager.[3]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vif.[1]'
      DeleteVM4:
        <<: *DELETE_VM
        deletevm: vm.[4]
      DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--KVM
      DeregisterHostNode2FromManager2: *REMOVE_NSX_MANAGER2_ON_NODE2--KVM
      DeregisterHostNode3FromManager3: *REMOVE_NSX_MANAGER3_ON_NODE3--KVM

KVMClusterRebootSimultaneous:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Semi-Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,Inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "KVMClusterRebootSimultaneous"
    Summary: 'This test case verifies that inventory updates are working fine
              after MP cluster nodes simultaneous reboot'
    Procedure: '1. Register 3 KVM host with NSXManager
                2. Discover all 3 host node
                3. Get VM1, VM2 and VM3 ID
                4. Verify cluster status from all 3 MP nodes
                5. Reboot all 3 MP cluster node simultaneously and while
                reboot is in progress deploy VM4 on KVM1 and add Vif
                6. Wait till all node comes UP and check cluster status from all nodes
                7. Get VM4 ID and Vif info from all 3 NSXManager'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE

    WORKLOADS:
      <<: *MPClusteringVerificationWorkloads
      Sequence:
        - ["RegisterHostNode1OnManager1"]
        - ["RegisterHostNode2OnManager2"]
        - ["RegisterHostNode3OnManager3"]
        - ['DiscoverHostNodes']
        - ['GetVm1IdFromManager1']
        - ['GetVm2IdFromManager2']
        - ['GetVm3IdFromManager3']
        - ["VerifyClusterStatusFrom_Node1"]
        - ["VerifyClusterStatusFrom_Node2"]
        - ["VerifyClusterStatusFrom_Node3"]
        - ["Restart_Node1", "Restart_Node2", "Restart_Node3", "AddVm4OnKVM1"]
        - ["AddVif1VM4"]
        - ["SetProtonServiceIdFor_Node1"]
        - ["VerifyStartProtonServiceStatusForNode1AfterRestart"]
        - ["VerifyClusterStatusFrom_Node1"]
        - ["VerifyClusterStatusFrom_Node2"]
        - ["VerifyClusterStatusFrom_Node3"]
        - ['GetVm4IdFromManager1', 'GetVm4IdFromManager2', 'GetVm4IdFromManager3']
        - ['GetVif1OfVM4FromManager1', 'GetVif1OfVM4FromManager2', 'GetVif1OfVM4FromManager3']
      ExitSequence:
        - ["DeleteVM4"]
        - ["DeregisterHostNode1FromManager1"]
        - ["DeregisterHostNode2FromManager2"]
        - ["DeregisterHostNode3FromManager3"]

      VerifyStartProtonServiceStatusForNode1AfterRestart:
        <<: *VERFIY_START_PROTON_SERVICE_STATUS_FOR_NODE_1
        sleepbetweenworkloads: 180

      RegisterHostNode1OnManager1: *SET_MANAGER--KVM
      RegisterHostNode2OnManager2: *SET_MANAGER2_ON_NODE2--KVM
      RegisterHostNode3OnManager3: *SET_MANAGER3_ON_NODE3--KVM
      DiscoverHostNodes: *DISCOVER_HOST_NODES--KVM
      GetVm1IdFromManager1: *GET_VM1_ID
      GetVm2IdFromManager2:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[2]"
        fabricvm:
            '[2]':
                discover: 'true'
                name: 'vm.[2]'
      GetVm3IdFromManager3:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[3]"
        fabricvm:
            '[3]':
                discover: 'true'
                name: 'vm.[3]'
      AddVm4OnKVM1:
        <<: *ADD_VM1_ON_HOST1--KVM
        vm:
          '[4]':
              template: 'rhel53-srv-32'
              host: 'kvm.[1]'
      AddVif1VM4:
        <<: *ADD_VIF1_TO_VM1
        TestVM: 'vm.[4]'
      GetVm4IdFromManager1:
        <<: *GET_VM1_ID
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVm4IdFromManager2:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[2]"
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVm4IdFromManager3:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[3]"
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVif1OfVM4FromManager1:
        <<: *GET_VIF1_OF_VM1_ON_KVM
        TestNSX: "nsxmanager.[1]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vif.[1]'
      GetVif1OfVM4FromManager2:
        <<: *GET_VIF1_OF_VM1_ON_KVM
        TestNSX: "nsxmanager.[2]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vif.[1]'
      GetVif1OfVM4FromManager3:
        <<: *GET_VIF1_OF_VM1_ON_KVM
        TestNSX: "nsxmanager.[3]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vif.[1]'
      DeleteVM4:
        <<: *DELETE_VM
        deletevm: vm.[4]
      DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--KVM
      DeregisterHostNode2FromManager2: *REMOVE_NSX_MANAGER2_ON_NODE2--KVM
      DeregisterHostNode3FromManager3: *REMOVE_NSX_MANAGER3_ON_NODE3--KVM

KVMDAConnectTOMPNodeWithoutHostRegistration:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Semi-Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,Inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "KVMDAConnectTOMPNodeWithoutHostRegistration"
    Summary: 'This test case verifies that host details are not getting posted to
              NSXManager when host unregistered from MP'
    Procedure: '1. Register host node with NSXManager
                2. Discover host node
                3. Get VM1 from manager
                4. Unregister host node
                5. Verify VM1 now deleted from inventory
                6. Restart MPA and DA to flush out changes'
    TestbedSpec: *ONE_NSXMANAGER_ONE_KVM_ONE_VM

    WORKLOADS:
      Sequence:
        - ["RegisterHostNode1OnManager1"]
        - ['DiscoverHostNode1']
        - ['GetVm1IdFromManager1']
      ExitSequence:
        - ['UnregisterHostNode1']
        - ['VerifyVm1Deleted']
        - ['RestartMPA']
        - ['RestartDA']

      RegisterHostNode1OnManager1: *SET_MANAGER--KVM
      DiscoverHostNode1: *DISCOVER_HOST_NODE1--KVM
      GetVm1IdFromManager1: *GET_VM1_ID
      UnregisterHostNode1: *UNREGISTER_HOST_NODE1
      VerifyVm1Deleted: *VERIFY_VM1_DELETED
      RestartMPA: *RESTART_MPA--KVM
      RestartDA: *RESTART_DA--KVM

KVMMPNodeUnreachableToClusterButConnectedToHost:
  Product: 'NSXTransformers'
  Category: 'ManagementPlatform'
  Component: 'Clustering'
  TestName: 'KVMMPNodeUnreachableToClusterButConnectedToHost'
  Version: "2"
  TCMSId: ''
  Priority: 'P1'
  PMT: ''
  Testcaselevel: 'Functional'
  Testcasetype: 'Functional'
  QCPath:  ''
  Summary: 'To verify host is able to send new inventory update if master MP node is unreachable to cluster '
  Procedure: '1. Create  a cluster of 3 node n1,n2 and n3
              2. Register 3 hostnode to mp nodes n1, n2 , n3
              3. Deploy vm1 on host 1
              4. Read vm1 from all nodes
              5. Add iptable rule to block communciation between node 1 and  node n2, n3.
              6. Check cluster status from all nodes
              7. Deploy vm4 on host node1
              8. Read vm4 from node n2 and n3
              9. Now remove the iptable rules from node 1 and restart its proton service
              10. Read vm4 from node n1'
  ExpectedResult: "Pass"
  Duration: '300'
  Tags: 'nsx,management'
  AutomationLevel: 'Automated'
  Developer: 'kchakraborty'
  FullyAutomatable: 'Y'
  Status: 'Execution Ready'
  PartnerFacing: 'Y'
  TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
  WORKLOADS:
    <<: *MPClusteringVerificationWorkloads
    <<: *MPClusteringConfigurationWorkloads
    Sequence:
        - ["GetMPNode1Id"]
        - ["MapNSXManager1ToCluster"]
        - ["VerifyClusterMembers_3MP"]
        - ["RegisterHostNode1ToManager1"]
        - ["RegisterHostNode2ToManager2"]
        - ["RegisterHostNode3ToManager3"]
        - ['DiscoverHostNodes']
        - ["BlockMPNode2Traffic_On_Node1","BlockMPNode3Traffic_On_Node1"]
        - ["VerifyMPClusterStatusUnknown_On_Node1_With_Sleep"]
        - ["VerifyClusterStatusFrom_Node2"]
        - ["VerifyClusterStatusFrom_Node3"]
        - ['AddVm4OnKVM1']
        - ['GetVm4IdFromManager2']
        - ['GetVm4IdFromManager3']
    ExitSequence:
        - ["UnBlockMPNode2Traffic_On_Node1", "UnBlockMPNode3Traffic_On_Node1"]
        - ["SetProtonServiceIdFor_Node1"]
        - ["RestartProtonServiceOn_Node1"]
        - ["Wait_For_Cluster_Status_Stable_On_Node1"]
        - ["VerifyClusterStatusFrom_Node1"]
        - ["VerifyClusterStatusFrom_Node2"]
        - ["VerifyClusterStatusFrom_Node3"]
        - ['GetVm4IdFromManager1']
        - ["DeleteVM4"]
        - ["RemoveNSXManager3OnNode3"]
        - ["RemoveNSXManager2OnNode2"]
        - ["RemoveNSXManager1OnNode1"]

    VerifyMPClusterStatusUnknown_On_Node1_With_Sleep:
      <<: *VERIFY_MP_CLUSTER_STATUS_UNKNOWN_ON_NODE1
      sleepbetweenworkloads: 60

    RegisterHostNode1ToManager1: *SET_MANAGER--KVM
    RegisterHostNode2ToManager2: *SET_MANAGER2_ON_NODE2--KVM
    RegisterHostNode3ToManager3: *SET_MANAGER3_ON_NODE3--KVM
    DiscoverHostNodes: *DISCOVER_HOST_NODES--KVM
    RemoveNSXManager1OnNode1: *REMOVE_NSX_MANAGER--KVM
    RemoveNSXManager2OnNode2: *REMOVE_NSX_MANAGER2_ON_NODE2--KVM
    RemoveNSXManager3OnNode3: *REMOVE_NSX_MANAGER3_ON_NODE3--KVM
    GetVm4IdFromManager1: *GET_VM4ID_FROM_MANAGER1
    GetVm1Id: *GET_VM1_ID
    AddVm4OnKVM1: *ADD_VM4_ON_HOST1--KVM
    GetVm4IdFromManager2:
      <<: *GET_VM4ID_FROM_MANAGER1
      TestNSX: "nsxmanager.[2]"
      sleepbetweenworkloads: 180
    GetVm4IdFromManager3:
      <<: *GET_VM4ID_FROM_MANAGER1
      TestNSX: "nsxmanager.[3]"
    DeleteVM4:
      <<: *DELETE_VM
      deletevm: vm.[4]

KVMNetworkDisconnectBetweenMpNodeAndHostDuringInventorySync:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies inventory is updated correctly post network disconnection during Inventory"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "KVMNetworkDisconnectBetweenMpNodeAndHostDuringInventorySync"
    Priority: "P1"
    Developer: "kchakraborty"
    Procedure: '1. Register a KVM1 to Nsxmanager1
                2. Verify vms and vif information are uploaded correctly to nsx manager
                3. Add a new Vm on the host
                4. Network is disconnected between Host and Nsxmanager while deployment started
                4. Network is restored between Host and Nsxmanager
                5. Verify new vm information is updated into nsx manager'
    ExpectedResult: "PASS"
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
            - ['SetManagerOnKVM1']
            - ['DiscoverHostNode']
            - ['GetVm1Id']
            - ['AddVm4OnKVM1', 'BlockHostNode1TrafficOnNode1']
            - ['UnblockHostNode1TrafficOnNode1']
            - ['GetClients']
            - ['PingClient1']
            - ['GetVm4Id']
        ExitSequence:
            - ['DeleteVm4']
            - ['RemoveNSXManager1OnNode1']

        SetManagerOnKVM1: *SET_MANAGER--KVM
        DiscoverHostNode: *DISCOVER_HOST_NODE1--KVM
        GetVm1Id: *GET_VM1_ID
        AddVm4OnKVM1: *ADD_VM4_ON_HOST1--KVM
        GetVm4Id: *GET_VM4ID_FROM_MANAGER1
        DeleteVm4:
          <<: *DELETE_VM
          deletevm: vm.[4]
        RemoveNSXManager1OnNode1: *REMOVE_NSX_MANAGER--KVM
        BlockHostNode1TrafficOnNode1: *BLOCK_HOSTNODE1_TRAFFIC_ON_NODE1--KVM
        UnblockHostNode1TrafficOnNode1: *UNBLOCK_HOSTNODE1_TRAFFIC_ON_NODE1--KVM
        GetClients: *GET_CLIENTS
        PingClient1: *PING_CLIENT_1

KVMMpnodeWithoutAnyHostInventoryUpdate:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Semi-Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,Inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "KVMMpnodeWithoutAnyHostInventoryUpdate"
    Summary: 'This test case verifies an mp node which does not have own inventory is able to fetch inventory of others'
    Procedure: '1. Register 2 KVM host with NSXManager
                2. Discover all 2 host node
                3. Get VM1 ID
                4. Deploy VM4 on KVM1
                5. Get VM4 ID from all NSXManager'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
            - ["RegisterHostNode1ToManager1"]
            - ["RegisterHostNode2ToManager2"]
            - ['DiscoverHostNode1']
            - ['DiscoverHostNode2']
            - ['GetVm1Id']
            - ['AddVm4OnKVM1']
            - ['GetVm4IdFromManager1']
            - ['GetVm4IdFromManager2']
            - ['GetVm4IdFromManager3']
        ExitSequence:
            - ["DeleteVM4"]
            - ["RemoveNSXManager2OnNode2"]
            - ["RemoveNSXManager1OnNode1"]

        RegisterHostNode1ToManager1: *SET_MANAGER--KVM
        RegisterHostNode2ToManager2: *SET_MANAGER2_ON_NODE2--KVM
        DiscoverHostNode1: *DISCOVER_HOST_NODE1--KVM
        DiscoverHostNode2: *DISCOVER_HOST_NODE2--KVM
        GetVm1Id: *GET_VM1_ID
        AddVm4OnKVM1: *ADD_VM4_ON_HOST1--KVM
        GetVm4IdFromManager1: *GET_VM4ID_FROM_MANAGER1
        GetVm4IdFromManager2:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[2]"
        GetVm4IdFromManager3:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[3]"
        DeleteVM4:
          <<: *DELETE_VM
          deletevm: vm.[4]
        RemoveNSXManager1OnNode1: *REMOVE_NSX_MANAGER--KVM
        RemoveNSXManager2OnNode2: *REMOVE_NSX_MANAGER2_ON_NODE2--KVM

KVMRegisterHostNodeClusterReadOnly:
  Product: 'NSXTransformers'
  Category: 'ManagementPlatform'
  Component: 'Clustering'
  TestName: 'KVMRegisterHostNodeClusterReadOnly:'
  Version: "2"
  TCMSId: ''
  Priority: 'P2'
  PMT: ''
  Testcaselevel: 'Functional'
  Testcasetype: 'Functional'
  QCPath:  ''
  Summary: 'to verify HostNode Registration fails  if cluster is in READ only state'
  Procedure: '1. Create  a cluster of 3 node n1,n2 and n3
              2. Stop Proton service in n2 and n3
              3. Try to regsiter a KVM in n1
              4. Host Node Registration should fail'
  ExpectedResult: "Pass"
  Duration: '300'
  Tags: 'nsx,management'
  AutomationLevel: 'Automated'
  Developer: 'kchakraborty'
  FullyAutomatable: 'Y'
  Status: 'Execution Ready'
  PartnerFacing: 'Y'
  TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
  WORKLOADS:
    <<: *MPClusteringVerificationWorkloads
    <<: *MPClusteringConfigurationWorkloads
    Sequence:
        - [SetProtonServiceIdFor_Node2]
        - ["GetMPNode1Id"]
        - ["MapNSXManager1ToCluster"]
        - ["VerifyClusterMembers_3MP"]
        - ["StopProtonServiceOn_Node2"]
        - ["StopProtonServiceOn_Node3"]
        - ["Wait_For_Cluster_Status_Unstable_On_Node1"]
        - ["RegisterHostNode1ToManager1Failed"]
    ExitSequence:
        - ["StartProtonServiceOn_Node2"]
        - ["StartProtonServiceOn_Node3"]
        - ["Wait_For_Cluster_Status_Stable_On_Node1"]
        - ["VerifyClusterStatusFrom_Node1"]
        - ["VerifyClusterStatusFrom_Node2"]
        - ["VerifyClusterStatusFrom_Node3"]

    RegisterHostNode1ToManager1Failed: *REGISTER_NODE_EXPECT_FAILURE--KVM

KVMInventoryChangeWhenClusterReadOnly:
  Product: 'NSXTransformers'
  Category: 'ManagementPlatform'
  Component: 'Clustering'
  TestName: 'KVMRegisterHostNodeClusterReadOnly:'
  Version: "2"
  TCMSId: ''
  Priority: 'P2'
  PMT: ''
  Testcaselevel: 'Functional'
  Testcasetype: 'Functional'
  QCPath:  ''
  Summary: 'To verify if inventory is changed while cluster is in READ ONLY state , nsx-da  is able to send update once '
  Procedure: '1. Create  a cluster of 3 node n1,n2 and n3
              2. Add KVM one to node 1
              3. Stop Proton service in n2 and n3
              4. Deploy vm1
              5. Verify read vm1 fails
              6. Restore all nodes of cluster to a stable state
              7. Verify inventory update of vm1 is received'
  ExpectedResult: "Pass"
  Duration: '300'
  Tags: 'nsx,management'
  AutomationLevel: 'Automated'
  Developer: 'kchakraborty'
  FullyAutomatable: 'Y'
  Status: 'Execution Ready'
  PartnerFacing: 'Y'
  TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
  WORKLOADS:
    <<: *MPClusteringVerificationWorkloads
    <<: *MPClusteringConfigurationWorkloads
    Sequence:
        - ["RegisterHostNode1ToManager1"]
        - ["DiscoverHostNode1"]
        - [SetProtonServiceIdFor_Node2]
        - ["GetMPNode1Id"]
        - ["MapNSXManager1ToCluster"]
        - ["VerifyClusterMembers_3MP"]
        - ["StopProtonServiceOn_Node2"]
        - ["StopProtonServiceOn_Node3"]
        - ["Wait_For_Cluster_Status_Unstable_On_Node1"]
        - ['AddVm4OnKVM1']
        - ['VerifyVm4NotAddedInIneventory']
    ExitSequence:
        - ["StartProtonServiceOn_Node2"]
        - ["StartProtonServiceOn_Node3"]
        - ["Wait_For_Cluster_Status_Stable_On_Node1"]
        - ["VerifyClusterStatusFrom_Node2"]
        - ["VerifyClusterStatusFrom_Node3"]
        - ['GetVm4IdFromManager1']
        - ['GetVm4IdFromManager2']
        - ['GetVm4IdFromManager3']
        - ["DeleteVM4"]
        - ["RemoveNSXManager1OnNode1"]

    RegisterHostNode1ToManager1: *SET_MANAGER--KVM
    DiscoverHostNode1: *DISCOVER_HOST_NODE1--KVM
    AddVm4OnKVM1: *ADD_VM4_ON_HOST1--KVM
    RemoveNSXManager1OnNode1: *REMOVE_NSX_MANAGER--KVM
    GetVm4IdFromManager1: *GET_VM4ID_FROM_MANAGER1
    GetVm4IdFromManager2:
      <<: *GET_VM4ID_FROM_MANAGER1
      TestNSX: "nsxmanager.[2]"
    GetVm4IdFromManager3:
      <<: *GET_VM4ID_FROM_MANAGER1
      TestNSX: "nsxmanager.[3]"
    DeleteVM4:
      <<: *DELETE_VM
      deletevm: vm.[4]
    VerifyVm4NotAddedInIneventory:
        Type: "Inventory"
        TestInventory: "nsxmanager.[1].fabricvm.[1]"
        ExpectedResult:
            status_code: SERVICE_UNAVAILABLE
        get_inventoryobject_list:
          'result_count[?]equal_to': 2

MultiHostSimultaneousRegistrationWithMultiNodes:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Semi-Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,Inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "MultiHostSimultaneousRegistrationWithMultiNodes"
    Summary: 'Verify Simlultaneously Host can be registered to multiple node'
    Procedure: '1. Register all 3 Host to 3 NSXManager simultaneously
                2. Discover host node on all 3 KVM
                3. Deploy 4th VM on KVM1
                4. Get VM4 ID from NSXManager 1,2 and 3'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
            - ["RegisterHostNode1ToManager1","RegisterHostNode2ToManager2","RegisterHostNode3ToManager3"]
            - ['DiscoverHostNodes']
            - ['AddVm4OnKVM1']
            - ['GetVm4IdFromManager1']
            - ['GetVm4IdFromManager2']
            - ['GetVm4IdFromManager3']
        ExitSequence:
            - ["DeleteVM4"]
            - ["RemoveNSXManager3OnNode3", "RemoveNSXManager2OnNode2", "RemoveNSXManager1OnNode1"]

        RegisterHostNode1ToManager1: *SET_MANAGER--KVM
        RegisterHostNode2ToManager2: *SET_MANAGER2_ON_NODE2--KVM
        RegisterHostNode3ToManager3: *SET_MANAGER3_ON_NODE3--KVM
        DiscoverHostNodes: *DISCOVER_HOST_NODES--KVM
        AddVm4OnKVM1: *ADD_VM4_ON_HOST1--KVM
        GetVm4IdFromManager1: *GET_VM4ID_FROM_MANAGER1
        GetVm4IdFromManager2:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[2]"
        GetVm4IdFromManager3:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[3]"
        DeleteVM4:
          <<: *DELETE_VM
          deletevm: vm.[4]
        RemoveNSXManager1OnNode1: *REMOVE_NSX_MANAGER--KVM
        RemoveNSXManager2OnNode2: *REMOVE_NSX_MANAGER2_ON_NODE2--KVM
        RemoveNSXManager3OnNode3: *REMOVE_NSX_MANAGER3_ON_NODE3--KVM

MultiHostSimultaneousRegistrationWithSameNode:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Semi-Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,Inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "MultiHostSimultaneousRegistrationWithSameNode"
    Summary: 'Verify Simlultaneously Host can be registered to multiple node'
    Procedure: '1. Register all 3 Host to 3 NSXManager simultaneously
                2. Discover host node on all 3 KVM
                3. Deploy 4th VM on KVM1
                4. Get VM4 ID from NSXManager 1,2 and 3'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
            - ["RegisterHostNode1ToManager1","RegisterHostNode2ToManager1","RegisterHostNode3ToManager1"]
            - ['DiscoverHostNodes']
            - ['AddVm4OnKVM1']
            - ['GetVm4IdFromManager1']
            - ['GetVm4IdFromManager2']
            - ['GetVm4IdFromManager3']
        ExitSequence:
            - ["DeleteVM4"]
            - ["RemoveNSXManager3OnNode3", "RemoveNSXManager2OnNode2", "RemoveNSXManager1OnNode1"]

        RegisterHostNode1ToManager1: *SET_MANAGER--KVM
        DiscoverHostNodes: *DISCOVER_HOST_NODES--KVM
        RemoveNSXManager1OnNode1: *REMOVE_NSX_MANAGER--KVM
        RemoveNSXManager2OnNode2: *REMOVE_NSX_MANAGER2_ON_NODE2--KVM
        RemoveNSXManager3OnNode3: *REMOVE_NSX_MANAGER3_ON_NODE3--KVM
        AddVm4OnKVM1: *ADD_VM4_ON_HOST1--KVM
        GetVm4IdFromManager1: *GET_VM4ID_FROM_MANAGER1
        GetVm4IdFromManager2:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[2]"
        GetVm4IdFromManager3:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[3]"
        DeleteVM4:
          <<: *DELETE_VM
          deletevm: vm.[4]
        RegisterHostNode2ToManager1:
            Type: Host
            TestHost: 'kvm.[2]'
            set_nsx_manager:
                manager_ip: 'nsxmanager.[1]'
                execution_type: 'cli'
                manager_thumbprint: 'nsxmanager.[1]'
        RegisterHostNode3ToManager1:
            Type: Host
            TestHost: 'kvm.[3]'
            set_nsx_manager:
                manager_ip: 'nsxmanager.[1]'
                execution_type: 'cli'
                manager_thumbprint: 'nsxmanager.[1]'

KVMRegisterHostWithEmptyInventory:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "KVMRegisterHostWithEmptyInventory"
    Summary: 'Verify no inventory updates send if host is not registered'
    Procedure: '1. Delete VM from host
                2. Register host with NSXManager
                3. Discover host
                4. Get VM ID which should fail
                5. Deploy a new VM to host
                6. Add Vif on VM
                7. Get VM ID from NSXManager
                8. Get VM4 Vif from NSXManager'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
      Sequence:
        - - DeleteVM3
        - - RegisterHostNode3ToManager3
        - - DiscoverHostNode3
      ExitSequence:
        - - AddVm3OnKVM3
        - - AddVif1VM3
        - - GetVm3IdFromManager3
        - - GetVif1OfVM3FromManager3
        - - DeleteVif1ofVM3
        - - RemoveNSXManager3OnNode3

      RegisterHostNode3ToManager3: *SET_MANAGER3_ON_NODE3--KVM
      DiscoverHostNode3: *DISCOVER_HOST_NODE3--KVM
      DeleteVM3:
        <<: *DELETE_VM
        deletevm: vm.[3]
      AddVm3OnKVM3:
        <<: *ADD_VM1_ON_HOST1--KVM
        vm:
          '[3]':
              template: 'template_kvm_debian'
              vmstate: 'poweron'
              host: 'kvm.[3]'
              installtype: 'fullclone'
      AddVif1VM3:
        <<: *ADD_VIF1_TO_VM1
        TestVM: 'vm.[3]'
        vif:
            '[1]':
                backing: 'kvm.[3].bridge.[1]'
      GetVm3IdFromManager3:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[3]"
        fabricvm:
            '[3]':
                discover: 'true'
                name: 'vm.[3]'
      GetVif1OfVM3FromManager3:
        <<: *GET_VIF1_OF_VM1_ON_KVM
        TestNSX: "nsxmanager.[3]"
        fabricvif:
            '[3]':
                discover: 'true'
                adapter_mac: 'vm.[3].vif.[1]'
      DeleteVif1ofVM3:
        <<: *DELETE_VIF1_OF_VM1
        TestVM: 'vm.[3]'
        deletevif: vm.[3].vif.[1]
      RemoveNSXManager3OnNode3: *REMOVE_NSX_MANAGER3_ON_NODE3--KVM


KVMVerifyInventoryPostNSXDAReinstall:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "KVMVerifyInventoryPostNSXDAReinstall"
    Summary: 'This test verify that inventory works fine after NSX-DA vib re-installation'
    Procedure: '1. Register host with NSXManager and Discover it
                2. Get VM1 id from node1
                3. Uninstall nsx-da
                4. Add VM4 on host1 and attach vnic to it
                5. Install nsx-da
                6. Verify inventory'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
          - - RegisterHostNode1OnManager1
          - - DiscoverHostNode1
          - - GetVm1IdFromManager1
          - - UninstallNSXDAPackage
          - - AddVm4OnKVM1
          - - AddVIF1ToVM4
        ExitSequence:
          - - InstallNSXDAPackage
          - - GetVm1IdFromManager1
          - - GetVm4IdFromManager1
          - - GetVif1OfVm4FromManager1
          - - DeleteVM4
          - - DeregisterHostNode1FromManager1

        RegisterHostNode1OnManager1: *SET_MANAGER--KVM

        DiscoverHostNode1: *DISCOVER_HOST_NODE1--KVM

        GetVm1IdFromManager1: *GET_VM1_ID

        AddVm4OnKVM1:
          <<: *ADD_VM1_ON_HOST1--KVM
          vm:
            '[4]':
              template: 'template_kvm_debian'
              vmstate: 'poweron'
              host: 'kvm.[1]'
              installtype: fullclone

        AddVIF1ToVM4:
          <<: *ADD_VIF1_TO_VM1
          Type: VM
          TestVM: 'vm.[4]'

        GetVm4IdFromManager1:
          <<: *GET_VM1_ID
          fabricvm:
              '[4]':
                  discover: 'true'
                  name: 'vm.[4]'

        GetVif1OfVm4FromManager1:
          <<: *GET_VIF1_OF_VM1_ON_KVM
          fabricvif:
              '[4]':
                  discover: 'true'
                  adapter_mac: 'vm.[4].vif.[1]'

        DeleteVM4:
          <<: *DELETE_VM
          deletevm: vm.[4]

        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--KVM

        UninstallNSXDAPackage:
            Type: Host
            TestHost: 'kvm.[1]'
            configure_package:
              execution_type: 'cmd'
              operation: uninstall
              resource:
                - 'nsx-da'

        InstallNSXDAPackage:
            Type: Host
            TestHost: 'kvm.[1]'
            configure_package:
              execution_type: 'cmd'
              operation: install
              resource:
                - '2627952:nsx-da-7.*rpm'

KVMVerifyInventoryPostNSXMPAReinstall:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "KVMVerifyInventoryPostNSXMPAReinstall"
    Summary: 'This test verify that inventory works fine after NSX-MPA vib re-installation'
    Procedure: '1. Register host with NSXManager and Discover it
                2. Get VM1 id from node1
                3. Uninstall nsx-mpa along with dependent packages i.e. nsx-cli and nsx-da
                4. Add VM4 on host1 and attach vif to it
                5. Install nsx-mpa and dependent packages
                6. Verify inventory'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
          - - RegisterHostNode1OnManager1
          - - DiscoverHostNode1
          - - GetVm1IdFromManager1
          - - DeregisterHostNode1FromManager1
          - - UninstallNSXMpaAndDependentPackagesFromHost1
          - - AddVm4OnKVM1
          - - AddVIF1ToVM4
        ExitSequence:
          - - InstallNSXMpaAndDependentPackagesOnHost1
          - - RegisterHostNode1OnManager1
          - - GetVm1IdFromManager1
          - - GetVm4IdFromManager1
          - - GetVif1OfVm4FromManager1
          - - DeleteVM4
          - - DeregisterHostNode1FromManager1

        RegisterHostNode1OnManager1: *SET_MANAGER--KVM

        DiscoverHostNode1: *DISCOVER_HOST_NODE1--KVM

        GetVm1IdFromManager1: *GET_VM1_ID

        AddVm4OnKVM1:
          <<: *ADD_VM1_ON_HOST1--KVM
          vm:
            '[4]':
              template: 'template_kvm_debian'
              vmstate: 'poweron'
              host: 'kvm.[1]'
              installtype: fullclone

        AddVIF1ToVM4:
          <<: *ADD_VIF1_TO_VM1
          Type: VM
          TestVM: 'vm.[4]'

        GetVm4IdFromManager1:
          <<: *GET_VM1_ID
          fabricvm:
              '[4]':
                  discover: 'true'
                  name: 'vm.[4]'

        GetVif1OfVm4FromManager1:
          <<: *GET_VIF1_OF_VM1_ON_KVM
          fabricvif:
              '[4]':
                  discover: 'true'
                  adapter_mac: 'vm.[4].vif.[1]'
        DeleteVM4:
          <<: *DELETE_VM
          deletevm: vm.[4]

        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--KVM

        UninstallNSXMpaAndDependentPackagesFromHost1:
            Type: Host
            TestHost: 'kvm.[1]'
            configure_package:
              execution_type: 'cmd'
              operation: uninstall
              resource:
                - 'nsxa'
                - 'nsx-da'
                - 'nsx-cli'
                - 'nsx-mpa'
        InstallNSXMpaAndDependentPackagesOnHost1:
            Type: Host
            TestHost: 'kvm.[1]'
            configure_package:
              execution_type: 'cmd'
              operation: install
              resource:
                - 'nsx-suite:master:beta:official:nsx-mpa-7.*rpm'
                - 'nsx-suite:master:beta:official:nsxa-7.*rpm'
                - 'nsx-suite:master:beta:official:nsx-cli-7.*rpm'
                - 'nsx-suite:master:beta:official:nsx-da-7.*rpm'

KVMRemoveNSXMPAWhenHostnodeNotRegisteredEvenOnce:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "KVMRemoveNSXMPAWhenHostnodeNotRegisteredEvenOnce"
    Summary: 'Inventory works fine after NSX-MPA vib re-installation when hostnode
              not registered even once'
    Procedure: '1. Setup has KVM host which is not registered with any MP-cluster node
                2. First remove and install nsx-mpa and its dependent packages
                   i.e. nsx-cli and nsx-da to make sure that host is in never used state
                3. Now uninstall nsx-mpa and its dependent packages
                4. Install nsx-mpa along with dependent packages
                5. Register and discover host1 with nsxmanager1
                6. Get VM1 ID from nsxmanager1
                7. Deregister host1 from nsxmanager1'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
          - - UninstallNSXMpaAndDependentPackagesFromHost1
          - - InstallNSXMpaAndDependentPackagesOnHost1
          - - UninstallNSXMpaAndDependentPackagesFromHost1
        ExitSequence:
          - - InstallNSXMpaAndDependentPackagesOnHost1
          - - RegisterHostNode1OnManager1
          - - DiscoverHostNode1
          - - GetVm1IdFromManager1
          - - DeregisterHostNode1FromManager1

        RegisterHostNode1OnManager1: *SET_MANAGER--KVM

        DiscoverHostNode1: *DISCOVER_HOST_NODE1--KVM

        GetVm1IdFromManager1: *GET_VM1_ID

        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--KVM

        UninstallNSXMpaAndDependentPackagesFromHost1:
            Type: Host
            TestHost: 'kvm.[1]'
            configure_package:
              execution_type: 'cmd'
              operation: uninstall
              resource:
                - 'nsx-da'
                - 'nsx-cli'
                - 'nsxa'
                - 'nsx-mpa'

        InstallNSXMpaAndDependentPackagesOnHost1:
            Type: Host
            TestHost: 'kvm.[1]'
            configure_package:
              execution_type: 'cmd'
              operation: install
              resource:
                - 'nsx-suite:master:beta:official:nsx-mpa-7.*rpm'
                - 'nsx-suite:master:beta:official:nsxa-7.*rpm'
                - 'nsx-suite:master:beta:official:nsx-cli-7.*rpm'
                - 'nsx-suite:master:beta:official:nsx-da-7.*rpm'

KVMVerifyDAServiceStateBasedOnHostRegistration:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "KVMVerifyDAServiceStateBasedOnHostRegistration"
    Summary: 'NSX-DA service is in running state only when host is registered'
    Procedure: '1. Verify nsx-da not running before host registration
                2. Register host with NSXManager and Discover it
                3. Verify nsx-da is in running state
                4. De-regiter host
                5. Verify that nsx-da now in stopped state'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
            - ['VerifyDANotRunning']
            - ['SetManagerOnKVM1']
            - ['DiscoverHostNode']
            - ['VerifyDARunning']
        ExitSequence:
            - ['RemoveNSXManagerOnKVM1']
            - ['VerifyDANotRunning']

        DiscoverHostNode: *DISCOVER_HOST_NODE1--KVM

        SetManagerOnKVM1:
          <<: *SET_MANAGER--KVM

        RemoveNSXManagerOnKVM1:
          <<: *REMOVE_NSX_MANAGER--KVM

        VerifyDANotRunning:
            Type: Host
            TestHost: 'kvm.[1]'
            execution_type: 'cmd'
            service_names:
              - 'nsx-da'
            sleepbetweenworkloads: 60
            get_service_status:
              'table[?]contain_once':
                  - service_name: nsx-da
                    service_status: stopped

        VerifyDARunning:
            Type: Host
            TestHost: 'kvm.[1]'
            execution_type: 'cmd'
            service_names:
              - 'nsx-da'
            sleepbetweenworkloads: 30
            get_service_status:
              'table[?]contain_once':
                  - service_name: nsx-da
                    service_status: started

KVMVerifyShowHostUUIDCLI:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "KVMVerifyShowHostUUIDCLI"
    Summary: 'This test runs and verify show host uuid cli on kvm host'
    Procedure: '1. Register host with NSXManager
                2. Discover host node
                3. Get VM1 ID
                4. Get fabric node external_id using API and persist this id
                5. Run show host uuid cli and verify the result with persisted id'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
            - ['SetManagerOnKVM1']
            - ['DiscoverHostNode']
            - ['GetExternalUUID']
            - ['VerifyHostUUID']
        ExitSequence:
            - ['RemoveNSXManagerOnKVM1']

        DiscoverHostNode: *DISCOVER_HOST_NODE1--KVM

        SetManagerOnKVM1: *SET_MANAGER--KVM

        RemoveNSXManagerOnKVM1: *REMOVE_NSX_MANAGER--KVM

        GetExternalUUID:
            Type: "Host"
            TestHost: "nsxmanager.[1].hostnode.[1]"
            PersistData: 'yes'
            read:
                'external_id[?]defined': ''

        VerifyHostUUID:
            Type: Host
            TestHost: 'kvm.[1]'
            execution_type: 'cli'
            get_host_uuid:
                'host_uuid[?]equal_to': 'nsxmanager.[1].hostnode.[1]->read->external_id'

KVMVerifyMPAConnectivityStatus:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "KVMVerifyMPAConnectivityStatus"
    Summary: 'This test verify mpa connectivity status of a fabric node'
    Procedure: '1. Register host with NSXManager
                2. Discover host node
                3. Verify that mpa connectivity status is UP
                4. Stop MPA service on host
                5. Verify that mpa connectivity status is DOWN now
                6. Start MPA service and verify that mpa connectivity status is UP again'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
            - ['SetManagerOnKVM1']
            - ['DiscoverHostNode']
            - ['VerifyMPAConnectivityIsUP']
            - ['StopMPAOnKVM1']
            - ['VerifyMPAConnectivityIsDown']
        ExitSequence:
            - ['StartMPAOnKVM1']
            - ['VerifyMPAConnectivityIsUP']
            - ['RemoveNSXManagerOnKVM1']

        DiscoverHostNode: *DISCOVER_HOST_NODE1--KVM

        SetManagerOnKVM1: *SET_MANAGER--KVM

        RemoveNSXManagerOnKVM1: *REMOVE_NSX_MANAGER--KVM

        VerifyMPAConnectivityIsUP:
            Type: "Host"
            TestHost: "nsxmanager.[1].hostnode.[1]"
            sleepbetweenworkloads: 60
            get_node_status:
                'mpa_connectivity_status[?]equal_to': 'UP'

        VerifyMPAConnectivityIsDown:
            Type: "Host"
            TestHost: "nsxmanager.[1].hostnode.[1]"
            sleepbetweenworkloads: 210
            get_node_status:
                'mpa_connectivity_status[?]equal_to': 'DOWN'

        StopMPAOnKVM1: *STOP_MPA--KVM

        StartMPAOnKVM1: *START_MPA--KVM

KVMAddNodeWithMultipleHostsToCluster:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,Inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "KVMAddNodeWithMultipleHostsToCluster"
    Summary: 'This test verifies that the host details get wiped out when MP
              node having multiple host registered added to MP cluster'
    Procedure: '1. This test make existing 3MP cluster into 2 clusters by removing and
                   cleaning MP node3, which makes MP node3 a single node cluster
                2. Register host1 with MP1 and host2, host3 with MP3
                3. Discover hosts and get VM1, VM2 and VM3 ID from respective MP nodes
                4. Now add MP node3 to cluster
                5. VM1 should get discovered from all 3 MP nodes
                6. Discovery of host2 and host3 from MP node3 should return Not_Found'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        <<: *INVENTORY_WORKLOADS
        <<: *MPClusteringConfigurationWorkloads
        <<: *MPClusteringVerificationWorkloads
        Sequence:
            - - CleanupMPNode3ForReuse
            - - RegisterHostNode1OnManager1
              - RegisterHostNode2OnManager3
              - RegisterHostNode3OnManager3
            - - DiscoverHostNode1OnManager1KVM
              - DiscoverHostNode1OnManager2KVM
              - DiscoverHostNode2OnManager3KVM
              - DiscoverHostNode3OnManager3KVM
            - - GetVm1IdFromManager1
              - GetVm1IdFromManager2
              - GetVm2IdFromManager3
              - GetVm3IdFromManager3
        ExitSequence:
            - - AddMPNode3ToCluster
            - - GetVm1IdFromManager1
              - GetVm1IdFromManager2
              - GetVm1IdFromManager3
            - - DiscoverHostNode2OnManager3NotFound
            - - DiscoverHostNode3OnManager3NotFound
            - - DeregisterHostNode1FromManager1
              - DeregisterHostNode2FromManager3
              - DeregisterHostNode3FromManager3


        RegisterHostNode1OnManager1: *SET_MANAGER--KVM

        RegisterHostNode2OnManager3:
            Type: Host
            TestHost: 'kvm.[2]'
            set_nsx_manager:
                manager_ip: 'nsxmanager.[3]'
                execution_type: 'cli'
                manager_thumbprint: 'nsxmanager.[3]'

        RegisterHostNode3OnManager3: *SET_MANAGER3_ON_NODE3--KVM

        DiscoverHostNode2OnManager3NotFound:
          <<: *DISCOVER_HOSTNODE2_ON_MANAGER3--KVM
          ExpectedResult:
              status_code: "NOT_FOUND"

        DiscoverHostNode3OnManager3NotFound:
          <<: *DISCOVER_HOSTNODE3_ON_MANAGER3--KVM
          ExpectedResult:
              status_code: "NOT_FOUND"

        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--KVM

        DeregisterHostNode2FromManager3:
          <<: *REMOVE_NSX_MANAGER--KVM
          TestHost: 'kvm.[2]'
          remove_nsx_manager:
              manager_ip: 'nsxmanager.[3]'
              execution_type: 'cli'
              manager_thumbprint: 'nsxmanager.[3]'

        DeregisterHostNode3FromManager3:
          <<: *REMOVE_NSX_MANAGER--KVM
          TestHost: 'kvm.[3]'
          remove_nsx_manager:
              manager_ip: 'nsxmanager.[3]'
              execution_type: 'cli'
              manager_thumbprint: 'nsxmanager.[3]'

KVMRemoveNsxCliWhileNsxdaAndNsxmpaStillInstalled:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "KVMRemoveNsxCliWhileNsxdaAndNsxmpaStillInstalled"
    Summary: 'nsx-cli package removal should throw dependency error when nsx-da
              is still installed'
    Procedure: '1. Start package removal and verify the dependency error message.'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
          - - UninstallNSXCliFromHost1

        UninstallNSXCliFromHost1:
            Type: Host
            TestHost: 'kvm.[1]'
            ExpectedResult:
                status_code: RUNTIME_ERROR
                error[?]match: |
                    Failed dependencies:\\n\\tnsx-cli is needed by \(installed\) nsx-da
            configure_package:
              execution_type: 'cmd'
              operation: uninstall
              resource:
                - 'nsx-cli'

KVMRemoveNsxmpaWhileNsxdaAndNsxcliStillInstalled:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "KVMRemoveNsxmpaWhileNsxdaAndNsxcliStillInstalled"
    Summary: 'nsx-mpa package removal should throw dependency error when nsx-da
              and nsx-cli is still installed'
    Procedure: '1. Start package removal and verify the dependency error message.'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
          - - UninstallNSXMpaFromHost1

        UninstallNSXMpaFromHost1:
            Type: Host
            TestHost: 'kvm.[1]'
            ExpectedResult:
                status_code: RUNTIME_ERROR
                error[?]match: |
                    Failed dependencies:
            configure_package:
              execution_type: 'cmd'
              operation: uninstall
              resource:
                - 'nsx-mpa'

KVMMPNodeRemovedFromCluster:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,Inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "KVMMPNodeRemovedFromCluster"
    Summary: 'Registered host inventory gets migrated when MP node removed from cluster'
    Procedure: '1. Create setup with three nsxmanager, three kvm each having one VM on it
                2. Register host1, host2 and host3 with all three nsxmanager respectively
                3. Discover host1 and get VM1 ID from all three MP nodes
                4. Now remove nsxmanager node3 from cluster
                5. VM3 should get discovered from nsxmanager 1 and 2
                6. Attach removed nsxmanager node to cluster
                7. Discovery of host3 from MP node3 should return Not_Found'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        <<: *INVENTORY_WORKLOADS
        <<: *MPClusteringConfigurationWorkloads
        <<: *MPClusteringVerificationWorkloads
        Sequence:
            - - RegisterHostNode1OnManager1
              - RegisterHostNode2OnManager2
              - RegisterHostNode3OnManager3
            - - DiscoverHostNode1OnManager1KVM
              - DiscoverHostNode1OnManager2KVM
              - DiscoverHostNode1OnManager3KVM
            - - GetVm1IdFromManager1
              - GetVm1IdFromManager2
              - GetVm1IdFromManager3
            - - CleanupMPNode3ForReuse
            - - DiscoverHostNode1OnManager1KVM
              - DiscoverHostNode1OnManager2KVM
              - DiscoverHostNode2OnManager1KVM
              - DiscoverHostNode2OnManager2KVM
              - DiscoverHostNode3OnManager1KVM
              - DiscoverHostNode3OnManager2KVM
            - - GetVm1IdFromManager1
              - GetVm1IdFromManager2
              - GetVm2IdFromManager1
              - GetVm2IdFromManager2
              - GetVm3IdFromManager1
              - GetVm3IdFromManager2
        ExitSequence:
            - - AddMPNode3ToCluster
            - - GetVm1IdFromManager1
              - GetVm1IdFromManager2
              - GetVm1IdFromManager3
#Follow-up work: Need to validate below behavior after bug#1446215 fix
#            - - DiscoverHostNode3OnManager3NotFound
            - - DeregisterHostNode1FromManager1
              - DeregisterHostNode2FromManager2
              - DeregisterHostNode3FromManager3

        RegisterHostNode1OnManager1: *SET_MANAGER--KVM

        RegisterHostNode2OnManager2: *SET_MANAGER2_ON_NODE2--KVM

        RegisterHostNode3OnManager3: *SET_MANAGER3_ON_NODE3--KVM

        DiscoverHostNode3OnManager3NotFound:
          <<: *DISCOVER_HOSTNODE3_ON_MANAGER3--KVM
          ExpectedResult:
              status_code: "NOT_FOUND"

        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--KVM

        DeregisterHostNode2FromManager2: *REMOVE_NSX_MANAGER2_ON_NODE2--KVM

        DeregisterHostNode3FromManager3: *REMOVE_NSX_MANAGER3_ON_NODE3--KVM

KVMInstallNsxdaWhenNsxmpaInstalledButNsxcliNotInstalled:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "KVMInstallNsxdaWhenNsxmpaInstalledButNsxcliNotInstalled"
    Summary: 'NSX-DA package installation should throw dependency error if NSX-CLI is not present'
    Procedure: '1. Remove NSX-DA and NSX-CLI packages from host1
                2. Installation of NSX-DA package on host1 throws NSX-CLI dependency error
                3. As part of exit process install both removed packages'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
          - - UninstallNSXCliAndNSXDaPackagesFromHost1
          - - InstallNSXDaWithoutInstallingNSXCliOnHost1
        ExitSequence:
          - - InstallNSXCliAndNSXDaPackagesOnHost1

        UninstallNSXCliAndNSXDaPackagesFromHost1:
            Type: Host
            TestHost: 'kvm.[1]'
            configure_package:
              execution_type: 'cmd'
              operation: uninstall
              resource:
                - 'nsx-da'
                - 'nsx-cli'

        InstallNSXDaWithoutInstallingNSXCliOnHost1:
            Type: Host
            TestHost: 'kvm.[1]'
            ExpectedResult:
                status_code: RUNTIME_ERROR
                error[?]match: |
                    Failed dependencies:\\n\\tnsx-cli is needed by nsx-da
            configure_package:
              execution_type: 'cmd'
              operation: install
              resource:
                - 'nsx-suite:master:beta:official:nsx-da-7.*rpm'

        InstallNSXCliAndNSXDaPackagesOnHost1:
            Type: Host
            TestHost: 'kvm.[1]'
            configure_package:
              execution_type: 'cmd'
              operation: install
              resource:
                - 'nsx-suite:master:beta:official:nsx-cli-7.*rpm'
                - 'nsx-suite:master:beta:official:nsx-da-7.*rpm'

KVMInstallNsxdaWhenBothNsxmpaAndNsxcliNotInstalled:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "KVMInstallNsxdaWhenBothNsxmpaAndNsxcliNotInstalled"
    Summary: 'NSX-DA package installation should throw dependency error if NSX-MPA
              and NSX-CLI is not present'
    Procedure: '1. Remove NSX-MPA, NSX-DA and NSX-CLI packages from host1
                2. Install NSX-DA package on host1 which throws NSX-MPA and NSX-CLI
                   dependency error
                3. As part of exit process install all removed packages'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
          - - UninstallNSXMpaNSXCliAndNSXDaPackagesFromHost1
          - - InstallNSXDaWithoutInstallingNSXMpaAndNSXCliOnHost1
        ExitSequence:
          - - InstallNSXMpaNSXCliAndDNSXDaPackagesOnHost1

        UninstallNSXMpaNSXCliAndNSXDaPackagesFromHost1:
            Type: Host
            TestHost: 'kvm.[1]'
            configure_package:
              execution_type: 'cmd'
              operation: uninstall
              resource:
                - 'nsx-da'
                - 'nsx-cli'
                - 'nsxa'
                - 'nsx-mpa'

        InstallNSXDaWithoutInstallingNSXMpaAndNSXCliOnHost1:
            Type: Host
            TestHost: 'kvm.[1]'
            ExpectedResult:
                status_code: RUNTIME_ERROR
                error[?]match: |
                    Failed dependencies:
            configure_package:
              execution_type: 'cmd'
              operation: install
              resource:
                - 'nsx-suite:master:beta:official:nsx-da-7.*rpm'

        InstallNSXMpaNSXCliAndDNSXDaPackagesOnHost1:
            Type: Host
            TestHost: 'kvm.[1]'
            configure_package:
              execution_type: 'cmd'
              operation: install
              resource:
                - 'nsx-suite:master:beta:official:nsx-mpa-7.*rpm'
                - 'nsx-suite:master:beta:official:nsxa-7.*rpm'
                - 'nsx-suite:master:beta:official:nsx-cli-7.*rpm'
                - 'nsx-suite:master:beta:official:nsx-da-7.*rpm'

KVMRemoveNsxmpaWhileHostNodeIsStillRegistered:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "KVMRemoveNsxmpaWhileHostNodeIsStillRegistered"
    Summary: 'NSX-MPA package removal should throw error if hostnode is still registered with MP'
    Procedure: '1. Register host1 with nsxmanager1
                2. Remove NSX-DA and NSX-CLI packages from host1
                3. Remove NSX-MPA package from host1 which should throw error message
                   saying de-register host before mpa uninstall
                4. Exit test with nsx-cli and nsx-da package install and host deregistration'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
          - - RegisterHostNode1OnManager1
          - - UninstallNSXCliAndNSXDaPackagesFromHost1
          - - VerifyNSXMpaUninstallFailure
        ExitSequence:
          - - InstallNSXCliAndNSXDaPackagesOnHost1
          - - DeregisterHostNode1FromManager1

        RegisterHostNode1OnManager1: *SET_MANAGER--KVM

        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--KVM

        UninstallNSXCliAndNSXDaPackagesFromHost1:
            Type: Host
            TestHost: 'kvm.[1]'
            configure_package:
              execution_type: 'cmd'
              operation: uninstall
              resource:
                - 'nsx-da'
                - 'nsx-cli'

        VerifyNSXMpaUninstallFailure:
            Type: Host
            TestHost: 'kvm.[1]'
            ExpectedResult:
                status_code: RUNTIME_ERROR
                error[?]match: |
                    Failed dependencies
            configure_package:
              execution_type: 'cmd'
              operation: uninstall
              resource:
                - 'nsx-mpa'

        InstallNSXCliAndNSXDaPackagesOnHost1:
            Type: Host
            TestHost: 'kvm.[1]'
            configure_package:
              execution_type: 'cmd'
              operation: install
              resource:
                - 'nsx-suite:master:beta:official:nsx-cli-7.*rpm'
                - 'nsx-suite:master:beta:official:nsx-da-7.*rpm'

KVMVerifyInventoryAfterAddingMaximumPermissibleVnicsInAVM:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "KVMVerifyInventoryAfterAddingMaximumPermissibleVnicsInAVM"
    Summary: 'Add maximum possible vifs to an KVM VM and verify all vnic IDs'
    Procedure: '1. Register host1 with NSXManager1
                2. Discover host node
                3. Add VM4 to host1
                4. Add 20 vifs to VM4
                5. Verify that all vifs are getting listed
                6. Remove VM4 as part of cleanup'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
            - - RegisterHostNode1OnManager1
            - - DiscoverHostNode
            - - AddVm4OnKVM1
            - - Add20VIFsToVM4
            - - GetVm4IdFromManager1
# Pending task: After creating 20 vifs the test started failing,need to confirm
# the maximum supported numbers
            - - GetAll20VifsOfVM4FromManager1
        ExitSequence:
            - - DeleteVM4
            - - DeregisterHostNode1FromManager1

        RegisterHostNode1OnManager1: *SET_MANAGER--KVM

        DiscoverHostNode: *DISCOVER_HOST_NODE1--KVM

        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--KVM

        DeleteVM4:
          <<: *DELETE_VM
          deletevm: 'vm.[4]'

        AddVm4OnKVM1:
          <<: *ADD_VM1_ON_HOST1--KVM
          vm:
            '[4]':
                template: 'rhel53-srv-32'
                host: 'kvm.[1]'

        Add20VIFsToVM4:
          Type: VM
          TestVM: 'vm.[4]'
          vif:
            '[1-20]':
                backing: 'kvm.[1].bridge.[1]'

        GetVm4IdFromManager1:
          <<: *GET_VM1_ID
          fabricvm:
              '[4]':
                  discover: 'true'
                  name: 'vm.[4]'

        GetAll20VifsOfVM4FromManager1:
          <<: *GET_VIF1_OF_VM1_ON_KVM
          TestNSX: "nsxmanager.[1]"
          fabricvif:
              '[1-20]':
                  discover: 'true'
                  adapter_mac: 'vm.[4].vif.[x]'

KVMHostFQDNChangeGetReflectInFabricNodeDisplayName:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "KVMHostFQDNChangeGetReflectInFabricNodeDisplayName"
    Summary: 'KVM host FQDN change get reflected in fabric node displayname'
    Procedure: '1. Register host with NSXManager
                2. Discover host node
                3. Query and save fabric node displayname and host FQDN
                4. Set new hostname and verify that fabric node displayname changed to
                   the new modified name
                5. Revert the hostname to its original'
    TestbedSpec: *3KVM_3NSXMANAGER_NESTED_IN_1ESX_NODE
    WORKLOADS:
        Sequence:
            - ['SetManagerOnKVM1']
            - ['DiscoverHostNode']
            - ['GetOriginalHostname']
            - ['SetNewHostname']
            - ['VerifyNewHostname']
            - ['VerifyUpdatedFabricNodeDisplayname']
        ExitSequence:
            - ['RevertOriginalHostname']
            - ['VerifyOriginalHostname']
            - ['RemoveNSXManagerOnKVM1']

        SetManagerOnKVM1: *SET_MANAGER--KVM

        DiscoverHostNode: *DISCOVER_HOST_NODE1--KVM

        RemoveNSXManagerOnKVM1: *REMOVE_NSX_MANAGER--KVM

        GetOriginalHostname:
            Type: "Host"
            TestHost: "kvm.[1]"
            PersistData: 'yes'
            execution_type: 'cmd'
            read_hostname:
                'hostname[?]defined': ''

        SetNewHostname:
            Type: "Host"
            TestHost: 'kvm.[1]'
            set_hostname:
              execution_type: 'cmd'
              hostname: 'newhostname.eng.vmware.com'

        VerifyNewHostname:
            Type: "Host"
            TestHost: 'kvm.[1]'
            execution_type: 'cmd'
            read_hostname:
                'hostname[?]equal_to': 'newhostname.eng.vmware.com'

        VerifyUpdatedFabricNodeDisplayname:
            Type: "Host"
            TestHost: "nsxmanager.[1].hostnode.[1]"
            sleepbetweenworkloads: 180
            read:
                'name[?]equal_to': 'newhostname.eng.vmware.com'

        RevertOriginalHostname:
            Type: "Host"
            TestHost: 'kvm.[1]'
            set_hostname:
              execution_type: 'cmd'
              hostname: 'kvm.[1]->read_hostname->hostname'

        VerifyOriginalHostname:
            Type: "Host"
            TestHost: 'kvm.[1]'
            execution_type: 'cmd'
            read_hostname:
                'hostname[?]equal_to': 'kvm.[1]->read_hostname->hostname'
