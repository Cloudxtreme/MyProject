!include ../AAA/CommonWorkloads.yaml
!include ../Clustering/MPCommonWorkloads.yaml
!include ../Clustering/TestbedSpec.yaml
!include CommonWorkloads.yaml
!include TestbedSpec.yaml

ESXRegisterNodeInvalidPassword:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies nsxcli returns correct error code if password is
    incorrect while registering hostnode in ESX"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "ESXDeregisterNodeInvalidPassword"
    Priority: "P2"
    Developer: "kchakraborty"
    Procedure: '1. Register a Fabric Host to inventory with incorrect password'
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_ESX_ONE_VM
    WORKLOADS:
        Sequence:
            - ['RegisterEsx1WithInvalidPassword']

        RegisterEsx1WithInvalidPassword: *REGISTER_NODE_WITH_INVALID_PASSWORD--ESX

ESXRegisterNodeInvalidThumbprint:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies nsxcli returns correct error code if Manager Thumbprint is
    incorrect while registering hostnode in ESX"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "ESXRegisterNodeInvalidThumbprint"
    Priority: "P2"
    Developer: "kchakraborty"
    Procedure: 'Register a Fabric Host to inventory with invalid thumbprint'
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_ESX_ONE_VM
    WORKLOADS:
        Sequence:
            - ['RegisterEsx1WithInvalidThumbprint']

        RegisterEsx1WithInvalidThumbprint: *REGISTER_NODE_WITH_INVALID_THUMBPRINT--ESX

ESXRegisterNodeInvalidUser:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies nsxcli returns correct error code if user is incorrect
    while registering hostnode in ESX"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "ESXRegisterNodeInvalidUser"
    Priority: "P2"
    Developer: "kchakraborty"
    Procedure: 'Register a Fabric Host to inventory with invalid user'
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_ESX_ONE_VM
    WORKLOADS:
        Sequence:
            - ['RegisterEsx1WithInvalidUser']

        RegisterEsx1WithInvalidUser: *REGISTER_NODE_WITH_INVALID_USER--ESX

ESXRegisterNodeUnreachableManager:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies nsxcli returns correct error code if Manager is
    unreachable while registering hostnode in ESX"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "ESXRegisterNodeUnreachableManager"
    Priority: "P2"
    Developer: "kchakraborty"
    Procedure: 'Register a Fabric Host to inventory with unreachable manager'
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_ESX_ONE_VM
    WORKLOADS:
        Sequence:
            - ['RegisterEsx1WithUnreachableManager']

        RegisterEsx1WithUnreachableManager: *REGISTER_NODE_WITH_UNREACHABLE_MANAGER--ESX

ESXDeregisterNodeInvalidPassword:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies nsxcli returns correct error code if password is
    incorrect while deregistering hostnode in ESX"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "ESXDeregisterNodeInvalidPassword"
    Priority: "P2"
    Developer: "kchakraborty"
    Procedure: '1. Deregister a Fabric Host to inventory with incorrect password'
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_ESX_ONE_VM
    WORKLOADS:
        Sequence:
            - ['SetManagerOnESX1']
            - ['DeregisterESX1WithInvalidPassword']
        ExitSequence:
            - ['RemoveNSXManagerOnESX1']

        SetManagerOnESX1: *SET_MANAGER--ESX
        DeregisterESX1WithInvalidPassword: *DEREGISTER_NODE_WITH_INVALID_PASSWORD--ESX
        RemoveNSXManagerOnESX1: *REMOVE_NSX_MANAGER--ESX

ESXDeregisterNodeInvalidThumbprint:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies nsxcli returns correct error code if Manager Thumbprint is
    incorrect while deregistering hostnode in ESX"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "ESXDeregisterNodeInvalidThumbprint"
    Priority: "P2"
    Developer: "kchakraborty"
    Procedure: '1. Deregister a Fabric Host to inventory with incorrect thumbprint'
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_ESX_ONE_VM
    WORKLOADS:
        Sequence:
            - ['SetManagerOnESX1']
            - ['DeregisterESX1WithInvalidThumbprint']
        ExitSequence:
            - ['RemoveNSXManagerOnESX1']

        SetManagerOnESX1: *SET_MANAGER--ESX
        DeregisterESX1WithInvalidThumbprint: *DEREGISTER_NODE_WITH_INVALID_THUMBPRINT--ESX
        RemoveNSXManagerOnESX1: *REMOVE_NSX_MANAGER--ESX

ESXDeregisterNodeInvalidUser:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies nsxcli returns correct error code if user is
    incorrect while deregistering hostnode in ESX"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "ESXDeregisterNodeInvalidUser"
    Priority: "P2"
    Developer: "kchakraborty"
    Procedure: '1. Deregister a Fabric Host to inventory with incorrect user'
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_ESX_ONE_VM
    WORKLOADS:
        Sequence:
            - ['SetManagerOnESX1']
            - ['DeregisterESX1WithInvalidUser']
        ExitSequence:
            - ['RemoveNSXManagerOnESX1']

        SetManagerOnESX1: *SET_MANAGER--ESX
        DeregisterESX1WithInvalidUser: *DEREGISTER_NODE_WITH_INVALID_USER--ESX
        RemoveNSXManagerOnESX1: *REMOVE_NSX_MANAGER--ESX

ESXDeregisterNodeUnreachableManager:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies nsxcli returns correct error code if Manager is unreachable
    while deregistering hostnode in ESX"
    Tags: nsx,avalanche
    Version: "2"
    TestName: "ESXDeregisterNodeUnreachableManager"
    Priority: "P2"
    Developer: "kchakraborty"
    Procedure: '1. Deregister a Fabric Host to inventory with unreachable manager'
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_ESX_ONE_VM
    WORKLOADS:
        Sequence:
            - ['SetManagerOnESX1']
            - ['DeregisterESX1WithUnreachableManager']
        ExitSequence:
            - ['RemoveNSXManagerOnESX1']

        SetManagerOnESX1: *SET_MANAGER--ESX
        DeregisterESX1WithUnreachableManager: *DEREGISTER_NODE_WITH_UNREACHABLE_MANAGER--ESX
        RemoveNSXManagerOnESX1: *REMOVE_NSX_MANAGER--ESX

ESXRegisterDeregisterHostNodeTacacasUser:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies nsxcli can regsiter and deregsiter node using Tacacas User in ESX"
    Tags: nsx,avalanche,cat
    Version: "2"
    TestName: "ESXRegisterDeregisterHostNodeTacacasUser"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Priority: "P2"
    Developer: "kchakraborty"
    Procedure: '1. Register an ESX host using Tacacs Server Credential
                2. Deregister an ESX host using Tacacs Server Credential'
    ExpectedResult: "PASS"
    TestbedSpec: *ONE_NSXMANAGER_ONE_ESX_ONE_VM
    WORKLOADS:
        <<: *AAA_WORKLOADS
        <<: *INVENTORY_WORKLOADS
        Sequence:
            - ["SetAAAId"]
            - ["UpdateProviderList"]
            - ["StopAuthServer"]
            - ["BackupDefaultConfig"]
            - ["AddUser"]
            - ["StartAuthServer"]
            - ["RegisterNodeWithTacacsUserESX"]
        ExitSequence:
            - ["DeregisterNodeWithTacacsUserESX"]
            - ["StopAuthServer"]
            - ["RestoreDefaultConfig"]
            - ["StartAuthServer"]

        RegisterNodeWithTacacsUserESX: *REGISTER_NODE_WITH_TACACS_USER--ESX
        DeregisterNodeWithTacacsUserESX: *DEREGISTER_NODE_WITH_TACACS_USER--ESX

ESXMPNodeGracefullyShutdown:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXMPNodeGracefullyShutdown"
    Summary: 'Verify ESX is shifted to new MP master and able to send inventory
              updates'
    Procedure: '1. Add VSS and Port Gourp on ESX1
                2. Register all 3 NSXManager
                3. Discover host node on all 3 ESX
                4. Get VM1 ID
                5. Power-off NSXManager 1
                6. Deploy 4th VM on ESX1
                7. Add Vnic on VM4
                8. Get VM4 ID from NSXManager 2 and 3
                9. Get VM4 Vnic from NSXManager 2 and 3'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
      <<: *MPClusteringVerificationWorkloads
      Sequence:
        - ['AddVSSOnEsx1']
        - ['AddPortGroupOnEsx1']
        - ['MapNSXManager1ToCluster']
        - ["RegisterHostNode1ToManager1",
           "RegisterHostNode2ToManager2",
           "RegisterHostNode3ToManager3"]
        - ['DiscoverHostNodes']
        - ['GetVm1Id']
        - ['PowerOffManager1']
        - ['AddVm4OnESX1']
        - ["AddVnic1VM4"]
        - ['GetVm4IdFromManager2', "GetVm4IdFromManager3"]
        - ['GetVnic1OfVM4FromManager2', 'GetVnic1OfVM4FromManager3']
      ExitSequence:
        - ['PowerOnManager1', "DeleteVM4"]
        - ["Wait_For_Cluster_Status_Stable_On_Node1"]
        - ["RemoveNSXManager3OnNode3",
           "RemoveNSXManager2OnNode2",
           "RemoveNSXManager1OnNode1"]
        - ['DeletePortgroupFromESX1']
        - ['DeleteVSSFromESX1']

      AddVSSOnEsx1: *ADD_VSS_ON_ESX1
      AddPortGroupOnEsx1: *ADD_PG_ON_ESX1
      RegisterHostNode1ToManager1: *SET_MANAGER--ESX
      RegisterHostNode2ToManager2: *SET_MANAGER2_ON_NODE2--ESX
      RegisterHostNode3ToManager3: *SET_MANAGER3_ON_NODE3--ESX
      DiscoverHostNodes: *DISCOVER_HOST_NODES--ESX
      GetVm1Id: *GET_VM1_ID
      PowerOffManager1: *POWER_OFF_MANAGER1
      AddVm4OnESX1:
        <<: *ADD_VM1_ON_HOST1--ESX
        vm:
          '[4]':
              template: 'rhel53-srv-32'
              host: 'esx.[1]'
      AddVnic1VM4:
        <<: *ADD_VNIC1_TO_VM1
        TestVM: 'vm.[4]'
      GetVm4IdFromManager2:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[2]"
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVm4IdFromManager3:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[3]"
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVnic1OfVM4FromManager2:
        <<: *GET_VNIC1_OF_VM1
        TestNSX: "nsxmanager.[2]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vnic.[1]'
      GetVnic1OfVM4FromManager3:
        <<: *GET_VNIC1_OF_VM1
        TestNSX: "nsxmanager.[3]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vnic.[1]'
      PowerOnManager1: *POWER_ON_MANAGER1
      DeleteVM4:
        <<: *DELETE_VM
        deletevm: vm.[4]
      RemoveNSXManager1OnNode1: *REMOVE_NSX_MANAGER--ESX
      RemoveNSXManager2OnNode2: *REMOVE_NSX_MANAGER2_ON_NODE2--ESX
      RemoveNSXManager3OnNode3: *REMOVE_NSX_MANAGER3_ON_NODE3--ESX
      DeletePortgroupFromESX1: *DELETE_PORTGROUP_FROM_ESX1
      DeleteVSSFromESX1: *DELETE_VSS_FROM_ESX1

ESXRestartMPAIn3NodeCluster:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXRestartMPAIn3NodeCluster"
    Summary: 'This test case verifies inventory updates are working fine in
              3 node MP cluster scenario'
    Procedure: '1. Add VSS and Port Gourp on ESX1
                2. Register all 3 NSXManager
                3. Discover host node on all 3 ESX
                4. Get VM1 ID
                5. Stop MPA on ESX1
                6. Deploy 4th VM on ESX1
                7. Add Vnic on VM4
                8. Start MPA on ESX1
                9. Get VM4 ID and Vnic from all 3 NSXManager'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
      <<: *MPClusteringVerificationWorkloads
      Sequence:
        - ['AddVSSOnEsx1']
        - ['AddPortGroupOnEsx1']
        - ['MapNSXManager1ToCluster']
        - ["RegisterHostNode1ToManager1",
           "RegisterHostNode2ToManager2",
           "RegisterHostNode3ToManager3"]
        - ['DiscoverHostNodes']
        - ['GetVm1Id']
        - ['StopMPAOnESX1']
        - ['AddVm4OnESX1']
        - ["AddVnic1VM4"]
        - ['StartMPAOnESX1']
        - ["Wait_For_Cluster_Status_Stable_On_Node1"]
        - ['GetVm4IdFromManager1',
           'GetVm4IdFromManager2',
           'GetVm4IdFromManager3']
        - ['GetVnic1OfVM4FromManager1',
           'GetVnic1OfVM4FromManager2',
           'GetVnic1OfVM4FromManager3']
      ExitSequence:
        - ["DeleteVM4"]
        - ["RemoveNSXManager3OnNode3",
           "RemoveNSXManager2OnNode2",
           "RemoveNSXManager1OnNode1"]
        - ['DeletePortgroupFromESX1']
        - ['DeleteVSSFromESX1']

      AddVSSOnEsx1: *ADD_VSS_ON_ESX1
      AddPortGroupOnEsx1: *ADD_PG_ON_ESX1
      RegisterHostNode1ToManager1: *SET_MANAGER--ESX
      RegisterHostNode2ToManager2: *SET_MANAGER2_ON_NODE2--ESX
      RegisterHostNode3ToManager3: *SET_MANAGER3_ON_NODE3--ESX
      DiscoverHostNodes: *DISCOVER_HOST_NODES--ESX
      GetVm1Id: *GET_VM1_ID
      StopMPAOnESX1: *STOP_MPA--ESX
      AddVm4OnESX1:
        <<: *ADD_VM1_ON_HOST1--ESX
        vm:
          '[4]':
              template: 'rhel53-srv-32'
              host: 'esx.[1]'
      AddVnic1VM4:
        <<: *ADD_VNIC1_TO_VM1
        TestVM: 'vm.[4]'
      StartMPAOnESX1: *START_MPA--ESX
      GetVm4IdFromManager1:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[1]"
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVm4IdFromManager2:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[2]"
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVm4IdFromManager3:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[3]"
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVnic1OfVM4FromManager1:
        <<: *GET_VNIC1_OF_VM1
        TestNSX: "nsxmanager.[1]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vnic.[1]'
      GetVnic1OfVM4FromManager2:
        <<: *GET_VNIC1_OF_VM1
        TestNSX: "nsxmanager.[2]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vnic.[1]'
      GetVnic1OfVM4FromManager3:
        <<: *GET_VNIC1_OF_VM1
        TestNSX: "nsxmanager.[3]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vnic.[1]'
      DeleteVM4:
        <<: *DELETE_VM
        deletevm: vm.[4]
      RemoveNSXManager1OnNode1: *REMOVE_NSX_MANAGER--ESX
      RemoveNSXManager2OnNode2: *REMOVE_NSX_MANAGER2_ON_NODE2--ESX
      RemoveNSXManager3OnNode3: *REMOVE_NSX_MANAGER3_ON_NODE3--ESX
      DeletePortgroupFromESX1: *DELETE_PORTGROUP_FROM_ESX1
      DeleteVSSFromESX1: *DELETE_VSS_FROM_ESX1

ESXAddMultipleHostsToMPNode:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXAddMultipleHostToMPNode"
    Summary: 'This test case verifies inventory updates are working fine in
              3 ESX host registered with single node MP scenario'
    Procedure: '1. Add VSS and Port Gourp on ESX1
                2. Register 3 ESX host with NSXManager
                3. Discover all 3 host node
                4. Get VM1, VM2 and VM3 ID
                5. Deploy VM4, VM4 and VM6 on ESX1, ESX2 and ESX3 respectively
                6. Add Vnic on VM4, VM5 and VM6
                7. Get VM4, VM5 and VM6 ID and Vnic from NSXManager'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
      Sequence:
        - ['AddVSSOnEsx1']
        - ['AddPortGroupOnEsx1']
        - ["RegisterHostNode1OnManager1",
           "RegisterHostNode2OnManager1",
           "RegisterHostNode3OnManager1"]
        - ['DiscoverHostNodes']
        - ["GetVm1Id", "GetVm2Id", "GetVm3Id"]
        - ['AddVm4OnESX1', 'AddVm5OnESX2', 'AddVm6OnESX3']
        - ["AddVnic1VM4", "AddVnic1VM5", "AddVnic1VM6"]
        - ['GetVm4IdFromManager1',
           'GetVm5IdFromManager1',
           'GetVm6IdFromManager1']
        - ['GetVnic1OfVM4FromManager1',
           'GetVnic1OfVM5FromManager1',
           'GetVnic1OfVM6FromManager1']
      ExitSequence:
        - ["DeleteVM4", "DeleteVM5", "DeleteVM6"]
        - ["DeregisterHostNode1FromManager1",
           "DeregisterHostNode2FromManager1",
           "DeregisterHostNode3FromManager1"]
        - ['DeletePortgroupFromESX1']
        - ['DeleteVSSFromESX1']

      AddVSSOnEsx1: *ADD_VSS_ON_ESX1
      AddPortGroupOnEsx1: *ADD_PG_ON_ESX1
      RegisterHostNode1OnManager1: *SET_MANAGER--ESX
      RegisterHostNode2OnManager1:
        <<: *SET_MANAGER--ESX
        TestHost: 'esx.[2]'
      RegisterHostNode3OnManager1:
        <<: *SET_MANAGER--ESX
        TestHost: 'esx.[3]'
      DiscoverHostNodes: *DISCOVER_HOST_NODES--ESX
      GetVm1Id: *GET_VM1_ID
      GetVm2Id:
        <<: *GET_VM1_ID
        fabricvm:
            '[2]':
                discover: 'true'
                name: 'vm.[2]'
      GetVm3Id:
        <<: *GET_VM1_ID
        fabricvm:
            '[3]':
                discover: 'true'
                name: 'vm.[3]'
      AddVm4OnESX1:
        <<: *ADD_VM1_ON_HOST1--ESX
        vm:
          '[4]':
              template: 'rhel53-srv-32'
              host: 'esx.[1]'
      AddVm5OnESX2:
        <<: *ADD_VM1_ON_HOST1--ESX
        vm:
          '[5]':
              template: 'rhel53-srv-32'
              host: 'esx.[2]'
      AddVm6OnESX3:
        <<: *ADD_VM1_ON_HOST1--ESX
        vm:
          '[6]':
              template: 'rhel53-srv-32'
              host: 'esx.[3]'
      AddVnic1VM4:
        <<: *ADD_VNIC1_TO_VM1
        TestVM: 'vm.[4]'
      AddVnic1VM5:
        <<: *ADD_VNIC1_TO_VM1
        TestVM: 'vm.[5]'
      AddVnic1VM6:
        <<: *ADD_VNIC1_TO_VM1
        TestVM: 'vm.[6]'
      GetVm4IdFromManager1:
        <<: *GET_VM1_ID
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVm5IdFromManager1:
        <<: *GET_VM1_ID
        fabricvm:
            '[5]':
                discover: 'true'
                name: 'vm.[5]'
      GetVm6IdFromManager1:
        <<: *GET_VM1_ID
        fabricvm:
            '[6]':
                discover: 'true'
                name: 'vm.[6]'
      GetVnic1OfVM4FromManager1:
        <<: *GET_VNIC1_OF_VM1
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vnic.[1]'
      GetVnic1OfVM5FromManager1:
        <<: *GET_VNIC1_OF_VM1
        fabricvif:
            '[5]':
                discover: 'true'
                adapter_mac: 'vm.[5].vnic.[1]'
      GetVnic1OfVM6FromManager1:
        <<: *GET_VNIC1_OF_VM1
        fabricvif:
            '[6]':
                discover: 'true'
                adapter_mac: 'vm.[6].vnic.[1]'
      DeleteVM4:
        <<: *DELETE_VM
        deletevm: vm.[4]
      DeleteVM5:
        <<: *DELETE_VM
        deletevm: vm.[5]
      DeleteVM6:
        <<: *DELETE_VM
        deletevm: vm.[6]
      DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--ESX
      DeregisterHostNode2FromManager1:
        <<: *REMOVE_NSX_MANAGER--ESX
        TestHost: 'esx.[2]'
      DeregisterHostNode3FromManager1:
        <<: *REMOVE_NSX_MANAGER--ESX
        TestHost: 'esx.[3]'
      DeletePortgroupFromESX1: *DELETE_PORTGROUP_FROM_ESX1
      DeleteVSSFromESX1: *DELETE_VSS_FROM_ESX1

ESXCascadedFailureOfNodesInCluster:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXCascadedFailureOfNodesInCluster"
    Summary: 'This test case verifies inventory updates are working fine after
              sequential shutdown of all 3 MP nodes'
    Procedure: '1. Add VSS and Port Gourp on ESX1
                2. Register ESX-1 host with NSXManager-1, ESX-2 host with
                NSXManager-2, ESX-3 host with NSXManager-3
                3. Discover all 3 host node
                4. Get VM1, VM2 and VM3 ID
                5. Poweroff all 3 NSXManager sequentially
                6. Deploy VM4 on ESX1
                7. Add Vnic on VM4
                8. Poweron all 3 NSXManager
                9. Get VM4 ID and Vnic info from all 3 NSXManager'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
      <<: *MPClusteringVerificationWorkloads
      Sequence:
        - ['AddVSSOnEsx1']
        - ['AddPortGroupOnEsx1']
        - ['MapNSXManager1ToCluster']
        - ["RegisterHostNode1OnManager1",
           "RegisterHostNode2OnManager2",
           "RegisterHostNode3OnManager3"]
        - ['DiscoverHostNodes']
        - ['GetVm1IdFromManager1',
           'GetVm2IdFromManager2',
           'GetVm2IdFromManager2']
        - ['PowerOffManager1']
        - ['PowerOffManager2']
        - ['PowerOffManager3', 'AddVm4OnESX1']
        - ["AddVnic1VM4"]
        - ['PowerOnManager1']
        - ['PowerOnManager2']
        - ['PowerOnManager3']
        - ["Wait_For_Cluster_Status_Stable_On_Node1"]
        - ['GetVm4IdFromManager1',
           'GetVm4IdFromManager2',
           'GetVm4IdFromManager3']
        - ['GetVnic1OfVM4FromManager1',
           'GetVnic1OfVM4FromManager2',
           'GetVnic1OfVM4FromManager3']
      ExitSequence:
        - ["DeleteVM4"]
        - ["DeregisterHostNode1FromManager1",
           "DeregisterHostNode2FromManager2",
           "DeregisterHostNode3FromManager3"]
        - ['DeletePortgroupFromESX1']
        - ['DeleteVSSFromESX1']

      AddVSSOnEsx1: *ADD_VSS_ON_ESX1
      AddPortGroupOnEsx1: *ADD_PG_ON_ESX1
      RegisterHostNode1OnManager1: *SET_MANAGER--ESX
      RegisterHostNode2OnManager2: *SET_MANAGER2_ON_NODE2--ESX
      RegisterHostNode3OnManager3: *SET_MANAGER3_ON_NODE3--ESX
      DiscoverHostNodes: *DISCOVER_HOST_NODES--ESX
      GetVm1IdFromManager1: *GET_VM1_ID
      GetVm2IdFromManager2:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[2]"
        fabricvm:
            '[2]':
                discover: 'true'
                name: 'vm.[2]'
      GetVm3IdFromManager3:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[3]"
        fabricvm:
            '[3]':
                discover: 'true'
                name: 'vm.[3]'
      PowerOffManager1: *POWER_OFF_MANAGER1
      PowerOffManager2:
        <<: *POWER_OFF_MANAGER1
        TestVM: "nsxmanager.[2]"
      PowerOffManager3:
        <<: *POWER_OFF_MANAGER1
        TestVM: "nsxmanager.[3]"
      AddVm4OnESX1:
        <<: *ADD_VM1_ON_HOST1--ESX
        vm:
          '[4]':
              template: 'rhel53-srv-32'
              host: 'esx.[1]'
      AddVnic1VM4:
        <<: *ADD_VNIC1_TO_VM1
        TestVM: 'vm.[4]'
      PowerOnManager1: *POWER_ON_MANAGER1
      PowerOnManager2:
        <<: *POWER_ON_MANAGER1
        TestVM: "nsxmanager.[2]"
      PowerOnManager3:
        <<: *POWER_ON_MANAGER1
        TestVM: "nsxmanager.[3]"
      GetVm4IdFromManager1:
        <<: *GET_VM1_ID
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVm4IdFromManager2:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[2]"
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVm4IdFromManager3:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[3]"
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVnic1OfVM4FromManager1:
        <<: *GET_VNIC1_OF_VM1
        TestNSX: "nsxmanager.[1]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vnic.[1]'
      GetVnic1OfVM4FromManager2:
        <<: *GET_VNIC1_OF_VM1
        TestNSX: "nsxmanager.[2]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vnic.[1]'
      GetVnic1OfVM4FromManager3:
        <<: *GET_VNIC1_OF_VM1
        TestNSX: "nsxmanager.[3]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vnic.[1]'
      DeleteVM4:
        <<: *DELETE_VM
        deletevm: vm.[4]
      DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--ESX
      DeregisterHostNode2FromManager2: *REMOVE_NSX_MANAGER2_ON_NODE2--ESX
      DeregisterHostNode3FromManager3: *REMOVE_NSX_MANAGER3_ON_NODE3--ESX
      DeletePortgroupFromESX1: *DELETE_PORTGROUP_FROM_ESX1
      DeleteVSSFromESX1: *DELETE_VSS_FROM_ESX1

ESXClusterRebootInOrder:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXClusterRebootInOrder"
    Summary: 'This test case verifies that inventory updates are working fine
              after MP cluster nodes sequential reboot'
    Procedure: '1. Add VSS and Port Gourp on ESX1
                2. Register 3 ESX host with NSXManager
                3. Discover all 3 host node
                4. Get VM1, VM2 and VM3 ID
                5. Verify cluster status from all 3 MP nodes
                6. Reboot MP cluster node-1
                7. Wait till node 1 comes UP and check cluster status from all nodes
                8. Reboot MP cluster node-2
                9. Wait till node 2 comes UP and check cluster status from all nodes
                10. Reboot MP cluster node-3 and simultaneously deploy VM4 on ESX1 and add Vnic
                11. Wait till node 3 comes UP and check cluster status from all nodes
                12. Get VM4 ID and Vnic info from all 3 NSXManager'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX

    WORKLOADS:
      <<: *MPClusteringVerificationWorkloads
      Sequence:
        - ['AddVSSOnEsx1']
        - ['AddPortGroupOnEsx1']
        - ['MapNSXManager1ToCluster']
        - ["RegisterHostNode1OnManager1",
           "RegisterHostNode2OnManager2",
           "RegisterHostNode3OnManager3"]
        - ['DiscoverHostNodes']
        - ['GetVm1IdFromManager1',
           'GetVm2IdFromManager2',
           'GetVm3IdFromManager3']
        - ["Wait_For_Cluster_Status_Stable_On_Node1"]
        - ["Restart_Node1"]
        - ["Wait_For_Cluster_Status_Stable_On_Node1"]
        - ["Restart_Node2"]
        - ["Wait_For_Cluster_Status_Stable_On_Node2"]
        - ["Restart_Node3", 'AddVm4OnESX1']
        - ["Wait_For_Cluster_Status_Stable_On_Node3",
           "AddVnic1VM4"]
        - ['GetVm4IdFromManager1',
           'GetVm4IdFromManager2',
           'GetVm4IdFromManager3']
        - ['GetVnic1OfVM4FromManager1',
           'GetVnic1OfVM4FromManager2',
           'GetVnic1OfVM4FromManager3']
      ExitSequence:
        - ["DeleteVM4"]
        - ["DeregisterHostNode1FromManager1",
           "DeregisterHostNode2FromManager2",
           "DeregisterHostNode3FromManager3"]
        - ['DeletePortgroupFromESX1']
        - ['DeleteVSSFromESX1']

      AddVSSOnEsx1: *ADD_VSS_ON_ESX1
      AddPortGroupOnEsx1: *ADD_PG_ON_ESX1
      RegisterHostNode1OnManager1: *SET_MANAGER--ESX
      RegisterHostNode2OnManager2: *SET_MANAGER2_ON_NODE2--ESX
      RegisterHostNode3OnManager3: *SET_MANAGER3_ON_NODE3--ESX
      DiscoverHostNodes: *DISCOVER_HOST_NODES--ESX
      GetVm1IdFromManager1: *GET_VM1_ID
      GetVm2IdFromManager2:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[2]"
        fabricvm:
            '[2]':
                discover: 'true'
                name: 'vm.[2]'
      GetVm3IdFromManager3:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[3]"
        fabricvm:
            '[3]':
                discover: 'true'
                name: 'vm.[3]'
      AddVm4OnESX1:
        <<: *ADD_VM1_ON_HOST1--ESX
        vm:
          '[4]':
              template: 'rhel53-srv-32'
              host: 'esx.[1]'
      AddVnic1VM4:
        <<: *ADD_VNIC1_TO_VM1
        TestVM: 'vm.[4]'
      GetVm4IdFromManager1:
        <<: *GET_VM1_ID
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVm4IdFromManager2:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[2]"
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVm4IdFromManager3:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[3]"
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVnic1OfVM4FromManager1:
        <<: *GET_VNIC1_OF_VM1
        TestNSX: "nsxmanager.[1]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vnic.[1]'
      GetVnic1OfVM4FromManager2:
        <<: *GET_VNIC1_OF_VM1
        TestNSX: "nsxmanager.[2]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vnic.[1]'
      GetVnic1OfVM4FromManager3:
        <<: *GET_VNIC1_OF_VM1
        TestNSX: "nsxmanager.[3]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vnic.[1]'
      DeleteVM4:
        <<: *DELETE_VM
        deletevm: vm.[4]
      DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--ESX
      DeregisterHostNode2FromManager2: *REMOVE_NSX_MANAGER2_ON_NODE2--ESX
      DeregisterHostNode3FromManager3: *REMOVE_NSX_MANAGER3_ON_NODE3--ESX
      DeletePortgroupFromESX1: *DELETE_PORTGROUP_FROM_ESX1
      DeleteVSSFromESX1: *DELETE_VSS_FROM_ESX1

ESXClusterRebootSimultaneous:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXClusterRebootSimultaneous"
    Summary: 'This test case verifies that inventory updates are working fine
              after MP cluster nodes simultaneous reboot'
    Procedure: '1. Add VSS and Port Gourp on ESX1
                2. Register 3 ESX host with NSXManager
                3. Discover all 3 host node
                4. Get VM1, VM2 and VM3 ID
                5. Verify cluster status from all 3 MP nodes
                6. Reboot all 3 MP cluster node simultaneously and while
                reboot is in progress deploy VM4 on ESX1 and add Vnic
                7. Wait till all node comes UP and check cluster status from all nodes
                8. Get VM4 ID and Vnic info from all 3 NSXManager'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX

    WORKLOADS:
      <<: *MPClusteringVerificationWorkloads
      Sequence:
        - ['AddVSSOnEsx1']
        - ['AddPortGroupOnEsx1']
        - ['MapNSXManager1ToCluster']
        - ["RegisterHostNode1OnManager1",
           "RegisterHostNode2OnManager2",
           "RegisterHostNode3OnManager3"]
        - ['DiscoverHostNodes']
        - ['GetVm1IdFromManager1',
           'GetVm2IdFromManager2',
           'GetVm3IdFromManager3']
        - ["Wait_For_Cluster_Status_Stable_On_Node1"]
        - ["Restart_Node1", "Restart_Node2",
           "Restart_Node3", "AddVm4OnESX1"]
        - ["AddVnic1VM4"]
        - ["Wait_For_Cluster_Status_Stable_On_Node1"]
        - ['GetVm1IdFromManager1',
           'GetVm2IdFromManager2',
           'GetVm3IdFromManager3']
        - ['GetVm4IdFromManager1',
           'GetVm4IdFromManager2',
           'GetVm4IdFromManager3']
        - ['GetVnic1OfVM4FromManager1',
           'GetVnic1OfVM4FromManager2',
           'GetVnic1OfVM4FromManager3']
      ExitSequence:
        - ["DeleteVM4"]
        - ["DeregisterHostNode1FromManager1",
           "DeregisterHostNode2FromManager2",
           "DeregisterHostNode3FromManager3"]
        - ['DeletePortgroupFromESX1']
        - ['DeleteVSSFromESX1']

      AddVSSOnEsx1: *ADD_VSS_ON_ESX1
      AddPortGroupOnEsx1: *ADD_PG_ON_ESX1
      RegisterHostNode1OnManager1: *SET_MANAGER--ESX
      RegisterHostNode2OnManager2: *SET_MANAGER2_ON_NODE2--ESX
      RegisterHostNode3OnManager3: *SET_MANAGER3_ON_NODE3--ESX
      DiscoverHostNodes: *DISCOVER_HOST_NODES--ESX
      GetVm1IdFromManager1: *GET_VM1_ID
      GetVm2IdFromManager2:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[2]"
        fabricvm:
            '[2]':
                discover: 'true'
                name: 'vm.[2]'
      GetVm3IdFromManager3:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[3]"
        fabricvm:
            '[3]':
                discover: 'true'
                name: 'vm.[3]'
      AddVm4OnESX1:
        <<: *ADD_VM1_ON_HOST1--ESX
        vm:
          '[4]':
              template: 'rhel53-srv-32'
              host: 'esx.[1]'
      AddVnic1VM4:
        <<: *ADD_VNIC1_TO_VM1
        TestVM: 'vm.[4]'
      GetVm4IdFromManager1:
        <<: *GET_VM1_ID
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVm4IdFromManager2:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[2]"
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVm4IdFromManager3:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[3]"
        fabricvm:
            '[4]':
                discover: 'true'
                name: 'vm.[4]'
      GetVnic1OfVM4FromManager1:
        <<: *GET_VNIC1_OF_VM1
        TestNSX: "nsxmanager.[1]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vnic.[1]'
      GetVnic1OfVM4FromManager2:
        <<: *GET_VNIC1_OF_VM1
        TestNSX: "nsxmanager.[2]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vnic.[1]'
      GetVnic1OfVM4FromManager3:
        <<: *GET_VNIC1_OF_VM1
        TestNSX: "nsxmanager.[3]"
        fabricvif:
            '[4]':
                discover: 'true'
                adapter_mac: 'vm.[4].vnic.[1]'
      DeleteVM4:
        <<: *DELETE_VM
        deletevm: vm.[4]
      DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--ESX
      DeregisterHostNode2FromManager2: *REMOVE_NSX_MANAGER2_ON_NODE2--ESX
      DeregisterHostNode3FromManager3: *REMOVE_NSX_MANAGER3_ON_NODE3--ESX
      DeletePortgroupFromESX1: *DELETE_PORTGROUP_FROM_ESX1
      DeleteVSSFromESX1: *DELETE_VSS_FROM_ESX1

ESXDAConnectTOMPNodeWithoutHostRegistration:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXDAConnectTOMPNodeWithoutHostRegistration"
    Summary: 'This test case verifies that host details are not getting posted to
              NSXManager when host unregistered from MP'
    Procedure: '1. Add VSS and Port Gourp on ESX1
                2. Register host node with NSXManager
                3. Discover host node
                4. Get VM1 from manager
                5. Unregister host node
                6. Verify VM1 now deleted from inventory
                7. Restart MPA and DA to flush out changes'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX

    WORKLOADS:
      Sequence:
        - ['AddVSSOnEsx1']
        - ['AddPortGroupOnEsx1']
        - ["RegisterHostNode1OnManager1"]
        - ['DiscoverHostNode1']
        - ['GetVm1IdFromManager1']
      ExitSequence:
        - ['UnregisterHostNode1']
        - ['VerifyVm1Deleted']
        - ['RestartMPA']
        - ['RestartDA']
        - ['DeletePortgroupFromESX1']
        - ['DeleteVSSFromESX1']

      AddVSSOnEsx1: *ADD_VSS_ON_ESX1
      AddPortGroupOnEsx1: *ADD_PG_ON_ESX1
      RegisterHostNode1OnManager1: *SET_MANAGER--ESX
      DiscoverHostNode1: *DISCOVER_HOST_NODE1--ESX
      GetVm1IdFromManager1: *GET_VM1_ID
      UnregisterHostNode1: *UNREGISTER_HOST_NODE1
      VerifyVm1Deleted: *VERIFY_VM1_DELETED
      RestartMPA: *RESTART_MPA--ESX
      RestartDA: *RESTART_DA--ESX
      DeletePortgroupFromESX1: *DELETE_PORTGROUP_FROM_ESX1
      DeleteVSSFromESX1: *DELETE_VSS_FROM_ESX1

ESXMpnodeWithoutAnyHostInventoryUpdatePostReboot:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXMpnodeWithoutAnyHostInventoryUpdatePostReboot"
    Summary: 'This test case verifies an MP node which does not have own inventory
              is able to fetch inventory of others post MP Node reboot'
    Procedure: '1. Register 2 ESX host with NSXManager
                2. Discover all 2 host node
                3. Get VM1 ID
                4. Reboot manager Nsxmanager 3
                5. Deploy VM4 on ESX1
                6. Get VM4 from all NSXManager'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        <<: *MPClusteringVerificationWorkloads
        Sequence:
            - ["RegisterHostNode1ToManager1",
               "RegisterHostNode2ToManager2"]
            - ['DiscoverHostNode1',
               'DiscoverHostNode2']
            - ['GetVm1Id']
            - ['Reboot_Node3_CLI']
            - ['AddVm4OnESX1']
            - ['GetVm4IdFromManager1',
               'GetVm4IdFromManager2',
               'GetVm4IdFromManager3']
        ExitSequence:
            - ["DeleteVM4"]
            - ["RemoveNSXManager2OnNode2",
               "RemoveNSXManager1OnNode1"]

        RegisterHostNode1ToManager1: *SET_MANAGER--ESX
        RegisterHostNode2ToManager2: *SET_MANAGER2_ON_NODE2--ESX
        DiscoverHostNode1: *DISCOVER_HOST_NODE1--ESX
        DiscoverHostNode2: *DISCOVER_HOST_NODE2--ESX
        GetVm1Id: *GET_VM1_ID
        AddVm4OnESX1: *ADD_VM4_ON_HOST1--ESX
        GetVm4IdFromManager1: *GET_VM4ID_FROM_MANAGER1
        GetVm4IdFromManager2:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[2]"
        GetVm4IdFromManager3:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[3]"
        DeleteVM4:
          <<: *DELETE_VM
          deletevm: vm.[4]
        RemoveNSXManager1OnNode1: *REMOVE_NSX_MANAGER--ESX
        RemoveNSXManager2OnNode2: *REMOVE_NSX_MANAGER2_ON_NODE2--ESX

ESXProtonServicesOfAllNodesDown:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXProtonServicesOfAllNodesDown"
    Summary: 'This test case verifies that inventory updates are working fine when some inventory changes happened
              while proton services are stopped in all nodes'
    Procedure: '1. Register all 3 NSXManager
                2. Discover host node on all 3 ESX
                3. Get VM1 ID
                4. Stop Proton Services on all nodes
                5. Deploy 4th VM on ESX1
                6. Add Vnic on VM4
                7. Start Proton Services on all nodes
                8. Get VM4 ID and Vnic from all 3 NSXManager
                9. Revert the changes as part of Exit sequence'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        <<: *MPClusteringVerificationWorkloads
        Sequence:
            - ['AddVSSOnEsx1']
            - ['AddPGOnEsx1']
            - ["MapNSXManager1ToCluster"]
            - ["RegisterHostNode1ToManager1",
               "RegisterHostNode2ToManager2",
               "RegisterHostNode3ToManager3"]
            - ['DiscoverHostNodes']
            - ['GetVm1Id']
            - ['SetProtonServiceIdFor_Node1']
            - ['StopProtonServiceOn_Node1']
            - ['StopProtonServiceOn_Node2']
            - ['StopProtonServiceOn_Node3']
            - ['AddVm4OnESX1']
            - ['AddVnic1VM4']
            - ['StartProtonServiceOn_Node1']
            - ['StartProtonServiceOn_Node2']
            - ['StartProtonServiceOn_Node3']
            - ["Wait_For_Cluster_Status_Stable_On_Node1"]
            - ['GetVm4IdFromManager1',
               'GetVm4IdFromManager2',
               'GetVm4IdFromManager3']
            - ['GetVnic1OfVM4FromManager1',
               'GetVnic1OfVM4FromManager2',
               'GetVnic1OfVM4FromManager3']
        ExitSequence:
            - ["DeleteVM4"]
            - ["RemoveNSXManager3OnNode3",
               "RemoveNSXManager2OnNode2",
               "RemoveNSXManager1OnNode1"]
            - ['DeletePortgroupFromESX1']
            - ['DeleteVSSFromESX1']

        AddVSSOnEsx1: *ADD_VSS_ON_ESX1
        AddPGOnEsx1: *ADD_PG_ON_ESX1
        RegisterHostNode1ToManager1: *SET_MANAGER--ESX
        RegisterHostNode2ToManager2: *SET_MANAGER2_ON_NODE2--ESX
        RegisterHostNode3ToManager3: *SET_MANAGER3_ON_NODE3--ESX
        DiscoverHostNodes: *DISCOVER_HOST_NODES--ESX
        RemoveNSXManager1OnNode1: *REMOVE_NSX_MANAGER--ESX
        RemoveNSXManager2OnNode2: *REMOVE_NSX_MANAGER2_ON_NODE2--ESX
        RemoveNSXManager3OnNode3: *REMOVE_NSX_MANAGER3_ON_NODE3--ESX
        GetVm4IdFromManager1: *GET_VM4ID_FROM_MANAGER1
        GetVm1Id: *GET_VM1_ID
        AddVm4OnESX1: *ADD_VM4_ON_HOST1--ESX
        DeletePortgroupFromESX1: *DELETE_PORTGROUP_FROM_ESX1
        DeleteVSSFromESX1: *DELETE_VSS_FROM_ESX1
        AddVnic1VM4:
          <<: *ADD_VNIC1_TO_VM1
          TestVM: 'vm.[4]'
        GetVm4IdFromManager2:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[2]"
        GetVm4IdFromManager3:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[3]"
        GetVnic1OfVM4FromManager1:
          <<: *GET_VNIC1_OF_VM1
          TestNSX: "nsxmanager.[1]"
          fabricvif:
              '[4]':
                  discover: 'true'
                  adapter_mac: 'vm.[4].vnic.[1]'
        GetVnic1OfVM4FromManager2:
          <<: *GET_VNIC1_OF_VM1
          TestNSX: "nsxmanager.[2]"
          fabricvif:
              '[4]':
                  discover: 'true'
                  adapter_mac: 'vm.[4].vnic.[2]'
        GetVnic1OfVM4FromManager3:
          <<: *GET_VNIC1_OF_VM1
          TestNSX: "nsxmanager.[3]"
          fabricvif:
              '[4]':
                  discover: 'true'
                  adapter_mac: 'vm.[4].vnic.[3]'
        DeleteVM4:
          <<: *DELETE_VM
          deletevm: vm.[4]

ESXOSVersionOfHost:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Summary: "This test case verifies os version of ESX is updated in NsxManager"
    Tags: "nsx,avalanche,inventory,cat"
    Version: "2"
    TestName: "ESXOSVersionOfHost"
    Priority: "P2"
    Developer: "kchakraborty"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Procedure: '1. Register a Host node
                2. Verify if Fabric Host is registered successfully
                3. Verify vms and vnic information are uploaded correctly to nsx manager
                4. Verify OS version of ess is updated in ESX'
    ExpectedResult: "PASS"
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        <<: *INVENTORY_WORKLOADS
        Sequence:
            - ['SetManagerOnESX1']
            - ['DiscoverHostNode']
            - ['GetVm1Id']
            - ['ReadOSVersionOnHostNode1']
        ExitSequence:
            - ['RemoveNSXManagerOnESX1']

        DiscoverHostNode: *DISCOVER_HOST_NODE1--ESX
        SetManagerOnESX1: *SET_MANAGER--ESX
        RemoveNSXManagerOnESX1: *REMOVE_NSX_MANAGER--ESX
        ReadOSVersionOnHostNode1: *READ_OSVERSION_ON_HOST_NODE1--ESX

ESXReregisterNodeToDifferentNodePostDeregister:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXReregisterNodeToDifferentNodePostDeregister"
    Summary: 'Verify ESX host can be registered to diffrent manager post
              registration from another manager'
    Procedure: '1. Register ESX1 with NSXManager 1
                2. Discover host node1
                3. Get VM1 ID on node 1
                4. Deregister host node 1
                5. Register ESX1 with NSXManager2
                6. Discover host node1
                7. Get VM1 ID on node 1'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
            - ["RegisterHostNode1ToManager1"]
            - ['DiscoverHostNode1']
            - ['GetVm1Id']
            - ["DeregisterHostNode1FromManager1"]
            - ["RegisterHostNode1ToManager2"]
            - ['DiscoverHostNode1']
            - ['GetVm1Id']
        ExitSequence:
            - ["DeregisterHostNode1FromManager2"]

        RegisterHostNode1ToManager1: *SET_MANAGER--ESX
        RegisterHostNode1ToManager2:
            Type: Host
            TestHost: 'esx.[1]'
            set_nsx_manager:
                manager_ip: 'nsxmanager.[2]'
                execution_type: 'cli'
                manager_thumbprint: 'nsxmanager.[2]'
        DiscoverHostNode1: *DISCOVER_HOST_NODE1--ESX
        GetVm1Id: *GET_VM1_ID
        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--ESX
        DeregisterHostNode1FromManager2:
          <<: *REMOVE_NSX_MANAGER--ESX
          remove_nsx_manager:
                manager_ip: 'nsxmanager.[2]'
                execution_type: 'cli'
                manager_thumbprint: 'nsxmanager.[2]'

ESXNetworkDisconnectBetweenMpAndHostNode:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXNetworkDisconnectBetweenMpAndHostNode"
    Summary: "This test case verifies inventory is updated after network disconnect
              with data generated during disconnect"
    Procedure: '1. Register a ESX1 to Nsxmanager1
                2. Verify vms and vnic information are uploaded correctly to nsx manager
                3. Network is disconnected between Host and Nsxmanager
                4. Add a new Vm on the host
                4. Network is restored between Host and Nsxmanager
                5. Verify new vm information is updated into nsx manager'
    ExpectedResult: "PASS"
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
            - ['AddVSSOnEsx1']
            - ['AddPGOnEsx1']
            - ['RegisterHostNode1ToManager1']
            - ['DiscoverHostNode']
            - ['GetVm1Id']
            - ['AddVnic1ToVM1']
            - ['GetVnic1OfVM1']
            - ['BlockHostNode1TrafficOnNode1']
            - ['AddVm4OnESX1']
            - ['AddVnic1VM4']
            - ['UnblockHostNode1TrafficOnNode1']
            - ['GetClients']
            - ['PingClient1']
            - ['GetVm4Id']
            - ['GetVnic1OfVM4']

        ExitSequence:
            - ['UnblockHostNode1TrafficOnNode1']
            - ['DeleteVM4']
            - ['DeleteVNIC1ofVM1']
            - ['DeregisterHostNode1FromManager1']
            - ['DeletePortgroupFromESX1']
            - ['DeleteVSSFromESX1']

        AddVSSOnEsx1: *ADD_VSS_ON_ESX1
        AddPGOnEsx1: *ADD_PG_ON_ESX1
        RegisterHostNode1ToManager1: *SET_MANAGER--ESX
        DiscoverHostNode: *DISCOVER_HOST_NODE1--ESX
        GetVm1Id: *GET_VM1_ID
        AddVnic1ToVM1: *ADD_VNIC1_TO_VM1
        GetVnic1OfVM1: *GET_VNIC1_OF_VM1
        AddVm4OnESX1: *ADD_VM4_ON_HOST1--ESX
        AddVnic1VM4:
          <<: *ADD_VNIC1_TO_VM1
          TestVM: 'vm.[4]'
        GetVm4Id: *GET_VM4ID_FROM_MANAGER1
        GetVnic1OfVM4:
          <<: *GET_VNIC1_OF_VM1
          TestNSX: "nsxmanager.[1]"
          fabricvif:
              '[4]':
                  discover: 'true'
                  adapter_mac: 'vm.[4].vnic.[1]'
        DeleteVM4:
          <<: *DELETE_VM
          deletevm: vm.[4]
        DeleteVNIC1ofVM1: *DELETE_VNIC1_OF_VM1
        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--ESX
        BlockHostNode1TrafficOnNode1: *BLOCK_HOSTNODE1_TRAFFIC_ON_NODE1--ESX
        UnblockHostNode1TrafficOnNode1: *UNBLOCK_HOSTNODE1_TRAFFIC_ON_NODE1--ESX
        GetClients: *GET_CLIENTS
        PingClient1: *PING_CLIENT_1
        DeletePortgroupFromESX1: *DELETE_PORTGROUP_FROM_ESX1
        DeleteVSSFromESX1: *DELETE_VSS_FROM_ESX1

ESXMPNodeUnreachableToClusterButConnectedToHost:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: 'ESXMPNodeUnreachableToClusterButConnectedToHost'
    Summary: 'This test case verifies that the Inventory is working fine when
              node 2 and 3 are disconnected from node 1 but host is still registered'
    Procedure: '1. Register hosts with managers
                2. Discover hostnodes
                3. Block MP node 2 and 3 traffic on node 1
                4. Deploy VM4 on host 1
                5. Get VM4 ID from node 2 and 3
                6. Unblock both nodes and verify proton service on node1
                7. Get VM4 ID from node1
                8. Cleanup the test created data'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        <<: *MPClusteringVerificationWorkloads
        <<: *MPClusteringConfigurationWorkloads
        Sequence:
            - ["GetMPNode1Id"]
            - ["MapNSXManager1ToCluster"]
            - ["RegisterHostNode1ToManager1",
               "RegisterHostNode2ToManager2",
               "RegisterHostNode3ToManager3"]
            - ['DiscoverHostNodes']
            - ["BlockMPNode2Traffic_On_Node1",
               "BlockMPNode3Traffic_On_Node1"]
            - ["Wait_For_Cluster_Status_Stable_On_Node1"]
            - ['AddVm4OnESX1']
            - ['GetVm4IdFromManager2']
            - ['GetVm4IdFromManager3']
        ExitSequence:
            - ["UnBlockMPNode2Traffic_On_Node1",
               "UnBlockMPNode3Traffic_On_Node1"]
            - ["SetProtonServiceIdFor_Node1"]
            - ["RestartProtonServiceOn_Node1"]
            - ["Wait_For_Cluster_Status_Stable_On_Node1"]
            - ['GetVm4IdFromManager1']
            - ["DeleteVM4"]
            - ["DeregisterHostNode3FromManager3",
               "DeregisterHostNode2FromManager2",
               "DeregisterHostNode1FromManager1"]

        RegisterHostNode1ToManager1: *SET_MANAGER--ESX
        RegisterHostNode2ToManager2: *SET_MANAGER2_ON_NODE2--ESX
        RegisterHostNode3ToManager3: *SET_MANAGER3_ON_NODE3--ESX
        DiscoverHostNodes: *DISCOVER_HOST_NODES--ESX
        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--ESX
        DeregisterHostNode2FromManager2: *REMOVE_NSX_MANAGER2_ON_NODE2--ESX
        DeregisterHostNode3FromManager3: *REMOVE_NSX_MANAGER3_ON_NODE3--ESX
        GetVm1Id: *GET_VM1_ID
        AddVm4OnESX1: *ADD_VM4_ON_HOST1--ESX
        GetVm4IdFromManager1: *GET_VM4ID_FROM_MANAGER1
        GetVm4IdFromManager2:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[2]"
        GetVm4IdFromManager3:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[3]"
        DeleteVM4:
          <<: *DELETE_VM
          deletevm: vm.[4]

ESXNetworkDisconnectBetweenMpNodeAndHostDuringInventorySync:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    Summary: "This test case verifies inventory is updated correctly post network
              disconnection during Inventory"
    TestName: "ESXNetworkDisconnectBetweenMpNodeAndHostDuringInventorySync"
    Procedure: '1. Register a ESX1 to Nsxmanager1
                2. Verify VMs and vnic information are uploaded correctly to nsx manager
                3. Add a new Vm on the host
                4. Network is disconnected between Host and Nsxmanager while deployment started
                4. Network is restored between Host and Nsxmanager
                5. Verify new vm information is updated into nsx manager'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
            - ['RegisterHostNode1ToManager1']
            - ['DiscoverHostNode']
            - ['GetVm1Id']
            - ['AddVm4OnESX1', 'BlockHostNode1TrafficOnNode1']
            - ['UnblockHostNode1TrafficOnNode1']
            - ['GetClients']
            - ['PingClient1']
            - ['GetVm4Id']
        ExitSequence:
            - ['DeleteVm4']
            - ['DeregisterHostNode1FromManager1']

        RegisterHostNode1ToManager1: *SET_MANAGER--ESX
        DiscoverHostNode: *DISCOVER_HOST_NODE1--ESX
        GetVm1Id: *GET_VM1_ID
        AddVm4OnESX1: *ADD_VM4_ON_HOST1--ESX
        GetVm4Id: *GET_VM4ID_FROM_MANAGER1
        BlockHostNode1TrafficOnNode1: *BLOCK_HOSTNODE1_TRAFFIC_ON_NODE1--ESX
        UnblockHostNode1TrafficOnNode1: *UNBLOCK_HOSTNODE1_TRAFFIC_ON_NODE1--ESX
        GetClients: *GET_CLIENTS
        PingClient1: *PING_CLIENT_1
        DeleteVm4:
          <<: *DELETE_VM
          deletevm: vm.[4]
        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--ESX

ESXMpnodeWithoutAnyHostInventoryUpdate:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXMpnodeWithoutAnyHostInventoryUpdate"
    Summary: 'This test case verifies an mp node which does not have own
              inventory is able to fetch inventory of others'
    Procedure: '1. Register 2 ESX host with NSXManager
                2. Discover all 2 host node
                3. Get VM1 ID
                4. Deploy VM4 on ESX1
                5. Get VM4 ID from all NSXManager'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
            - ["RegisterHostNode1ToManager1",
               "RegisterHostNode2ToManager2"]
            - ['DiscoverHostNode1',
               'DiscoverHostNode2']
            - ['GetVm1Id']
            - ['AddVm4OnESX1']
            - ['GetVm4IdFromManager1',
               'GetVm4IdFromManager2',
               'GetVm4IdFromManager3']
        ExitSequence:
            - ["DeleteVM4"]
            - ["DeregisterHostNode2FromManager2",
               "DeregisterHostNode1FromManager1"]

        RegisterHostNode1ToManager1: *SET_MANAGER--ESX
        RegisterHostNode2ToManager2: *SET_MANAGER2_ON_NODE2--ESX
        DiscoverHostNode1: *DISCOVER_HOST_NODE1--ESX
        DiscoverHostNode2: *DISCOVER_HOST_NODE2--ESX
        GetVm1Id: *GET_VM1_ID
        AddVm4OnESX1: *ADD_VM4_ON_HOST1--ESX
        GetVm4IdFromManager1: *GET_VM4ID_FROM_MANAGER1
        GetVm4IdFromManager2:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[2]"
        GetVm4IdFromManager3:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[3]"
        DeleteVM4:
          <<: *DELETE_VM
          deletevm: vm.[4]
        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--ESX
        DeregisterHostNode2FromManager2: *REMOVE_NSX_MANAGER2_ON_NODE2--ESX

ESXRegisterHostNodeClusterReadOnly:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: 'ESXRegisterHostNodeClusterReadOnly:'
    Summary: 'To verify HostNode Registration fails  if cluster is in READ only state'
    Procedure: '1. Create  a cluster of 3 node n1,n2 and n3
                2. Stop Proton service in n2 and n3
                3. Try to regsiter a ESX in n1
                4. Host Node Registration should fail'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        <<: *MPClusteringVerificationWorkloads
        <<: *MPClusteringConfigurationWorkloads
        Sequence:
            - ["SetProtonServiceIdFor_Node2"]
            - ["GetMPNode1Id"]
            - ["MapNSXManager1ToCluster"]
            - ["VerifyClusterMembers_3MP"]
            - ["StopProtonServiceOn_Node2"]
            - ["StopProtonServiceOn_Node3"]
            - ["Wait_For_Cluster_Status_Unstable_On_Node1"]
            - ["RegisterHostNode1ToManager1Failed"]
        ExitSequence:
            - ["StartProtonServiceOn_Node2"]
            - ["StartProtonServiceOn_Node3"]
            - ["Wait_For_Cluster_Status_Stable_On_Node1"]
            - ["VerifyClusterStatusFrom_Node1"]
            - ["VerifyClusterStatusFrom_Node2"]
            - ["VerifyClusterStatusFrom_Node3"]

        RegisterHostNode1ToManager1Failed: *REGISTER_NODE_EXPECT_FAILURE--ESX

ESXInventoryChangeWhenClusterReadOnly:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: 'ESXInventoryChangeWhenClusterReadOnly'
    Summary: 'To verify if inventory is changed while cluster is in READ ONLY state
              nsx-da  is able to send update once cluster is stable'
    Procedure: '1. Create  a cluster of 3 node n1,n2 and n3
                2. Add ESX one to node 1
                3. Stop Proton service in n2 and n3
                4. Deploy vm1
                5. Verify read vm1 fails
                6. Restore all nodes of cluster to a stable state
                7. Verify inventory update of vm1 is received'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        <<: *MPClusteringVerificationWorkloads
        <<: *MPClusteringConfigurationWorkloads
        Sequence:
            - ["RegisterHostNode1ToManager1"]
            - ["DiscoverHostNode1"]
            - ["SetProtonServiceIdFor_Node2"]
            - ["GetMPNode1Id"]
            - ["MapNSXManager1ToCluster"]
            - ["VerifyClusterMembers_3MP"]
            - ["StopProtonServiceOn_Node2"]
            - ["StopProtonServiceOn_Node3"]
            - ["Wait_For_Cluster_Status_Unstable_On_Node1"]
            - ['AddVm4OnESX1']
            - ['VerifyVm4NotAddedInIneventory']
        ExitSequence:
            - ["StartProtonServiceOn_Node2"]
            - ["StartProtonServiceOn_Node3"]
            - ["Wait_For_Cluster_Status_Stable_On_Node1"]
            - ['GetVm4IdFromManager1',
               'GetVm4IdFromManager2',
               'GetVm4IdFromManager3']
            - ["DeleteVM4"]
            - ["DeregisterHostNode1FromManager1"]

        RegisterHostNode1ToManager1: *SET_MANAGER--ESX
        DiscoverHostNode1: *DISCOVER_HOST_NODE1--ESX
        AddVm4OnESX1: *ADD_VM4_ON_HOST1--ESX
        VerifyVm4NotAddedInIneventory:
            Type: "Inventory"
            TestInventory: "nsxmanager.[1].fabricvm.[4]"
            ExpectedResult:
                status_code: SERVICE_UNAVAILABLE
            get_inventoryobject_list:
              'result_count[?]equal_to': 2
        GetVm4IdFromManager1: *GET_VM4ID_FROM_MANAGER1
        GetVm4IdFromManager2:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[2]"
        GetVm4IdFromManager3:
          <<: *GET_VM4ID_FROM_MANAGER1
          TestNSX: "nsxmanager.[3]"
        DeleteVM4:
          <<: *DELETE_VM
          deletevm: vm.[4]
        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--ESX

ESXInventoryGatingTest:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "kchakraborty"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,gating_test_cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXInventoryGatingTest"
    Summary: 'This test case verifies inventory updates are working fine in
              3 node MP cluster scenario'
    Procedure: '1. Verify Vm1 details from ESX1 is uploaded in 3 nsx managers
                2. Verify Vm2 details from ESX2 is uploaded in 3 nsx managers
                3. Stop MPA in ESX1
                4. Deploy Vm5 in ESX1 and a nic is added in ESX1 and Started MPA
                5. Verify Vm5 and its nic details from ESX1 is uploaded in 3 nsx managers
                6. delete nic of Vm5
                7. Verify deleted nic details are not anymore present in 3 nsx managers
                8. Deleted Vm5
                9. Verify deleted Vm5 details are not anymore present in 3 nsx managers
                10. Restarted nsx manager1
                11. Deploy Vm5 in ESX1 and a nic is added in ESX1
                12. Verify Vm5 details from ESX1 is uploaded in 3 nsx managers'
    TestbedSpec: *3MP_3CCP_4ESX
    WORKLOADS:
        <<: *MPClusteringVerificationWorkloads
        <<: *MPClusteringConfigurationWorkloads
        Sequence:
          - ['GetMPNode1Id']
          - ['MapNSXManager1ToCluster']
          - ['AddVSSOnEsx1']
          - ['AddPortGroupOnEsx1']
          - ['GetVm1IdFromManager1',
             'GetVm1IdFromManager2',
             'GetVm1IdFromManager3']
          - ['GetVm2IdFromManager1',
             'GetVm2IdFromManager2',
             'GetVm2IdFromManager3']
          - ['StopMPAOnESX1']
          - ['AddVm5OnESX1']
          - ['AddVnic1VM5']
          - ['StartMPAOnESX1']
          - ['GetVm5IdFromManager1',
             'GetVm5IdFromManager2',
             'GetVm5IdFromManager2']
          - ['GetVnic1OfVM5FromManager1',
             'GetVnic1OfVM5FromManager2',
             'GetVnic1OfVM5FromManager2']
          - ['DeleteVnic1VM5']
          - ['VerifyVnic1OfVM5DeletedFromManager1',
             'VerifyVnic1OfVM5DeletedFromManager2',
             'VerifyVnic1OfVM5DeletedFromManager3']
          - ['DeleteVM5']
          - ['VerifyVM5DeletedFromManager1',
             'VerifyVM5DeletedFromManager2',
             'VerifyVM5DeletedFromManager3']
          - ['RestartManagerAppliance']
          - ['AddVm5OnESX1']
          - ['AddVnic1VM5']
          - ['Wait_For_Cluster_Status_Stable_On_Node1']
          - ['GetVm5IdFromManager1',
             'GetVm5IdFromManager2',
             'GetVm5IdFromManager3']
          - ['GetVnic1OfVM5FromManager1',
             'GetVnic1OfVM5FromManager2',
             'GetVnic1OfVM5FromManager3']
        ExitSequence:
          - ['DeleteVM5']
          - ['DeletePortgroupFromESX1']
          - ['DeleteVSSFromESX1']

        AddVSSOnEsx1: *ADD_VSS_ON_ESX1
        AddPortGroupOnEsx1: *ADD_PG_ON_ESX1
        GetVm1IdFromManager1: *GET_VM1_ID
        StopMPAOnESX1: *STOP_MPA--ESX
        RestartManagerAppliance: *RESTART_MANAGER_APPLIANCE
        DeletePortgroupFromESX1: *DELETE_PORTGROUP_FROM_ESX1
        DeleteVSSFromESX1: *DELETE_VSS_FROM_ESX1
        AddVm5OnESX1:
          <<: *ADD_VM1_ON_HOST1--ESX
          vm:
            '[5]':
                template: 'rhel53-srv-32'
                host: 'esx.[1]'
        AddVnic1VM5:
          <<: *ADD_VNIC1_TO_VM1
          TestVM: 'vm.[5]'
        StartMPAOnESX1: *START_MPA--ESX
        GetVm5IdFromManager1:
          <<: *GET_VM1_ID
          TestNSX: "nsxmanager.[1]"
          fabricvm:
              '[5]':
                  discover: 'true'
                  name: 'vm.[5]'
        GetVm5IdFromManager2:
          <<: *GET_VM1_ID
          TestNSX: "nsxmanager.[2]"
          fabricvm:
              '[5]':
                  discover: 'true'
                  name: 'vm.[5]'
        GetVm5IdFromManager3:
          <<: *GET_VM1_ID
          TestNSX: "nsxmanager.[3]"
          fabricvm:
              '[5]':
                  discover: 'true'
                  name: 'vm.[5]'
        GetVm1IdFromManager2:
          <<: *GET_VM1_ID
          TestNSX: "nsxmanager.[2]"
        GetVm1IdFromManager3:
          <<: *GET_VM1_ID
          TestNSX: "nsxmanager.[3]"
        GetVm2IdFromManager1:
          <<: *GET_VM1_ID
          fabricvm:
              '[2]':
                  discover: 'true'
                  name: 'vm.[2]'
        GetVm2IdFromManager2:
          <<: *GET_VM1_ID
          TestNSX: "nsxmanager.[2]"
          fabricvm:
              '[2]':
                  discover: 'true'
                  name: 'vm.[2]'
        GetVm2IdFromManager3:
          <<: *GET_VM1_ID
          TestNSX: "nsxmanager.[3]"
          fabricvm:
              '[2]':
                  discover: 'true'
                  name: 'vm.[2]'
        GetVnic1OfVM5FromManager1:
          <<: *GET_VNIC1_OF_VM1
          TestNSX: "nsxmanager.[1]"
          fabricvif:
              '[5]':
                  discover: 'true'
                  adapter_mac: 'vm.[5].vnic.[1]'
        GetVnic1OfVM5FromManager2:
          <<: *GET_VNIC1_OF_VM1
          TestNSX: "nsxmanager.[2]"
          fabricvif:
              '[5]':
                  discover: 'true'
                  adapter_mac: 'vm.[5].vnic.[1]'
        GetVnic1OfVM5FromManager3:
          <<: *GET_VNIC1_OF_VM1
          TestNSX: "nsxmanager.[3]"
          fabricvif:
              '[5]':
                  discover: 'true'
                  adapter_mac: 'vm.[5].vnic.[1]'
        DeleteVM5:
          <<: *DELETE_VM
          deletevm: vm.[5]
        DeleteVnic1VM5:
          <<: *DELETE_VNIC1_OF_VM1
          TestVM: 'vm.[5]'
          deletevnic: 'vm.[5].vnic.[1]'
        VerifyVnic1OfVM5DeletedFromManager1:
          <<: *VERIFY_VIF1_OF_VM1_DELETED
          TestInventory: "nsxmanager.[1].fabricvif.[5]"
          get_inventoryobject_list:
              'results[?]not_contains':
                   - id_: 'nsxmanager.[1].fabricvif.[5]->id'
        VerifyVnic1OfVM5DeletedFromManager2:
          <<: *VERIFY_VIF1_OF_VM1_DELETED
          TestInventory: "nsxmanager.[2].fabricvif.[5]"
          get_inventoryobject_list:
              'results[?]not_contains':
                   - id_: 'nsxmanager.[2].fabricvif.[5]->id'
        VerifyVnic1OfVM5DeletedFromManager3:
          <<: *VERIFY_VIF1_OF_VM1_DELETED
          TestInventory: "nsxmanager.[3].fabricvif.[5]"
          get_inventoryobject_list:
              'results[?]not_contains':
                   - id_: 'nsxmanager.[3].fabricvif.[5]->id'
        VerifyVM5DeletedFromManager1:
          <<: *VERIFY_VM1_DELETED
          TestInventory: "nsxmanager.[1].fabricvm.[5]"
          get_inventoryobject_list:
              'results[?]not_contains':
                   - id_: 'nsxmanager.[1].fabricvm.[5]->id'
        VerifyVM5DeletedFromManager2:
          <<: *VERIFY_VM1_DELETED
          TestInventory: "nsxmanager.[2].fabricvm.[5]"
          get_inventoryobject_list:
              'results[?]not_contains':
                   - id_: 'nsxmanager.[2].fabricvm.[5]->id'
        VerifyVM5DeletedFromManager3:
          <<: *VERIFY_VM1_DELETED
          TestInventory: "nsxmanager.[3].fabricvm.[5]"
          get_inventoryobject_list:
              'results[?]not_contains':
                   - id_: 'nsxmanager.[3].fabricvm.[5]->id'

ESXRegisterHostWithEmptyInventory:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXRegisterHostWithEmptyInventory"
    Summary: 'Verify no inventory updates send if host is not registered'
    Procedure: '1. Delete VM from host
                2. Register host with NSXManager
                3. Discover host
                4. Get VM ID which should fail
                5. Deploy a new VM to host
                6. Add Vnic on VM
                7. Get VM ID from NSXManager
                8. Get VM4 Vnic from NSXManager'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
      Sequence:
        - - AddVSSOnEsx3
        - - AddPortGroupOnEsx3
        - - DeleteVM3
        - - RegisterHostNode3ToManager3
        - - DiscoverHostNode3
      ExitSequence:
        - - AddVm3OnESX3
        - - AddVnic1VM3
        - - GetVm3IdFromManager3
        - - GetVnic1OfVM3FromManager3
        - - DeleteVnic1ofVM3
        - - RemoveNSXManager3OnNode3
        - - DeletePortgroupFromESX1
        - - DeleteVSSFromESX1

      AddVSSOnEsx3:
        <<: *ADD_VSS_ON_ESX1
        TestHost: 'esx.[3]'
      AddPortGroupOnEsx3:
        <<: *ADD_PG_ON_ESX1
        TestHost: 'esx.[3]'
        portgroup:
           '[1]':
              name: "testpg"
              vss: "esx.[3].vss.[1]"
      RegisterHostNode3ToManager3: *SET_MANAGER3_ON_NODE3--ESX
      DiscoverHostNode3: *DISCOVER_HOST_NODE3--ESX
      GetVm3Id:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[3]"
        fabricvm:
            '[3]':
                discover: 'true'
                name: 'vm.[3]'
      DeleteVM3:
        <<: *DELETE_VM
        deletevm: vm.[3]
      AddVm3OnESX3:
        <<: *ADD_VM1_ON_HOST1--ESX
        vm:
          '[3]':
              template: 'rhel53-srv-32'
              host: 'esx.[3]'
      AddVnic1VM3:
        <<: *ADD_VNIC1_TO_VM1
        TestVM: 'vm.[3]'
        vnic:
            '[1]':
                driver: "E1000"
                connected: 1
                startconnected: 1
                portgroup: "esx.[3].portgroup.[1]"
      GetVm3IdFromManager3:
        <<: *GET_VM1_ID
        TestNSX: "nsxmanager.[3]"
        fabricvm:
            '[3]':
                discover: 'true'
                name: 'vm.[3]'
      GetVnic1OfVM3FromManager3:
        <<: *GET_VNIC1_OF_VM1
        TestNSX: "nsxmanager.[3]"
        fabricvif:
            '[3]':
                discover: 'true'
                adapter_mac: 'vm.[3].vnic.[1]'
      DeleteVnic1ofVM3:
        <<: *DELETE_VNIC1_OF_VM1
        TestVM: 'vm.[3]'
        deletevnic: vm.[3].vnic.[1]
      RemoveNSXManager3OnNode3: *REMOVE_NSX_MANAGER3_ON_NODE3--ESX
      DeletePortgroupFromESX1:
        <<: *DELETE_PORTGROUP_FROM_ESX1
        TestHost: 'esx.[3]'
        deleteportgroup: 'esx.[3].portgroup.[1]'
      DeleteVSSFromESX1:
        <<: *DELETE_VSS_FROM_ESX1
        TestHost: 'esx.[3]'
        deletevss: 'esx.[3].vss.[1]'

ESXVerifyDAServiceStateBasedOnHostRegistration:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXVerifyDAServiceStateBasedOnHostRegistration"
    Summary: 'This test verify NSX-DA service state depending on host registration'
    Procedure: '1. Verify nsx-da not running before host registration
                2. Register host with NSXManager and Discover it
                3. Verify nsx-da is in running state
                4. De-regiter host
                5. Verify that nsx-da now in stopped state'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
            - ['VerifyDANotRunning']
            - ['SetManagerOnESX1']
            - ['DiscoverHostNode']
            - ['VerifyDARunning']
        ExitSequence:
            - ['RemoveNSXManagerOnESX1']
            - ['VerifyDANotRunning']

        DiscoverHostNode: *DISCOVER_HOST_NODE1--ESX
        SetManagerOnESX1:
          <<: *SET_MANAGER--ESX
        RemoveNSXManagerOnESX1:
          <<: *REMOVE_NSX_MANAGER--ESX
        VerifyDANotRunning:
            Type: Host
            TestHost: 'esx.[1]'
            execution_type: 'cli'
            service_names:
              - 'nsx-da'
            sleepbetweenworkloads: 60
            get_service_status:
              'table[?]contain_once':
                  - service_name: nsx-da
                    service_status: stopped
        VerifyDARunning:
            Type: Host
            TestHost: 'esx.[1]'
            execution_type: 'cli'
            service_names:
              - 'nsx-da'
            sleepbetweenworkloads: 30
            get_service_status:
              'table[?]contain_once':
                  - service_name: nsx-da
                    service_status: started

ESXVerifyShowHostUUIDCLI:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "ESXVerifyShowHostUUIDCLI"
    Summary: 'This test runs and verify show host uuid cli on esx host'
    Procedure: '1. Register host with NSXManager
                2. Discover host node
                3. Get VM1 ID
                4. Get fabric node external_id using API and persist this id
                5. Run show host uuid cli and verify the result with persisted id'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
            - ['SetManagerOnESX1']
            - ['DiscoverHostNode']
            - ['GetExternalUUID']
            - ['VerifyHostUUID']
        ExitSequence:
            - ['RemoveNSXManagerOnESX1']

        DiscoverHostNode: *DISCOVER_HOST_NODE1--ESX
        SetManagerOnESX1: *SET_MANAGER--ESX
        RemoveNSXManagerOnESX1: *REMOVE_NSX_MANAGER--ESX
        GetExternalUUID:
            Type: "Host"
            TestHost: "nsxmanager.[1].hostnode.[1]"
            PersistData: 'yes'
            read:
                'external_id[?]defined': ''
        VerifyHostUUID:
            Type: Host
            TestHost: 'esx.[1]'
            execution_type: 'cli'
            get_host_uuid:
                'host_uuid[?]equal_to': 'nsxmanager.[1].hostnode.[1]->read->external_id'

ESXDeployAndRegisterEdgeVMVerifyResourceTypeIsEdgeNode:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXDeployAndRegisterEdgeVMVerifyResourceTypeIsEdgeNode"
    Summary: 'This test verify that resource type returned as EdgeNode after Edge VM registered with MP'
    Procedure: '1. Register host1 with NSXManager1 and Discover it
                2. Deploy Edge VM and register it with NSXManager1
                3. Discover Edge node ID
                4. Verify resource type is EdgeNode
                5. Remove Edge VM'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
            - ['SetManagerOnESX1']
            - ['DiscoverHostNode']
            - ['DeployEdgeVM']
            - ['RegisterEdgenodeWithNSXManager1']
            - ['DiscoverEdgeNodeId']
            - ['VerifyEdgeNodeResourceType']
        ExitSequence:
            - ['DeleteEdgeNode']
            - ['DeleteEdgeVm']
            - ['RemoveNSXManagerOnESX1']

        SetManagerOnESX1:
          <<: *SET_MANAGER--ESX
        DiscoverHostNode: *DISCOVER_HOST_NODE1--ESX
        RemoveNSXManagerOnESX1:
          <<: *REMOVE_NSX_MANAGER--ESX
        DeployEdgeVM:
            Type: Root
            TestNode: 'root.[1]'
            nsxedge:
              '[1]':
                  'username' : 'admin'
                  'password' : 'C@shc0w12345'
                  'build': 'nsx-edgenode:avalanche:beta:official'
                  'edgetype': 'compact'
                  'esx': 'esx.[2]'
                  'management_network': 'VM Network'
                  'internal_network': 'VM Network'
                  'uplink_network': 'VM Network'
                  'installtype': 'nested'
        RegisterEdgenodeWithNSXManager1:
            Type: Gateway
            TestGateway: 'nsxedge.[1]'
            sleepbetweenworkloads: 120
            register_nsx_edge_node:
                manager_username: 'admin'
                manager_password: 'default'
                manager_ip: 'nsxmanager.[1]'
                manager_thumbprint: 'nsxmanager.[1]'
                execution_type: 'cli'
        DiscoverEdgeNodeId:
            Type: "NSX"
            TestNSX: "nsxmanager.[1]"
            query_params:
                node_type: 'EdgeNode'
            hostnode:
                '[4]':
                    discover: 'true'
                    ip_addresses: 'nsxedge.[1]'
        VerifyEdgeNodeResourceType:
            Type: "Host"
            TestHost: "nsxmanager.[1].hostnode.[4]"
            read:
                'resource_type[?]equal_to': 'EdgeNode'
        DeleteEdgeNode:
            Type: "NSX"
            TestNSX: "nsxmanager.[1]"
            deleteedgenode: "nsxmanager.[1].hostnode.[4]"
        DeleteEdgeVm:
            <<: *DELETE_VM
            deletevm: nsxedge.[1]

ESXVerifyInventoryPostNSXDAReinstall:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "ESXVerifyInventoryPostNSXDAReinstall"
    Summary: 'This test verify that inventory works fine after NSX-DA vib re-installation'
    Procedure: '1. Register host with NSXManager and Discover it
                2. Get VM1 id from node1
                3. Uninstall nsx-da
                4. Add VM4 on host1 and attach vnic to it
                5. Install nsx-da
                6. Verify inventory'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
          - - AddVSSOnEsx1
          - - AddPortGroupOnEsx1
          - - RegisterHostNode1OnManager1
          - - DiscoverHostNode1
          - - GetVm1IdFromManager1
          - - UninstallNSXDAPackage
          - - AddVm4OnESX1
          - - AddVnic1VM4
        ExitSequence:
          - - InstallNSXDAPackage
          - - GetVm1IdFromManager1
          - - GetVm4IdFromManager1
          - - GetVnic1OfVM4FromManager1
          - - DeleteVM4
          - - DeregisterHostNode1FromManager1
          - - DeletePortgroupFromESX1
          - - DeleteVSSFromESX1

        AddVSSOnEsx1: *ADD_VSS_ON_ESX1
        AddPortGroupOnEsx1: *ADD_PG_ON_ESX1
        RegisterHostNode1OnManager1: *SET_MANAGER--ESX
        DiscoverHostNode1: *DISCOVER_HOST_NODE1--ESX
        GetVm1IdFromManager1: *GET_VM1_ID
        AddVm4OnESX1:
          <<: *ADD_VM1_ON_HOST1--ESX
          vm:
            '[4]':
                template: 'rhel53-srv-32'
                host: 'esx.[1]'
        AddVnic1VM4:
          <<: *ADD_VNIC1_TO_VM1
          TestVM: 'vm.[4]'
        GetVm4IdFromManager1:
          <<: *GET_VM1_ID
          fabricvm:
              '[4]':
                  discover: 'true'
                  name: 'vm.[4]'
        GetVnic1OfVM4FromManager1:
          <<: *GET_VNIC1_OF_VM1
          TestNSX: "nsxmanager.[1]"
          fabricvif:
              '[4]':
                  discover: 'true'
                  adapter_mac: 'vm.[4].vnic.[1]'
        DeleteVM4:
          <<: *DELETE_VM
          deletevm: vm.[4]
        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--ESX
        DeletePortgroupFromESX1: *DELETE_PORTGROUP_FROM_ESX1
        DeleteVSSFromESX1: *DELETE_VSS_FROM_ESX1

        UninstallNSXDAPackage:
            Type: Host
            TestHost: 'esx.[1]'
            configure_package:
              execution_type: 'cli'
              operation: uninstall
              resource:
                - 'nsx-da'
        InstallNSXDAPackage:
            Type: Host
            TestHost: 'esx.[1]'
            configure_package:
              execution_type: 'cli'
              operation: install
              maintenance: 1
              signaturecheck: 0
              resource:
                - 'nsx-suite:avalanche:beta:official:esx55.+nsx-da.+\.zip'

ESXVerifyInventoryPostNSXMpaReinstall:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "ESXVerifyInventoryPostNSXMpaReinstall"
    Summary: 'This test verify that inventory works fine after NSX-MPA vib re-installation'
    Procedure: '1. Register host with NSXManager and Discover it
                2. Get VM1 id from node1
                3. Uninstall nsx-mpa along with dependent packages i.e. nsxcli and nsx-da
                4. Add VM4 on host1 and attach vnic to it
                5. Install nsx-mpa and dependent packages
                6. Verify inventory'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
          - - AddVSSOnEsx1
          - - AddPortGroupOnEsx1
          - - RegisterHostNode1OnManager1
          - - DiscoverHostNode1
          - - GetVm1IdFromManager1
          - - DeregisterHostNode1FromManager1
          - - UninstallNSXMpaAndDependentPackagesFromHost1
          - - AddVm4OnESX1
          - - AddVnic1VM4
        ExitSequence:
          - - InstallNSXMpaAndDependentPackagesOnHost1
          - - RegisterHostNode1OnManager1
          - - GetVm1IdFromManager1
          - - GetVm4IdFromManager1
          - - GetVnic1OfVM4FromManager1
          - - DeleteVM4
          - - DeregisterHostNode1FromManager1
          - - DeletePortgroupFromESX1
          - - DeleteVSSFromESX1

        AddVSSOnEsx1: *ADD_VSS_ON_ESX1
        AddPortGroupOnEsx1: *ADD_PG_ON_ESX1
        RegisterHostNode1OnManager1: *SET_MANAGER--ESX
        DiscoverHostNode1: *DISCOVER_HOST_NODE1--ESX
        GetVm1IdFromManager1:
          <<: *GET_VM1_ID
          sleepbetweenworkloads: 150
        AddVm4OnESX1:
          <<: *ADD_VM1_ON_HOST1--ESX
          vm:
            '[4]':
                template: 'rhel53-srv-32'
                host: 'esx.[1]'
        AddVnic1VM4:
          <<: *ADD_VNIC1_TO_VM1
          TestVM: 'vm.[4]'
        GetVm4IdFromManager1:
          <<: *GET_VM1_ID
          fabricvm:
              '[4]':
                  discover: 'true'
                  name: 'vm.[4]'
        GetVnic1OfVM4FromManager1:
          <<: *GET_VNIC1_OF_VM1
          TestNSX: "nsxmanager.[1]"
          fabricvif:
              '[4]':
                  discover: 'true'
                  adapter_mac: 'vm.[4].vnic.[1]'
        DeleteVM4:
          <<: *DELETE_VM
          deletevm: vm.[4]
        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--ESX
        DeletePortgroupFromESX1: *DELETE_PORTGROUP_FROM_ESX1
        DeleteVSSFromESX1: *DELETE_VSS_FROM_ESX1

        UninstallNSXMpaAndDependentPackagesFromHost1:
            Type: Host
            TestHost: 'esx.[1]'
            configure_package:
              execution_type: 'cli'
              operation: uninstall
              resource:
                - 'nsx-da'
                - 'nsxcli'
                - 'nsx-mpa'
        InstallNSXMpaAndDependentPackagesOnHost1:
            Type: Host
            TestHost: 'esx.[1]'
            configure_package:
              execution_type: 'cli'
              operation: install
              maintenance: 1
              signaturecheck: 0
              resource:
                - 'nsx-suite:avalanche:beta:official:esx55.+nsx-mpa.+\.vib'
                - 'nsx-suite:avalanche:beta:official:esx55.+nsxcli.+\.vib'
                - 'nsx-suite:avalanche:beta:official:esx55.+nsx-da.+\.zip'

ESXVerifyMPAConnectivityStatus:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXVerifyMPAConnectivityStatus"
    Summary: 'This test verify mpa connectivity status of a fabric node'
    Procedure: '1. Register host with NSXManager
                2. Discover host node
                3. Verify that mpa connectivity status is UP
                4. Stop MPA service on host
                5. Verify that mpa connectivity status is DOWN now
                6. Start MPA service and verify that mpa connectivity status is UP again'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
            - ['SetManagerOnESX1']
            - ['DiscoverHostNode']
            - ['VerifyMPAConnectivityIsUP']
            - ['StopMPAOnESX1']
            - ['VerifyMPAConnectivityIsDown']
        ExitSequence:
            - ['StartMPAOnESX1']
            - ['VerifyMPAConnectivityIsUP']
            - ['RemoveNSXManagerOnESX1']

        SetManagerOnESX1: *SET_MANAGER--ESX
        DiscoverHostNode: *DISCOVER_HOST_NODE1--ESX
        RemoveNSXManagerOnESX1: *REMOVE_NSX_MANAGER--ESX
        VerifyMPAConnectivityIsUP:
            Type: "Host"
            TestHost: "nsxmanager.[1].hostnode.[1]"
            sleepbetweenworkloads: 60
            get_node_status:
                'mpa_connectivity_status[?]equal_to': 'UP'
        VerifyMPAConnectivityIsDown:
            Type: "Host"
            TestHost: "nsxmanager.[1].hostnode.[1]"
            sleepbetweenworkloads: 210
            get_node_status:
                'mpa_connectivity_status[?]equal_to': 'DOWN'
        StopMPAOnESX1: *STOP_MPA--ESX
        StartMPAOnESX1: *START_MPA--ESX

ESXRemoveNSXMPAWhenHostnodeNotRegisteredEvenOnce:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "ESXRemoveNSXMPAWhenHostnodeNotRegisteredEvenOnce"
    Summary: 'Inventory works fine after NSX-MPA vib re-installation when hostnode
              not registered even once'
    Procedure: '1. Setup has ESX host which is not registered with any MP-cluster node
                2. First remove and install nsx-mpa and its dependent packages
                   i.e. nsx-cli and nsx-da to make sure that host is in never used state
                3. Now uninstall nsx-mpa and its dependent packages
                4. Install nsx-mpa along with dependent packages
                5. Register and discover host1 with nsxmanager1
                6. Get VM1 ID from nsxmanager1
                7. Deregister host1 from nsxmanager1'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
          - - UninstallNSXMpaAndDependentPackagesFromHost1
          - - InstallNSXMpaAndDependentPackagesOnHost1
          - - UninstallNSXMpaAndDependentPackagesFromHost1
        ExitSequence:
          - - InstallNSXMpaAndDependentPackagesOnHost1
          - - RegisterHostNode1OnManager1
          - - DiscoverHostNode1
          - - GetVm1IdFromManager1
          - - DeregisterHostNode1FromManager1

        RegisterHostNode1OnManager1: *SET_MANAGER--ESX

        DiscoverHostNode1: *DISCOVER_HOST_NODE1--ESX

        GetVm1IdFromManager1:
          <<: *GET_VM1_ID
          sleepbetweenworkloads: 150

        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--ESX

        UninstallNSXMpaAndDependentPackagesFromHost1:
            Type: Host
            TestHost: 'esx.[1]'
            configure_package:
              execution_type: 'cli'
              operation: uninstall
              resource:
                - 'nsx-da'
                - 'nsxcli'
                - 'nsx-mpa'

        InstallNSXMpaAndDependentPackagesOnHost1:
            Type: Host
            TestHost: 'esx.[1]'
            configure_package:
              execution_type: 'cli'
              operation: install
              maintenance: 1
              signaturecheck: 0
              resource:
                - 'nsx-suite:avalanche:beta:official:esx55.+nsx-mpa.+\.vib'
                - 'nsx-suite:avalanche:beta:official:esx55.+nsxcli.+\.vib'
                - 'nsx-suite:avalanche:beta:official:esx55.+nsx-da.+\.zip'

ESXAddNodeWithMultipleHostsToCluster:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,Inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXAddNodeWithMultipleHostsToCluster"
    Summary: 'This test verifies that the host details get wiped out when MP
              node having multiple host registered added to MP cluster'
    Procedure: '1. This test make existing 3MP cluster into 2 clusters by removing and
                   cleaning MP node3, which makes MP node3 a single node cluster
                2. Register host1 with MP1 and host2, host3 with MP3
                3. Discover hosts and get VM1, VM2 and VM3 ID from respective MP nodes
                4. Now add MP node3 to cluster
                5. VM1 should get discovered from all 3 MP nodes
                6. Discovery of host2 and host3 from MP node3 should return Not_Found'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        <<: *INVENTORY_WORKLOADS
        <<: *MPClusteringConfigurationWorkloads
        <<: *MPClusteringVerificationWorkloads
        Sequence:
            - - CleanupMPNode3ForReuse
            - - RegisterHostNode1OnManager1
              - RegisterHostNode2OnManager3
              - RegisterHostNode3OnManager3
            - - DiscoverHostNode1OnManager1ESX
              - DiscoverHostNode1OnManager2ESX
              - DiscoverHostNode2OnManager3ESX
              - DiscoverHostNode3OnManager3ESX
            - - GetVm1IdFromManager1
              - GetVm1IdFromManager2
              - GetVm2IdFromManager3
              - GetVm3IdFromManager3
        ExitSequence:
            - - AddMPNode3ToCluster
            - - GetVm1IdFromManager1
              - GetVm1IdFromManager2
              - GetVm1IdFromManager3
            - - DiscoverHostNode2OnManager3NotFound
            - - DiscoverHostNode3OnManager3NotFound
            - - DeregisterHostNode1FromManager1
              - DeregisterHostNode2FromManager3
              - DeregisterHostNode3FromManager3

        RegisterHostNode1OnManager1: *SET_MANAGER--ESX

        RegisterHostNode2OnManager3:
            Type: Host
            TestHost: 'esx.[2]'
            set_nsx_manager:
                manager_ip: 'nsxmanager.[3]'
                execution_type: 'cli'
                manager_thumbprint: 'nsxmanager.[3]'

        RegisterHostNode3OnManager3: *SET_MANAGER3_ON_NODE3--ESX

        DiscoverHostNode2OnManager3NotFound:
          <<: *DISCOVER_HOSTNODE2_ON_MANAGER3--ESX
          ExpectedResult:
              status_code: "NOT_FOUND"

        DiscoverHostNode3OnManager3NotFound:
          <<: *DISCOVER_HOSTNODE3_ON_MANAGER3--ESX
          ExpectedResult:
              status_code: "NOT_FOUND"

        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--ESX

        DeregisterHostNode2FromManager3:
          <<: *REMOVE_NSX_MANAGER--ESX
          TestHost: 'esx.[2]'
          remove_nsx_manager:
              manager_ip: 'nsxmanager.[3]'
              execution_type: 'cli'
              manager_thumbprint: 'nsxmanager.[3]'

        DeregisterHostNode3FromManager3:
          <<: *REMOVE_NSX_MANAGER--ESX
          TestHost: 'esx.[3]'
          remove_nsx_manager:
              manager_ip: 'nsxmanager.[3]'
              execution_type: 'cli'
              manager_thumbprint: 'nsxmanager.[3]'

ESXRemoveNsxCliWhileNsxdaAndNsxmpaStillInstalled:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "ESXRemoveNsxCliWhileNsxdaAndNsxmpaStillInstalled"
    Summary: 'nsx-cli package removal should throw dependency error when nsx-da
              is still installed'
    Procedure: '1. Start package removal and verify the dependency error message.'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
          - - UninstallNSXCliFromHost1

        UninstallNSXCliFromHost1:
            Type: Host
            TestHost: 'esx.[1]'
            ExpectedResult:
                status_code: RUNTIME_ERROR
                error[?]match: |
                    \[DependencyError\]\\n VIB
            configure_package:
              execution_type: 'cli'
              operation: uninstall
              resource:
                - 'nsxcli'

ESXRemoveNsxmpaWhileNsxdaAndNsxcliStillInstalled:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "ESXRemoveNsxmpaWhileNsxdaAndNsxcliStillInstalled"
    Summary: 'nsx-mpa package removal should throw dependency error when nsx-da
              and nsx-cli is still installed'
    Procedure: '1. Start package removal and verify the dependency error message.'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
          - - UninstallNSXMpaFromHost1

        UninstallNSXMpaFromHost1:
            Type: Host
            TestHost: 'esx.[1]'
            ExpectedResult:
                status_code: RUNTIME_ERROR
                error[?]match: |
                    \[DependencyError\]\\n VIB
            configure_package:
              execution_type: 'cli'
              operation: uninstall
              resource:
                - 'nsx-mpa'

ESXMPNodeRemovedFromCluster:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '5'
    Tags: 'nsxmanager,Inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXMPNodeRemovedFromCluster"
    Summary: 'Registered host inventory gets migrated when MP node removed from cluster'
    Procedure: '1. Create setup with three nsxmanager, three esx each having one VM on it
                2. Register host1, host2 and host3 with all three nsxmanager respectively
                3. Discover host1 and get VM1 ID from all three MP nodes
                4. Now remove nsxmanager node3 from cluster
                5. VM3 should get discovered from nsxmanager 1 and 2
                6. Attach removed nsxmanager node to cluster
                7. Discovery of host3 from MP node3 should return Not_Found'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        <<: *INVENTORY_WORKLOADS
        <<: *MPClusteringConfigurationWorkloads
        <<: *MPClusteringVerificationWorkloads
        Sequence:
            - - RegisterHostNode1OnManager1
              - RegisterHostNode2OnManager2
              - RegisterHostNode3OnManager3
            - - DiscoverHostNode1OnManager1ESX
              - DiscoverHostNode1OnManager2ESX
              - DiscoverHostNode1OnManager3ESX
            - - GetVm1IdFromManager1
              - GetVm1IdFromManager2
              - GetVm1IdFromManager3
            - - CleanupMPNode3ForReuse
            - - DiscoverHostNode1OnManager1ESX
              - DiscoverHostNode1OnManager2ESX
              - DiscoverHostNode2OnManager1ESX
              - DiscoverHostNode2OnManager2ESX
              - DiscoverHostNode3OnManager1ESX
              - DiscoverHostNode3OnManager2ESX
            - - GetVm1IdFromManager1
              - GetVm1IdFromManager2
              - GetVm2IdFromManager1
              - GetVm2IdFromManager2
              - GetVm3IdFromManager1
              - GetVm3IdFromManager2
        ExitSequence:
            - - AddMPNode3ToCluster
            - - GetVm1IdFromManager1
              - GetVm1IdFromManager2
              - GetVm1IdFromManager3
#Follow-up work: Need to validate below behavior after bug#1446215 fix
#            - - DiscoverHostNode3OnManager3NotFound
            - - DeregisterHostNode1FromManager1
              - DeregisterHostNode2FromManager2
              - DeregisterHostNode3FromManager3

        RegisterHostNode1OnManager1: *SET_MANAGER--ESX

        RegisterHostNode2OnManager2: *SET_MANAGER2_ON_NODE2--ESX

        RegisterHostNode3OnManager3: *SET_MANAGER3_ON_NODE3--ESX

        DiscoverHostNode3OnManager3NotFound:
          <<: *DISCOVER_HOSTNODE3_ON_MANAGER3--ESX
          ExpectedResult:
              status_code: "NOT_FOUND"

        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--ESX

        DeregisterHostNode2FromManager2: *REMOVE_NSX_MANAGER2_ON_NODE2--ESX

        DeregisterHostNode3FromManager3: *REMOVE_NSX_MANAGER3_ON_NODE3--ESX

ESXInstallNsxdaWhenNsxmpaInstalledButNsxcliNotInstalled:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "ESXInstallNsxdaWhenNsxmpaInstalledButNsxcliNotInstalled"
    Summary: 'NSX-DA package installation should throw dependency error if NSX-CLI is not present'
    Procedure: '1. Remove NSX-DA and NSX-CLI packages from host1
                2. Installation of NSX-DA package on host1 throws NSX-CLI dependency error
                3. As part of exit process install both removed packages'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
          - - UninstallNSXCliAndNSXDaPackagesFromHost1
          - - InstallNSXDaWithoutInstallingNSXCliOnHost1
        ExitSequence:
          - - InstallNSXCliAndDNSXDaPackagesOnHost1

        UninstallNSXCliAndNSXDaPackagesFromHost1:
            Type: Host
            TestHost: 'esx.[1]'
            configure_package:
              execution_type: 'cli'
              operation: uninstall
              resource:
                - 'nsx-da'
                - 'nsxcli'

        InstallNSXDaWithoutInstallingNSXCliOnHost1:
            Type: Host
            TestHost: 'esx.[1]'
            ExpectedResult:
                status_code: RUNTIME_ERROR
                error[?]match: |
                    \[DependencyError\]\\n VIB
            configure_package:
              execution_type: 'cli'
              operation: install
              maintenance: 1
              signaturecheck: 0
              resource:
                - 'nsx-suite:avalanche:beta:official:esx55.+nsx-da.+\.zip'

        InstallNSXCliAndDNSXDaPackagesOnHost1:
            Type: Host
            TestHost: 'esx.[1]'
            configure_package:
              execution_type: 'cli'
              operation: install
              maintenance: 1
              signaturecheck: 0
              resource:
                - 'nsx-suite:avalanche:beta:official:esx55.+nsxcli.+\.vib'
                - 'nsx-suite:avalanche:beta:official:esx55.+nsx-da.+\.zip'

ESXInstallNsxdaWhenBothNsxmpaAndNsxcliNotInstalled:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "ESXInstallNsxdaWhenBothNsxmpaAndNsxcliNotInstalled"
    Summary: 'NSX-DA package installation should throw dependency error if NSX-MPA
              and NSX-CLI is not present'
    Procedure: '1. Remove NSX-MPA, NSX-DA and NSX-CLI packages from host1
                2. Install NSX-DA package on host1 which throws NSX-MPA and NSX-CLI
                   dependency error
                3. As part of exit process install all removed packages'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
          - - UninstallNSXMpaNSXCliAndNSXDaPackagesFromHost1
          - - InstallNSXDaWithoutInstallingNSXMpaAndNSXCliOnHost1
        ExitSequence:
          - - InstallNSXMpaNSXCliAndDNSXDaPackagesOnHost1

        UninstallNSXMpaNSXCliAndNSXDaPackagesFromHost1:
            Type: Host
            TestHost: 'esx.[1]'
            configure_package:
              execution_type: 'cli'
              operation: uninstall
              resource:
                - 'nsx-da'
                - 'nsxcli'
                - 'nsx-mpa'

        InstallNSXDaWithoutInstallingNSXMpaAndNSXCliOnHost1:
            Type: Host
            TestHost: 'esx.[1]'
            ExpectedResult:
                status_code: RUNTIME_ERROR
                error[?]match: |
                    \[DependencyError\]\\n VIB
            configure_package:
              execution_type: 'cli'
              operation: install
              maintenance: 1
              signaturecheck: 0
              resource:
                - 'nsx-suite:avalanche:beta:official:esx55.+nsx-da.+\.zip'

        InstallNSXMpaNSXCliAndDNSXDaPackagesOnHost1:
            Type: Host
            TestHost: 'esx.[1]'
            configure_package:
              execution_type: 'cli'
              operation: install
              maintenance: 1
              signaturecheck: 0
              resource:
                - 'nsx-suite:avalanche:beta:official:esx55.+nsx-mpa.+\.vib'
                - 'nsx-suite:avalanche:beta:official:esx55.+nsxcli.+\.vib'
                - 'nsx-suite:avalanche:beta:official:esx55.+nsx-da.+\.zip'

ESXRemoveNsxmpaWhileHostNodeIsStillRegistered:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "ESXRemoveNsxmpaWhileHostNodeIsStillRegistered"
    Summary: 'NSX-MPA package removal should throw error if hostnode is still registered with MP'
    Procedure: '1. Register host1 with nsxmanager1
                2. Remove NSX-DA and NSX-CLI packages from host1
                3. Remove NSX-MPA package from host1 which should throw error message
                   saying de-register node before mpa uninstall
                4. Exit test with nsx-cli and nsx-da package install and host deregistration'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
          - - RegisterHostNode1OnManager1
          - - UninstallNSXCliAndNSXDaPackagesFromHost1
          - - VerifyNSXMpaUninstallFailure
        ExitSequence:
          - - InstallNSXCliAndNSXDaPackagesOnHost1
          - - DeregisterHostNode1FromManager1

        RegisterHostNode1OnManager1: *SET_MANAGER--ESX

        DeregisterHostNode1FromManager1: *REMOVE_NSX_MANAGER--ESX

        UninstallNSXCliAndNSXDaPackagesFromHost1:
            Type: Host
            TestHost: 'esx.[1]'
            configure_package:
              execution_type: 'cli'
              operation: uninstall
              resource:
                - 'nsx-da'
                - 'nsxcli'

        VerifyNSXMpaUninstallFailure:
            Type: Host
            TestHost: 'esx.[1]'
            ExpectedResult:
                status_code: RUNTIME_ERROR
                error[?]match: |
                    De-register node from MP before uninstalling MPA
            configure_package:
              execution_type: 'cli'
              operation: uninstall
              resource:
                - 'nsx-mpa'

        InstallNSXCliAndNSXDaPackagesOnHost1:
            Type: Host
            TestHost: 'esx.[1]'
            configure_package:
              execution_type: 'cli'
              operation: install
              resource:
                - 'nsx-suite:avalanche:beta:official:nsxcli-7.*rpm'
                - 'nsx-suite:avalanche:beta:official:nsx-da-7.*rpm'

ESXVerifyMPAConnectivityStatusHostDown:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXVerifyMPAConnectivityStatusHostDown"
    Summary: 'MPA connectivity status of a fabric node becomes down when host is down'
    Procedure: '1. Register host with NSXManager
                2. Discover host node and verify mpa connectivity status is UP
                3. Start host reboot operation and verify that mpa connectivity
                   status is DOWN'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
            - ['SetManagerOnESX1']
            - ['DiscoverHostNode']
            - ['VerifyMPAConnectivityIsUP']
            - ['RebootHost1', 'VerifyMPAConnectivityIsDown']
        ExitSequence:
            - ['VerifyMPAConnectivityIsUP']
            - ['RemoveNSXManagerOnESX1']

        SetManagerOnESX1: *SET_MANAGER--ESX

        DiscoverHostNode: *DISCOVER_HOST_NODE1--ESX

        RemoveNSXManagerOnESX1: *REMOVE_NSX_MANAGER--ESX

        VerifyMPAConnectivityIsUP:
            Type: "Host"
            TestHost: "nsxmanager.[1].hostnode.[1]"
            sleepbetweenworkloads: 60
            get_node_status:
                'mpa_connectivity_status[?]equal_to': 'UP'

        VerifyMPAConnectivityIsDown:
            Type: "Host"
            TestHost: "nsxmanager.[1].hostnode.[1]"
            sleepbetweenworkloads: 210
            get_node_status:
                'mpa_connectivity_status[?]equal_to': 'DOWN'

        RebootHost1:
            Type: 'Host'
            TestHost: 'esx.[1]'
            reboot: 'yes'

ESXVerifyInventoryAfterAddingMaximumPermissibleVnicsInAVM:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P1"
    QCPath: ""
    TestName: "ESXVerifyInventoryAfterAddingMaximumPermissibleVnicsInAVM"
    Summary: 'Add maximum possible vnics to an ESX VM and verify all vnic IDs'
    Procedure: '1. Register host1 with NSXManager1
                2. Discover host node
                3. Add VM4 to host1
                4. Add 9 vnics to VM4 (maximum 10 vnics are supported and one
                   gets created during VM creation)
                5. Verify that all vnics are getting listed
                6. Remove all newly added vnics and VM4 as part of cleanup'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
            - - AddVSSOnEsx1
            - - AddPortGroupOnEsx1
            - - SetManagerOnESX1
            - - DiscoverHostNode
            - - AddVm4OnESX1
            - - Add9VnicsToVM4
            - - GetVm4Id
            - - GetAll9VnicsOfVM4
        ExitSequence:
            - - DeleteAllNewlyAddedVnicsFromVM4
            - - DeleteVM4
            - - RemoveNSXManagerOnESX1
            - - DeletePortgroupFromESX1
            - - DeleteVSSFromESX1

        AddVSSOnEsx1: *ADD_VSS_ON_ESX1

        AddPortGroupOnEsx1: *ADD_PG_ON_ESX1

        SetManagerOnESX1: *SET_MANAGER--ESX

        DiscoverHostNode: *DISCOVER_HOST_NODE1--ESX

        RemoveNSXManagerOnESX1: *REMOVE_NSX_MANAGER--ESX

        AddVm4OnESX1: *ADD_VM4_ON_HOST1--ESX

        Add9VnicsToVM4:
          Type: VM
          TestVM: 'vm.[4]'
          vnic:
              '[1-9]':
                  driver: "E1000"
                  connected: 1
                  startconnected: 1
                  portgroup: "esx.[1].portgroup.[1]"

        DeleteAllNewlyAddedVnicsFromVM4:
          Type: VM
          TestVM: 'vm.[4]'
          deletevnic: 'vm.[4].vnic.[1-9]'

        DeleteVM4:
          <<: *DELETE_VM
          deletevm: 'vm.[4]'

        GetVm4Id: *GET_VM4ID_FROM_MANAGER1

        GetAll9VnicsOfVM4:
          <<: *GET_VNIC1_OF_VM1
          fabricvif:
              '[1-9]':
                  discover: 'true'
                  adapter_mac: 'vm.[4].vnic.[x]'

        DeletePortgroupFromESX1: *DELETE_PORTGROUP_FROM_ESX1

        DeleteVSSFromESX1: *DELETE_VSS_FROM_ESX1

ESXHostFQDNChangeGetReflectInFabricNodeDisplayName:
    Product: "NSXTransformers"
    Category: "ManagementPlatform"
    Component: "InventoryManager"
    Developer: "ugaurav"
    Version: "2"
    ExpectedResult: "PASS"
    Status: "Execution Ready"
    AutomationLevel: "Automated"
    FullyAutomatable: "Y"
    TestcaseLevel: "Functional"
    TestcaseType: "Functional"
    Duration: '300'
    Tags: 'nsxmanager,inventory,management,cat'
    Partnerfacing: "Y"
    Priority: "P2"
    QCPath: ""
    TestName: "ESXHostFQDNChangeGetReflectInFabricNodeDisplayName"
    Summary: 'ESX host FQDN change get reflected in fabric node displayname'
    Procedure: '1. Register host with NSXManager
                2. Discover host node
                3. Query and save fabric node displayname and host FQDN
                4. Set new hostname and verify that fabric node displayname changed to
                   the new modified name
                5. Revert the hostname to its original'
    TestbedSpec: *4ESX_NODES_3NSXMANAGER_NESTED_IN_4TH_ESX
    WORKLOADS:
        Sequence:
            - ['SetManagerOnESX1']
            - ['DiscoverHostNode']
            - ['GetOriginalHostname']
            - ['SetNewHostname']
            - ['VerifyNewHostname']
            - ['VerifyUpdatedFabricNodeDisplayname']
        ExitSequence:
            - ['RevertOriginalHostname']
            - ['VerifyOriginalHostname']
            - ['RemoveNSXManagerOnESX1']

        SetManagerOnESX1: *SET_MANAGER--ESX

        DiscoverHostNode: *DISCOVER_HOST_NODE1--ESX

        RemoveNSXManagerOnESX1: *REMOVE_NSX_MANAGER--ESX

        GetOriginalHostname:
            Type: "Host"
            TestHost: "esx.[1]"
            PersistData: 'yes'
            execution_type: 'cli'
            read_hostname:
                'hostname[?]defined': ''

        SetNewHostname:
            Type: "Host"
            TestHost: 'esx.[1]'
            set_hostname:
                execution_type: 'cli'
                hostname: 'newhostname.eng.vmware.com'

        VerifyNewHostname:
            Type: "Host"
            TestHost: 'esx.[1]'
            execution_type: 'cli'
            read_hostname:
                'hostname[?]equal_to': 'newhostname.eng.vmware.com'

        VerifyUpdatedFabricNodeDisplayname:
            Type: "Host"
            TestHost: "nsxmanager.[1].hostnode.[1]"
            sleepbetweenworkloads: 180
            read:
                'name[?]equal_to': 'newhostname.eng.vmware.com'

        RevertOriginalHostname:
            Type: "Host"
            TestHost: 'esx.[1]'
            set_hostname:
                execution_type: 'cli'
                hostname: 'esx.[1]->read_hostname->hostname'

        VerifyOriginalHostname:
            Type: "Host"
            TestHost: 'esx.[1]'
            execution_type: 'cli'
            read_hostname:
                'hostname[?]equal_to': 'esx.[1]->read_hostname->hostname'
